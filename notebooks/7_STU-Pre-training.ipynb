{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95281584",
   "metadata": {},
   "source": [
    "# We will take the pre-trained STU-Net (Large -> Pre-trained on the TotalSegmentator cases) and further pre-train on the scrolls and fragments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 1000\n",
    "PATCH_SIZE = (128,128,128)\n",
    "CRITERION = \"L1\"\n",
    "MASK_WEIGHT = 10\n",
    "LR_SCHEDULER = \"CosineAnnealingLR\"\n",
    "DEVICE = 'cuda'\n",
    "SAVE_DIR = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/5_scrolls_pretrain\"\n",
    "CHECKPOINT_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/binary_large_ep4k.pth\"\n",
    "DATA_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Pre-training\"\n",
    "VAL_DATA_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset\"\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "RESUME = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/5_scrolls_pretrain/wandb/run-20251219_094054-w862cvd3/files/model/model_epoch_100.pth\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f11b5",
   "metadata": {},
   "source": [
    "## Building the data loader (DONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37bdefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "from os import listdir, makedirs\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import zarr\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import nibabel as nib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# MONAI\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureType,\n",
    "    RandCoarseDropout,\n",
    "    RandCropByPosNegLabel,\n",
    "    RandFlip,\n",
    "    RandGaussianNoise,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    ScaleIntensityRange,\n",
    "    LoadImage,\n",
    "    CopyItemsd,\n",
    "    LoadImaged, \n",
    "    ScaleIntensityRanged, \n",
    "    ResizeWithPadOrCropd, \n",
    "    RandCoarseDropoutd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd\n",
    ")\n",
    "from monai.data import DataLoader, CacheDataset\n",
    "\n",
    "from stunet_model import STUNetReconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vol(tensor, path):\n",
    "    # prediction: torch.Tensor\n",
    "    # shape example: [B, C, H, W] or [B, 1, H, W]\n",
    "\n",
    "    tensor_cpu = tensor.detach().cpu()\n",
    "\n",
    "    # Remove batch and channel dims if needed\n",
    "    tensor_cpu = tensor_cpu[0]          \n",
    "    tensor_cpu = tensor_cpu.squeeze(0)  \n",
    "\n",
    "    tensor_np = tensor_cpu.numpy()\n",
    "\n",
    "    affine = np.eye(4)  # identity affine (OK if no spatial metadata)\n",
    "\n",
    "    nii = nib.Nifti1Image(tensor_np.astype(np.float32), affine)\n",
    "    nib.save(nii, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrVolumeDataset(Dataset):\n",
    "    def __init__(self, zarr_path, transform_input, transform_deform, patch_size=(128, 128, 128), threshold=10.0): # threshold 10 to avoid some background noise\n",
    "        \"\"\"\n",
    "        it expects to receive:\n",
    "            zarr_path -> path to the root zarr folder\n",
    "            transform_input -> MONAI transforms to load the data\n",
    "            transform_deform -> MONAI transforms for self-supervised training\n",
    "            patch_size -> Patch size (double check if a pre-trained network is being used)\n",
    "            threshold -> Only returns the data if any voxel inside of the patch is greater than threshold.\n",
    "\n",
    "        \"\"\"\n",
    "        self.zarr_path = zarr_path\n",
    "        self.transform_input = transform_input\n",
    "        self.transform_deform = transform_deform\n",
    "        self.patch_size = patch_size\n",
    "        self.threshold = threshold  # Value below which we consider the pixel \"background\"\n",
    "\n",
    "        print(f\"Loading data from -> {zarr_path}\")\n",
    "\n",
    "        self.zarr_vols_paths = []\n",
    "        for zarr_folder in listdir(zarr_path):\n",
    "            if zarr_folder.endswith(\".zarr\"):\n",
    "                complete_zarr_path = join(zarr_path, zarr_folder)\n",
    "                self.zarr_vols_paths.append(complete_zarr_path) # save a list of paths\n",
    "                \n",
    "                # Load the zarr file in the __getitem___\n",
    "                # shape = vol.shape\n",
    "                # entry = {\n",
    "                #     \"name\": zarr_folder,\n",
    "                #     \"volume\": vol,\n",
    "                #     \"shape\": shape\n",
    "                # }\n",
    "                # self.zarr_vols.append(entry)\n",
    "        print(f\"All ZARR paths: {self.zarr_vols_paths}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Defining a length of one epoch\n",
    "        return 1000 \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Transformations on the fly\n",
    "        # Using lazy loader (memory doesn't handle such big data)\n",
    "        random_entry = random.choice(self.zarr_vols_paths) # select random path\n",
    "        # open the file (lazy)\n",
    "        root = zarr.open(random_entry, mode='r')     \n",
    "        if 'volume' in root:\n",
    "            vol = root['volume']\n",
    "        else:\n",
    "            vol = root['0']\n",
    "        \n",
    "        shape = vol.shape\n",
    "        \n",
    "        z_max = max(0, shape[0] - self.patch_size[0])\n",
    "        y_max = max(0, shape[1] - self.patch_size[1])\n",
    "        x_max = max(0, shape[2] - self.patch_size[2])\n",
    "\n",
    "        # --- THE REJECTION SAMPLING LOOP ---\n",
    "        # Try up to 100 times to find a non-empty chunk (very likely to find one!)\n",
    "        for attempt in range(100):\n",
    "            # We'll do it ourselves, it's easier to understand\n",
    "            # 1. Random Coordinates\n",
    "            z_start = np.random.randint(0, z_max) if z_max > 0 else 0\n",
    "            y_start = np.random.randint(0, y_max) if y_max > 0 else 0\n",
    "            x_start = np.random.randint(0, x_max) if x_max > 0 else 0\n",
    "\n",
    "            # 2. Load the chunk\n",
    "            patch = vol[\n",
    "                z_start : z_start + self.patch_size[0],\n",
    "                y_start : y_start + self.patch_size[1],\n",
    "                x_start : x_start + self.patch_size[2]\n",
    "            ]\n",
    "\n",
    "            # 3. Check if it contains data\n",
    "            # If the max value in this patch is greater than our threshold (0), it's valid.\n",
    "            if np.max(patch) > self.threshold:\n",
    "                # Found valid data! Break the loop and process it.\n",
    "                break\n",
    "            \n",
    "            # If we are here, the patch was empty. The loop continues to the next attempt.\n",
    "        \n",
    "        # Note: If the loop finishes 20 times and finds nothing, it will return the LAST empty patch.\n",
    "        # This prevents the code from hanging forever if the file is truly empty.\n",
    "\n",
    "        # 4. MONAI Formatting\n",
    "        patch = patch.astype(np.float32) # Ensure float for transforms\n",
    "        patch = patch[np.newaxis, ...]   # Add Channel dim -> (1, Z, Y, X)\n",
    "        \n",
    "        tracking_mask = np.ones_like(patch) # Create a volume full one 1s to track the mask generated\n",
    "\n",
    "        # Normalization\n",
    "        patch_dict = self.transform_input(\n",
    "            {\"image\": patch}\n",
    "        )\n",
    "\n",
    "        # Save the clean image\n",
    "        clean_patch = patch_dict['image'].clone()\n",
    "        \n",
    "        # Create masked volume\n",
    "        deform_patch = self.transform_deform(\n",
    "            {\n",
    "                \"image\": patch_dict['image'], \n",
    "                \"tracking_mask\": tracking_mask\n",
    "            }\n",
    "        )\n",
    "\n",
    "        dropout_mask = 1 - deform_patch['tracking_mask']\n",
    "\n",
    "        return {\n",
    "            'clean_patch':clean_patch,\n",
    "            'deform_patch':deform_patch[\"image\"],\n",
    "            'dropout_mask': dropout_mask\n",
    "        }\n",
    "\n",
    "def describe_tensor(name, t):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  type:  {type(t)}\")\n",
    "    print(f\"  dtype: {t.dtype}\")\n",
    "    print(f\"  device:{t.device}\")\n",
    "    print(f\"  shape: {tuple(t.shape)}\")\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    # --- Setup ---\n",
    "    transform_input = Compose([\n",
    "        # Load image will be handeled by the lazzy zarr loading data\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0, b_max=1, clip=True),\n",
    "        # Not do it, we have a lot of data for pre-training\n",
    "        # RandFlip(\n",
    "        #    prob=0.1, \n",
    "        #    spatial_axis=None\n",
    "        #    ),\n",
    "        # RandRotate90(\n",
    "        #    prob=0.1,  \n",
    "        #    max_k=3, \n",
    "        #    spatial_axes=(0, 1), \n",
    "        #    lazy=False)\n",
    "        EnsureTyped(keys=[\"image\"])\n",
    "    ])\n",
    "\n",
    "    # The Corruption Transforms\n",
    "    # We want to force the model to fix heavy defects.\n",
    "    transform_deform = Compose([\n",
    "        # Cut out 10 holes, each spatial size roughly 32x48x48\n",
    "        # 35% of data loss\n",
    "        RandCoarseDropoutd(\n",
    "            keys=[\"image\", \"tracking_mask\"],\n",
    "            holes=10, \n",
    "            spatial_size=(32, 48, 48), \n",
    "            fill_value=0,\n",
    "            prob=1.0 # Always apply\n",
    "        ),\n",
    "        # Add noise (not do it)\n",
    "        #RandGaussianNoise(prob=0.5, mean=0.0, std=0.1),\n",
    "        EnsureTyped(keys=[\"image\", \"tracking_mask\"])\n",
    "    ])\n",
    "\n",
    "    print(\"Initializing Dataset...\")\n",
    "    ds = ZarrVolumeDataset(\n",
    "        \"/mounts/disk2/Andre_Data_Augmentation/PhD/Vesuvius\", \n",
    "        transform_input=transform_input,\n",
    "        transform_deform=transform_deform,\n",
    "        patch_size=(128, 128, 128) \n",
    "    )\n",
    "\n",
    "    print(\"Initializing DataLoader...\")\n",
    "    loader = monai.data.DataLoader(ds, batch_size=1, num_workers=4)\n",
    "    data_loader = iter(loader)\n",
    "    first_batch = next(data_loader)\n",
    "    clean_patch = first_batch['clean_patch']\n",
    "    deform_patch = first_batch['deform_patch']\n",
    "    print(\"Fetching a batch to ensure it's not empty...\")\n",
    "\n",
    "    print(f\"Batch Max Value: {clean_patch.max()}\")\n",
    "    if clean_patch.max() == 0:\n",
    "        print(\"WARNING: The batch is still empty. Your threshold might be too high or the volume is empty.\")\n",
    "    else:\n",
    "        print(\"Success! Loaded a non-empty chunk.\")\n",
    "\n",
    "    print(f\"Success! Batch shape: {clean_patch.shape}\")\n",
    "\n",
    "    describe_tensor(\"clean_patch\", clean_patch)\n",
    "    describe_tensor(\"deform_patch\", deform_patch)\n",
    "    for i in range(10):\n",
    "        first_batch = next(data_loader)\n",
    "        dropout_mask = first_batch['dropout_mask']\n",
    "\n",
    "        save_vol(dropout_mask, f\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/train_mask_{i}.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1476980",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from ipywidgets import interact, IntSlider\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    # 1. Extract the raw 3D volume from the batch\n",
    "    # MONAI batch shape is (Batch_Size, Channel, Dim1, Dim2, Dim3)\n",
    "    # We select Batch 0 and Channel 0\n",
    "    input_data = deform_patch[0, 0].cpu().numpy()\n",
    "\n",
    "    print(f\"Batch Shape: {clean_patch.shape}\")\n",
    "    print(f\"Visualizing Sample Shape: {clean_patch.shape}\")\n",
    "\n",
    "    # 2. Setup Interactive Viewer\n",
    "    def view_batch_slice(slice_idx, axis):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        \n",
    "        # Allow slicing along different axes to debug orientation\n",
    "        if axis == 0:\n",
    "            # Slicing the first dimension (usually Z if (Z, Y, X))\n",
    "            plt.imshow(input_data[slice_idx, :, :], cmap='gray')\n",
    "            plt.xlabel(\"Axis 2\")\n",
    "            plt.ylabel(\"Axis 1\")\n",
    "        elif axis == 1:\n",
    "            # Slicing the second dimension\n",
    "            plt.imshow(input_data[:, slice_idx, :], cmap='gray')\n",
    "            plt.xlabel(\"Axis 2\")\n",
    "            plt.ylabel(\"Axis 0\")\n",
    "        else:\n",
    "            # Slicing the third dimension\n",
    "            plt.imshow(input_data[:, :, slice_idx], cmap='gray')\n",
    "            plt.xlabel(\"Axis 1\")\n",
    "            plt.ylabel(\"Axis 0\")\n",
    "            \n",
    "        plt.title(f\"Slice {slice_idx} along Axis {axis}\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    # 3. Create Slider\n",
    "    # We default to Axis 0, but you can change the axis variable below to 1 or 2\n",
    "    axis_to_scroll = 0 \n",
    "\n",
    "    interact(\n",
    "        view_batch_slice, \n",
    "        slice_idx=IntSlider(\n",
    "            min=0, \n",
    "            max=input_data.shape[axis_to_scroll]-1, \n",
    "            step=1, \n",
    "            value=input_data.shape[axis_to_scroll]//2,\n",
    "            description='Slice'\n",
    "        ),\n",
    "        axis=IntSlider(min=0, max=2, step=1, value=0, description='View Axis')\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ab577",
   "metadata": {},
   "source": [
    "## Building the pre-training process\n",
    "* The technique will be simple masking (oclusion) and respective reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "\n",
    "date_string = f\"{x.day}-{x.month}-{x.year}\"\n",
    "print(date_string)\n",
    "\n",
    "# Initialize your wandb run and specify the directory\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"faking_it\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"Vesuvius\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"architecture\": \"STU-Net\",\n",
    "        \"dataset\": \"5 scrolls\",\n",
    "        \"epochs\": NUM_EPOCHS,\n",
    "        \"patch_size\": PATCH_SIZE,\n",
    "        \"criterion\": CRITERION,\n",
    "        \"lr_scheduler\": LR_SCHEDULER,\n",
    "        \"save_dir\": SAVE_DIR,\n",
    "        \"checkpoint_path\": CHECKPOINT_PATH\n",
    "    },\n",
    "    name=f\"Pre_training_with_5_scrolls_{date_string}\", \n",
    "    dir=SAVE_DIR\n",
    ")\n",
    "\n",
    "MODEL_SAVE_PATH = join(run.dir, \"model\")\n",
    "makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "PREDS_PATH = join(run.dir, \"preds\")\n",
    "makedirs(PREDS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0c4b6-6834-444a-aa22-2aadf7bf0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_logic(best_loss, avg_loss, epoch, optimizer, model):\n",
    "    if best_loss > avg_loss: \n",
    "        best_loss = avg_loss\n",
    "        save_path = join(MODEL_SAVE_PATH, f\"model_best.pth\")\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_weights': model.state_dict(),  \n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': avg_loss,\n",
    "            }, save_path)\n",
    "        print(f\"Saved checkpoint: {save_path}\")\n",
    "\n",
    "    # Save Checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        save_path = join(MODEL_SAVE_PATH, f\"model_epoch_{epoch}.pth\")\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_weights': model.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': avg_loss,\n",
    "            }, save_path)\n",
    "        print(f\"Saved checkpoint: {save_path}\")\n",
    "    return best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, train_loader, train_criterion, optimizer, epoch, scaler):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\")\n",
    "    for idx, batch_dict in enumerate(pbar):\n",
    "        clean_patch = batch_dict['clean_patch'].to(DEVICE)\n",
    "        deform_patch = batch_dict['deform_patch'].to(DEVICE)\n",
    "        dropout_mask = batch_dict['dropout_mask'].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # --- FP16 FORWARD PASS ---\n",
    "        with autocast(device_type=DEVICE):\n",
    "            # Forward Pass\n",
    "            # The model tries to predict the CLEAN image from the DEFORMED input\n",
    "            prediction = model(deform_patch)\n",
    "            # Calculate Loss (Compare Prediction vs. Clean)\n",
    "            train_loss = train_criterion(prediction, clean_patch, dropout_mask)\n",
    "\n",
    "            # commented to avoid overwhelming \n",
    "            # run.log(\n",
    "            #     {\n",
    "            #         \"train_loss\": train_loss.item(),\n",
    "            #         \"train_step\": epoch*len(train_loader)+idx\n",
    "                \n",
    "            #     }\n",
    "            # )\n",
    "            \n",
    "        # Backward\n",
    "        scaler.scale(train_loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        epoch_loss += train_loss.item()\n",
    "        pbar.set_postfix({\"Loss\": train_loss.item()})\n",
    "\n",
    "    # Save a prediction\n",
    "    save_vol(prediction, join(PREDS_PATH, f\"{epoch}_pred_train.nii.gz\"))\n",
    "    save_vol(deform_patch, join(PREDS_PATH, f\"{epoch}_deform_train.nii.gz\"))\n",
    "    save_vol(clean_patch, join(PREDS_PATH, f\"{epoch}_clean_train.nii.gz\"))\n",
    "    save_vol(dropout_mask, join(PREDS_PATH, f\"{epoch}_mask_train.nii.gz\"))\n",
    "    train_avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} Finished. Avg Loss: {train_avg_loss:.6f}\")\n",
    "    return model, optimizer, train_avg_loss\n",
    "\n",
    "def val(model, val_loader, val_criterion, epoch):\n",
    "    model.eval()\n",
    "    val_loss_sum = 0\n",
    "    pbar = tqdm(val_loader, desc=f\"Val epoch {epoch}/{NUM_EPOCHS}\")\n",
    "    for batch_dict in pbar:\n",
    "        clean_patch = batch_dict['image'].to(DEVICE)\n",
    "        deform_patch = batch_dict['deform_patch'].to(DEVICE)\n",
    "        dropout_mask = 1 - batch_dict['tracking_mask']\n",
    "        dropout_mask = dropout_mask.to(DEVICE)\n",
    "        # --- FP16 FORWARD PASS ---\n",
    "        with torch.no_grad():\n",
    "            # Forward Pass\n",
    "            # The model tries to predict the CLEAN image from the DEFORMED input\n",
    "            prediction = model(deform_patch)\n",
    "            # Calculate Loss (Compare Prediction vs. Clean)\n",
    "            val_loss = val_criterion(prediction, clean_patch, dropout_mask)\n",
    "            # commented to avoid overwhelming \n",
    "            #run.log({\"val_loss\": val_loss.item()})\n",
    "\n",
    "        val_loss_sum += val_loss.item()\n",
    "        pbar.set_postfix({\"Loss\": val_loss.item()})\n",
    "\n",
    "    # Save a prediction\n",
    "    save_vol(prediction, join(PREDS_PATH, f\"{epoch}_pred.nii.gz\"))\n",
    "    save_vol(deform_patch, join(PREDS_PATH, f\"{epoch}_deform.nii.gz\"))\n",
    "    save_vol(clean_patch, join(PREDS_PATH, f\"{epoch}_clean.nii.gz\"))\n",
    "    save_vol(dropout_mask, join(PREDS_PATH, f\"{epoch}_mask.nii.gz\"))\n",
    "    val_avg_loss = val_loss_sum / len(val_loader)\n",
    "    print(f\"Epoch {epoch} with validation avg Loss: {val_avg_loss:.6f}\")\n",
    "    return val_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56984e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, train_loader, val_loader, train_criterion, val_criterion, scheduler, scaler, epoch, val_loss):\n",
    "    best_val_loss = val_loss\n",
    "    \n",
    "    for epoch in range(epoch, NUM_EPOCHS + 1):\n",
    "        # Train one epoch\n",
    "        model, optimizer, train_avg_loss = epoch_train(\n",
    "            model=model, \n",
    "            train_loader=train_loader,\n",
    "            optimizer=optimizer, \n",
    "            epoch=epoch, \n",
    "            scaler=scaler, \n",
    "            train_criterion=train_criterion\n",
    "        )\n",
    "\n",
    "        # Run validation step\n",
    "        val_avg_loss = val(\n",
    "            model=model, \n",
    "            epoch=epoch, \n",
    "            val_loader=val_loader, \n",
    "            val_criterion=val_criterion\n",
    "        )\n",
    "\n",
    "        # Save in wandb\n",
    "        run.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_avg_loss\": train_avg_loss,\n",
    "                \"val_avg_loss\": val_avg_loss\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Checking if saving \n",
    "        best_val_loss = saving_logic(\n",
    "            best_loss=best_val_loss, \n",
    "            avg_loss=val_avg_loss, \n",
    "            epoch=epoch, \n",
    "            optimizer=optimizer, \n",
    "            model=model\n",
    "        )\n",
    "\n",
    "        # Applying learning rate Cosine Annealing\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6034ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zarr_dataloader():\n",
    "    transform_input = Compose(\n",
    "        [\n",
    "            # Load image will be handeled by the lazzy zarr loading data\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0, b_max=1, clip=True),\n",
    "            EnsureTyped(keys=[\"image\"])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # The Corruption Transforms\n",
    "    # We want to force the model to fix heavy defects.\n",
    "    transform_deform = Compose(\n",
    "        [\n",
    "            # Cut out 10 holes, each spatial size roughly 32x48x48\n",
    "            # 35% of data loss\n",
    "            RandCoarseDropoutd(\n",
    "                keys=[\"image\", \"tracking_mask\"],\n",
    "                holes=10, \n",
    "                spatial_size=(32, 48, 48), \n",
    "                fill_value=0,\n",
    "                prob=1.0 # Always apply\n",
    "            ),\n",
    "            # Add noise (not do it)\n",
    "            #RandGaussianNoise(prob=0.5, mean=0.0, std=0.1),\n",
    "            EnsureTyped(keys=[\"image\", \"tracking_mask\"])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Initializing Dataset...\")\n",
    "    ds = ZarrVolumeDataset(\n",
    "        zarr_path=DATA_PATH, \n",
    "        transform_input=transform_input,\n",
    "        transform_deform=transform_deform,\n",
    "        patch_size=PATCH_SIZE\n",
    "    )\n",
    "\n",
    "    print(\"Initializing DataLoader...\")\n",
    "    train_loader = monai.data.DataLoader(ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    return train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "# Create volume of ones\n",
    "volume = np.ones((128, 128, 128), dtype=np.float32)\n",
    "\n",
    "# Create an identity affine (voxel-to-world transform)\n",
    "affine = np.eye(4)\n",
    "\n",
    "# Create NIfTI image\n",
    "nii_img = nib.Nifti1Image(volume, affine)\n",
    "\n",
    "# Save as .nii.gz\n",
    "nib.save(nii_img, \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset/tracking_mask.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nii_dataloader():\n",
    "    data_list = []\n",
    "\n",
    "    train_images_nii = join(VAL_DATA_PATH, 'train_images_nii')\n",
    "    tracking_mask_path = join(VAL_DATA_PATH, 'tracking_mask.nii.gz')\n",
    "    for file_name in listdir(train_images_nii):\n",
    "        complete_path = join(train_images_nii, file_name)\n",
    "        \n",
    "        data_list.append(\n",
    "            {\n",
    "                \"image\": complete_path,\n",
    "                \"tracking_mask\": tracking_mask_path},\n",
    "\n",
    "        )\n",
    "        if len(data_list)>=100:\n",
    "            break\n",
    "    transforms = Compose(\n",
    "        [   \n",
    "            # Load image \n",
    "            LoadImaged(keys=[\"image\", 'tracking_mask']),\n",
    "            EnsureChannelFirstd(keys=[\"image\", 'tracking_mask']),\n",
    "            # Normalize uint8 input\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0, b_max=1, clip=True),\n",
    "            ResizeWithPadOrCropd(keys=[\"image\"], spatial_size=PATCH_SIZE),\n",
    "            # Make a clean copy\n",
    "            # Copy the image tensor to a new key\n",
    "            CopyItemsd(keys=[\"image\"], times=1, names=[\"deform_patch\"]),\n",
    "\n",
    "            # Cut out 10 holes, each spatial size roughly 32x48x48\n",
    "            # 35% of data loss\n",
    "            RandCoarseDropoutd(\n",
    "                keys=[\"deform_patch\", 'tracking_mask'],\n",
    "                holes=10, \n",
    "                spatial_size=(32, 48, 48), \n",
    "                fill_value=0,\n",
    "                prob=1.0 # Always apply\n",
    "            ),\n",
    "            EnsureTyped(keys=[\"image\", \"deform_patch\", 'tracking_mask'], track_meta=False)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"Initializing Dataset...\")\n",
    "    val_ds = CacheDataset(\n",
    "        data=data_list, \n",
    "        transform=transforms, \n",
    "        cache_rate=1.0,  \n",
    "        num_workers=NUM_WORKERS, \n",
    "        progress=True\n",
    "    )\n",
    "    \n",
    "    print(\"Initializing DataLoader...\")\n",
    "    val_loader = monai.data.DataLoader(val_ds, batch_size=1, num_workers=NUM_WORKERS)\n",
    "    return val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca942610",
   "metadata": {},
   "source": [
    "# Test every step before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    try:\n",
    "        model = STUNetReconstruction()\n",
    "        state_dict = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.train()\n",
    "        model.cuda()\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model loading: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    try:\n",
    "        train_loader = get_zarr_dataloader()\n",
    "        temp_zarr_iterator = iter(train_loader)\n",
    "        one_batch = next(temp_zarr_iterator)\n",
    "        clean_patch = one_batch['clean_patch']\n",
    "        deform_patch = one_batch['deform_patch']\n",
    "        describe_tensor(\"clean_patch\", clean_patch)\n",
    "        describe_tensor(\"deform_patch\", deform_patch)\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with zarr data loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe9ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    try:\n",
    "        val_loader = get_nii_dataloader()\n",
    "        temp_nii_iterator = iter(val_loader)\n",
    "        one_batch = next(temp_nii_iterator)\n",
    "        clean_patch = one_batch['image']\n",
    "        describe_tensor(\"clean_patch\", clean_patch)\n",
    "        deform_patch = one_batch['deform_patch']\n",
    "        describe_tensor(\"deform_patch\", deform_patch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with nii data loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9795c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    epoch = 2\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    avg_loss = 2.0\n",
    "    save_path = join(MODEL_SAVE_PATH, f\"model_epoch_{epoch}.pth\")\n",
    "    \n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_weights': model.state_dict(),  # \n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_loss,\n",
    "        }, save_path)\n",
    "    print(f\"Saved checkpoint: {save_path}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriterionL1(nn.Module):\n",
    "    def __init__(self, mask_weight=10.0):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Computes L1 loss.\n",
    "        mask_weight: How much more we care about the masked region than the global image.\n",
    "                     Default 10.0 means masked region is ~10x more important.\n",
    "        \"\"\"\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mask_weight = mask_weight\n",
    "    \n",
    "    def forward(self, pred, target, dropout_mask):\n",
    "        # 1. Calculate absolute difference\n",
    "        l1_diff = torch.abs(pred - target)\n",
    "        \n",
    "        # 2. Masked Loss (The \"Hard\" Task)\n",
    "        # Apply mask (1 = hole/missing, 0 = visible)\n",
    "        masked_l1 = l1_diff * dropout_mask\n",
    "        \n",
    "        # Normalize by the number of masked pixels\n",
    "        # (Sum of L1 errors in mask / Count of masked pixels)\n",
    "        loss_masked = masked_l1.sum() / (dropout_mask.sum() + 1e-8)\n",
    "\n",
    "        # 3. Global Loss (The \"Stabilizer\")\n",
    "        # Calculates mean over the *entire* volume (masked + visible)\n",
    "        loss_global = self.l1_loss(pred, target)\n",
    "        \n",
    "        # 4. Combine\n",
    "        # Effectively: Loss = (1.0 * Masked) + (0.1 * Global)\n",
    "        total_loss = loss_masked + (loss_global / self.mask_weight)\n",
    "        \n",
    "        # No need to divide by 2 unless you have a specific learning rate reason\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __main__():\n",
    "    # Load model\n",
    "    model = STUNetReconstruction()\n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Load states if resume\n",
    "    if RESUME == None:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "        epoch = 0\n",
    "        val_loss = 10000\n",
    "        model = model.to(DEVICE)\n",
    "    else:\n",
    "        checkpoint = torch.load(RESUME, map_location=\"cpu\", weights_only=False) \n",
    "\n",
    "        epoch = checkpoint['epoch'] + 1 # To continue to the next epoch instead of repeating  \n",
    "        model_weights = checkpoint['model_weights']   # already reconstructed\n",
    "        model.load_state_dict(model_weights, strict=True)\n",
    "        val_loss = checkpoint['val_loss']\n",
    "\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        print(\"Model loaded correctly. Resuming training...\")\n",
    " \n",
    "    # Data loader\n",
    "    train_loader = get_zarr_dataloader()\n",
    "    val_loader = get_nii_dataloader()\n",
    "\n",
    "    # Loss\n",
    "    train_criterion = CriterionL1(mask_weight=MASK_WEIGHT) #nn.L1Loss() # Sharpness preference (Better for restoration)\n",
    "    val_criterion = CriterionL1(mask_weight=MASK_WEIGHT) #nn.L1Loss() # Using the same metric for evaluation\n",
    "\n",
    "    # Defining learning rate scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, NUM_EPOCHS, eta_min=0.0, last_epoch=-1)\n",
    "\n",
    "    # FP16 initialization \n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Start training loop\n",
    "    train_loop(\n",
    "        model=model, \n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        train_criterion=train_criterion, \n",
    "        val_criterion=val_criterion, \n",
    "        scheduler=scheduler, \n",
    "        scaler=scaler,\n",
    "        epoch=epoch,\n",
    "        val_loss=val_loss\n",
    "\n",
    "    )\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    __main__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d3b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d24b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9dfa72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
