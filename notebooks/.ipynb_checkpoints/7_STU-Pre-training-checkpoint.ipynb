{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95281584",
   "metadata": {},
   "source": [
    "# We will take the pre-trained STU-Net (Large -> Pre-trained on the TotalSegmentator cases) and further pre-train on the scrolls and fragments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c13800",
   "metadata": {},
   "source": [
    "## Convert tif into zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab80053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def convert_tiff_stack_to_zarr(tiff_folder, output_zarr_path, chunk_size=(128, 128, 128)):\n",
    "    # 1. Get file list (assuming sorted filenames correspond to Z-slices)\n",
    "    tiff_files = sorted(glob.glob(os.path.join(tiff_folder, \"*.tif\")))\n",
    "    \n",
    "    # 2. Read first slice to get dimensions and dtype\n",
    "    sample = tifffile.imread(tiff_files[0])\n",
    "    z, y, x = len(tiff_files), sample.shape[0], sample.shape[1]\n",
    "    dtype = sample.dtype\n",
    "    \n",
    "    print(f\"Volume shape: ({z}, {y}, {x}), Dtype: {dtype}\")\n",
    "\n",
    "    # 3. Create Zarr v3 store on disk\n",
    "    #    Using mode=\"w\" to overwrite\n",
    "    root = zarr.open(output_zarr_path, mode=\"w\")\n",
    "\n",
    "    # 4. Create array (v3 uses create_array instead of create_dataset)\n",
    "    dset = root.create_array(\n",
    "        name=\"volume\",\n",
    "        shape=(z, y, x),\n",
    "        chunks=chunk_size,\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "    # 5. Write slices\n",
    "    print(\"Converting...\")\n",
    "    for i, fname in tqdm(enumerate(tiff_files), total=z):\n",
    "        img_data = tifffile.imread(fname)\n",
    "        dset[i, :, :] = img_data\n",
    "\n",
    "    print(f\"Conversion complete! Saved to {output_zarr_path}\")\n",
    "\n",
    "# Example usage:\n",
    "#convert_tiff_stack_to_zarr(\n",
    "#    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Pre-training/example\",\n",
    "#    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Pre-training/data.zarr\"\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a77d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Update this path to where your TIFs are\n",
    "TIFF_FOLDER = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/notebooks/temp_raw_downloads\"\n",
    "\n",
    "# 1. Get the first file\n",
    "files = sorted(glob.glob(os.path.join(TIFF_FOLDER, \"*.tif\")))\n",
    "\n",
    "for file_name in files:\n",
    "    # 2. Read the image\n",
    "    img = tifffile.imread(file_name)\n",
    "    \n",
    "    if img.dtype!=\"uint16\":\n",
    "        # 3. Print stats\n",
    "        print(f\"--- File Analysis ---\")\n",
    "        print(f\"Filename: {os.path.basename(file_name)}\")\n",
    "        print(f\"Data Type (dtype): {img.dtype}\")\n",
    "        print(f\"Shape: {img.shape}\")\n",
    "        print(f\"Min Value: {np.min(img)}\")\n",
    "        print(f\"Max Value: {np.max(img)}\")\n",
    "    \n",
    "    # 4. Check for potential overflow\n",
    "    if np.max(img) > 65535:\n",
    "        print(\"\\n⚠️ WARNING: Max value exceeds 65535.\")\n",
    "        print(\"You MUST normalize (divide) this data before converting to float16.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f11b5",
   "metadata": {},
   "source": [
    "## Building the data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6c91f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset...\n",
      "zarr_path: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Pre-training/PHercParis4.zarr\n",
      "Try\n",
      "volume in root\n",
      "Initializing DataLoader...\n",
      "Fetching a batch to ensure it's not empty...\n",
      "Batch Max Value: 1.0\n",
      "Success! Loaded a non-empty chunk.\n",
      "Success! Batch shape: torch.Size([1, 1, 6, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import zarr\n",
    "import numpy as np\n",
    "import monai\n",
    "from monai.transforms import Compose, ScaleIntensity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import monai\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Compose, ScaleIntensity, EnsureType, \n",
    "    RandCoarseDropout, RandGaussianNoise\n",
    ")\n",
    "\n",
    "class ZarrVolumeDataset(Dataset):\n",
    "    def __init__(self, zarr_path, transform_input, transform_deform, transform_output, patch_size=(128, 128, 6), threshold=0.0):\n",
    "        self.zarr_path = zarr_path\n",
    "        self.transform_input = transform_input\n",
    "        self.transform_deform = transform_deform\n",
    "        self.transform_output = transform_output\n",
    "        self.patch_size = patch_size\n",
    "        self.threshold = threshold  # Value below which we consider the pixel \"background\"\n",
    "        print(f\"zarr_path: {zarr_path}\")\n",
    "        # --- Robust Zarr Loading ---\n",
    "        try:\n",
    "            root = zarr.open(zarr_path, mode='r')\n",
    "            print(\"Try\")\n",
    "        except:\n",
    "            store = zarr.storage.LocalStore(zarr_path, mode='r')\n",
    "            root = zarr.open(store, mode='r')\n",
    "            \n",
    "        if hasattr(root, 'shape'):\n",
    "            self.vol = root\n",
    "            self.shape = root.shape\n",
    "        elif 'volume' in root:\n",
    "            print('volume in root')\n",
    "            self.vol = root['volume']\n",
    "            self.shape = root['volume'].shape\n",
    "        elif '0' in root:\n",
    "            self.vol = root['0']\n",
    "            self.shape = root['0'].shape\n",
    "        else:\n",
    "            raise ValueError(\"Could not find volume data.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000 \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # We need to re-open the store inside the worker to be safe with multiprocessing\n",
    "        # However, for pure read, we can often rely on the self.vol reference if using threads.\n",
    "        # But to be 100% safe against \"Pickling\" errors, we re-reference:\n",
    "        vol = self.vol \n",
    "\n",
    "        z_max = max(0, self.shape[0] - self.patch_size[0])\n",
    "        y_max = max(0, self.shape[1] - self.patch_size[1])\n",
    "        x_max = max(0, self.shape[2] - self.patch_size[2])\n",
    "\n",
    "        # --- THE REJECTION SAMPLING LOOP ---\n",
    "        # Try up to 20 times to find a non-empty chunk\n",
    "        for attempt in range(100):\n",
    "            # 1. Random Coordinates\n",
    "            z_start = np.random.randint(0, z_max) if z_max > 0 else 0\n",
    "            y_start = np.random.randint(0, y_max) if y_max > 0 else 0\n",
    "            x_start = np.random.randint(0, x_max) if x_max > 0 else 0\n",
    "\n",
    "            # 2. Load the chunk\n",
    "            patch = vol[\n",
    "                z_start : z_start + self.patch_size[0],\n",
    "                y_start : y_start + self.patch_size[1],\n",
    "                x_start : x_start + self.patch_size[2]\n",
    "            ]\n",
    "\n",
    "            # 3. Check if it contains data\n",
    "            # If the max value in this patch is greater than our threshold (0), it's valid.\n",
    "            if np.max(patch) > self.threshold:\n",
    "                # Found valid data! Break the loop and process it.\n",
    "                break\n",
    "            \n",
    "            # If we are here, the patch was empty. The loop continues to the next attempt.\n",
    "        \n",
    "        # Note: If the loop finishes 20 times and finds nothing, it will return the LAST empty patch.\n",
    "        # This prevents the code from hanging forever if the file is truly empty.\n",
    "\n",
    "        # 4. MONAI Formatting\n",
    "        patch = patch.astype(np.float32) # Ensure float for transforms\n",
    "        patch = patch[np.newaxis, ...]   # Add Channel dim -> (1, Z, Y, X)\n",
    "        \n",
    "        #if self.transform:\n",
    "        patch = self.transform_input(patch)\n",
    "        clean_patch = patch.clone()\n",
    "        deform_patch = self.transform_deform(patch)\n",
    "        #patch = self.transform_output(patch)\n",
    "\n",
    "        return {\n",
    "            'clean_patch':clean_patch,\n",
    "            'deform_patch':deform_patch\n",
    "        }\n",
    "\n",
    "# --- Setup ---\n",
    "transform_input = Compose([\n",
    "    ScaleIntensity(),\n",
    "])\n",
    "\n",
    "# 1. The Dataset (Your existing Zarr code)\n",
    "# ds = ZarrVolumeDataset(...) \n",
    "# loader = DataLoader(ds, batch_size=4, ...)\n",
    "\n",
    "# 2. The Corruption Transforms (Applied ONLY to the Input)\n",
    "# We want to force the model to fix heavy defects.\n",
    "transform_deform = Compose([\n",
    "    # Cut out 1-10 holes, each spatial size roughly 16x16x2\n",
    "    RandCoarseDropout(\n",
    "        holes=10, \n",
    "        spatial_size=(2, 16, 16), # TODO change to 16\n",
    "        fill_value=0, # \n",
    "        prob=1.0 # Always apply\n",
    "    ),\n",
    "    # Add noise\n",
    "    #RandGaussianNoise(prob=0.5, mean=0.0, std=0.1),\n",
    "    EnsureType()\n",
    "])\n",
    "\n",
    "# --- Verification ---\n",
    "# MONAI Pipeline Setup\n",
    "train_transforms = Compose([\n",
    "    ScaleIntensity(),\n",
    "])\n",
    "\n",
    "print(\"Initializing Dataset...\")\n",
    "ds = ZarrVolumeDataset(\n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Pre-training/PHercParis4.zarr\", \n",
    "    transform_input=transform_input,\n",
    "    transform_deform=transform_deform,\n",
    "    transform_output=None,\n",
    "    patch_size=(6, 128, 128) \n",
    ")\n",
    "\n",
    "print(\"Initializing DataLoader...\")\n",
    "loader = monai.data.DataLoader(ds, batch_size=1, num_workers=4)\n",
    "data_loader = iter(loader)\n",
    "first_batch = next(data_loader)\n",
    "clean_patch = first_batch['clean_patch']\n",
    "deform_patch = first_batch['deform_patch']\n",
    "print(\"Fetching a batch to ensure it's not empty...\")\n",
    "\n",
    "print(f\"Batch Max Value: {clean_patch.max()}\")\n",
    "if clean_patch.max() == 0:\n",
    "    print(\"WARNING: The batch is still empty. Your threshold might be too high or the volume is empty.\")\n",
    "else:\n",
    "    print(\"Success! Loaded a non-empty chunk.\")\n",
    "\n",
    "\n",
    "print(f\"Success! Batch shape: {clean_patch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e851d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data_loader)\n",
    "clean_patch = first_batch['clean_patch']\n",
    "deform_patch = first_batch['deform_patch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1476980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: torch.Size([1, 1, 6, 128, 128])\n",
      "Visualizing Sample Shape: torch.Size([1, 1, 6, 128, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f890e4fa716441ca8140425de5eec843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='Slice', max=5), IntSlider(value=0, description='View Axi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 1. Extract the raw 3D volume from the batch\n",
    "# MONAI batch shape is (Batch_Size, Channel, Dim1, Dim2, Dim3)\n",
    "# We select Batch 0 and Channel 0\n",
    "input_data = deform_patch[0, 0].cpu().numpy()\n",
    "\n",
    "print(f\"Batch Shape: {clean_patch.shape}\")\n",
    "print(f\"Visualizing Sample Shape: {clean_patch.shape}\")\n",
    "\n",
    "# 2. Setup Interactive Viewer\n",
    "def view_batch_slice(slice_idx, axis):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    # Allow slicing along different axes to debug orientation\n",
    "    if axis == 0:\n",
    "        # Slicing the first dimension (usually Z if (Z, Y, X))\n",
    "        plt.imshow(input_data[slice_idx, :, :], cmap='gray')\n",
    "        plt.xlabel(\"Axis 2\")\n",
    "        plt.ylabel(\"Axis 1\")\n",
    "    elif axis == 1:\n",
    "        # Slicing the second dimension\n",
    "        plt.imshow(input_data[:, slice_idx, :], cmap='gray')\n",
    "        plt.xlabel(\"Axis 2\")\n",
    "        plt.ylabel(\"Axis 0\")\n",
    "    else:\n",
    "        # Slicing the third dimension\n",
    "        plt.imshow(input_data[:, :, slice_idx], cmap='gray')\n",
    "        plt.xlabel(\"Axis 1\")\n",
    "        plt.ylabel(\"Axis 0\")\n",
    "        \n",
    "    plt.title(f\"Slice {slice_idx} along Axis {axis}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Create Slider\n",
    "# We default to Axis 0, but you can change the axis variable below to 1 or 2\n",
    "axis_to_scroll = 0 \n",
    "\n",
    "interact(\n",
    "    view_batch_slice, \n",
    "    slice_idx=IntSlider(\n",
    "        min=0, \n",
    "        max=input_data.shape[axis_to_scroll]-1, \n",
    "        step=1, \n",
    "        value=input_data.shape[axis_to_scroll]//2,\n",
    "        description='Slice'\n",
    "    ),\n",
    "    axis=IntSlider(min=0, max=2, step=1, value=0, description='View Axis')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ab577",
   "metadata": {},
   "source": [
    "## Building the pre-training process\n",
    "* The technique will be simple masking (oclusion) and respective reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de913e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vesuvius)",
   "language": "python",
   "name": "vesuvius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
