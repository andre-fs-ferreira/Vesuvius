{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5136931",
   "metadata": {},
   "source": [
    "# Download data for pre-training. \n",
    "* Each scroll is veryyyyy large, so we need to do some pre-processing on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137bff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "\"\"\"\n",
    "# List of available scrolls:\n",
    "['https://dl.ash2txt.org/full-scrolls/Scroll2/PHercParis3.volpkg/volumes_masked/20230210143520/', \n",
    "'https://dl.ash2txt.org/full-scrolls/Scroll2/PHercParis3.volpkg/volumes_masked/20230212125146/',\n",
    "''\n",
    "]\n",
    "\"\"\"\n",
    "TARGET_URL = \"https://dl.ash2txt.org/full-scrolls/Scroll1/PHercParis4.volpkg/volumes_masked/20230205180739/\"\n",
    "DOWNLOAD_DIR = \"./temp_raw_downloads\"\n",
    "OUTPUT_DIR = \"../DataSet/Pre-training/cropped_output\"\n",
    "\n",
    "def get_tif_links(url):\n",
    "    \"\"\"Scrapes the directory for .tif files.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = [a['href'] for a in soup.find_all('a') if a['href'].endswith('.tif')]\n",
    "        return sorted(links)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching links: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81247b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(file_url, local_path):\n",
    "    \"\"\"Downloads a single file if it doesn't exist.\"\"\"\n",
    "    if os.path.exists(local_path):\n",
    "        return\n",
    "    \n",
    "    with requests.get(file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9950bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "def crop_foreground(tiff_path, bounds):\n",
    "\n",
    "    x_min = bounds['x_min']\n",
    "    x_max = bounds['x_max']\n",
    "    y_min = bounds['y_min']\n",
    "    y_max = bounds['y_max']\n",
    "    \n",
    "    # Load image\n",
    "    tiff_img = tifffile.imread(tiff_path)\n",
    "\n",
    "\n",
    "\n",
    "    # Crop\n",
    "    cropped = tiff_img[y_min:y_max+1, x_min:x_max+1]\n",
    "    return cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ee422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_sample_list(tif_files):\n",
    "    # Suppose tif_files is your list of file paths\n",
    "    n_samples = 100\n",
    "\n",
    "    # Handle case when there are fewer than 100 files\n",
    "    n_samples = min(n_samples, len(tif_files))\n",
    "\n",
    "    # Get 100 equally spaced indices\n",
    "    indices = np.linspace(0, len(tif_files)-1, n_samples, dtype=int)\n",
    "\n",
    "    # Select files\n",
    "    selected_files = [tif_files[i] for i in indices]\n",
    "    return selected_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4b8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_bounds(file_list):\n",
    "    \"\"\"\n",
    "    Iterates through 2D files to calculate the 3D bounding box \n",
    "    without loading the whole volume into RAM.\n",
    "    Implements your 'detect_deges_with_content' logic iteratively.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Scanning files to calculate Global Bounding Box ---\")\n",
    "    \n",
    "    # Initialize with inverted infinity to find min/max\n",
    "    min_x, max_x = float('inf'), float('-inf')\n",
    "    min_y, max_y = float('inf'), float('-inf')\n",
    "    min_z, max_z = float('inf'), float('-inf')\n",
    "    \n",
    "    has_data = False\n",
    "\n",
    "    for z_index, filename in enumerate(tqdm(file_list, desc=\"Scanning Geometry\")):\n",
    "        file_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "        \n",
    "        # Load 2D slice\n",
    "        img = tifffile.imread(file_path)\n",
    "        \n",
    "        # Check if slice has any data (Your Z-axis check)\n",
    "        if np.any(img > 0):\n",
    "            # Update Z bounds\n",
    "            if z_index < min_z: min_z = z_index\n",
    "            if z_index > max_z: max_z = z_index\n",
    "            \n",
    "            has_data = True\n",
    "            \n",
    "            # Check Y axis (Rows) for this slice\n",
    "            # np.any(img, axis=1) gives boolean array of rows containing data\n",
    "            y_indices = np.where(np.any(img > 0, axis=1))[0]\n",
    "            if len(y_indices) > 0:\n",
    "                current_y_min, current_y_max = y_indices[0], y_indices[-1]\n",
    "                min_y = min(min_y, current_y_min)\n",
    "                max_y = max(max_y, current_y_max)\n",
    "\n",
    "            # Check X axis (Cols) for this slice\n",
    "            # np.any(img, axis=0) gives boolean array of cols containing data\n",
    "            x_indices = np.where(np.any(img > 0, axis=0))[0]\n",
    "            if len(x_indices) > 0:\n",
    "                current_x_min, current_x_max = x_indices[0], x_indices[-1]\n",
    "                min_x = min(min_x, current_x_min)\n",
    "                max_x = max(max_x, current_x_max)\n",
    "\n",
    "    if not has_data:\n",
    "        return None\n",
    "\n",
    "    # Convert to integers\n",
    "    bounds = {\n",
    "        'x_min': int(min_x), 'x_max': int(max_x),\n",
    "        'y_min': int(min_y), 'y_max': int(max_y),\n",
    "        'z_min': int(min_z), 'z_max': int(max_z)\n",
    "    }\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb639e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9438a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching file list...\n",
      "Found 14376 files.\n",
      "Downloading files...\n",
      "\n",
      "Processing chunk 1/15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 3/1024 [00:22<2:09:24,  7.60s/it]"
     ]
    }
   ],
   "source": [
    "# 1. Setup\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# 2. Get File List\n",
    "print(\"Fetching file list...\")\n",
    "tif_files = get_tif_links(TARGET_URL)\n",
    "if not tif_files:\n",
    "    print(\"No files found.\")\n",
    "    exit()\n",
    "    \n",
    "print(f\"Found {len(tif_files)} files.\")\n",
    "\n",
    "# 3. Download (One by one), crop and store locally\n",
    "# We will divide by chunks of x, y, 1024 -> so we can still have volumes, a good representation of data and save disk space\n",
    "print(\"Downloading files...\")\n",
    "\n",
    "chunk_size = 1024\n",
    "\n",
    "chunk_list = [tif_files[i:i + chunk_size] for i in range(0, len(tif_files), chunk_size)]\n",
    "\n",
    "for chunk_idx, tif_files in enumerate(chunk_list):\n",
    "    print(f\"\\nProcessing chunk {chunk_idx+1}/{len(chunk_list)}...\")\n",
    "    OUTPUT_DIR_chunk = os.path.join(OUTPUT_DIR, f\"chunk_{chunk_idx}\")\n",
    "    os.makedirs(OUTPUT_DIR_chunk, exist_ok=True)\n",
    "    \n",
    "    for idx_z, f in enumerate(tqdm(tif_files, desc=\"Downloading\")):\n",
    "        url = urljoin(TARGET_URL, f)\n",
    "        path = os.path.join(DOWNLOAD_DIR, f)\n",
    "        download_file(url, path)\n",
    "  \n",
    "    # Calculate bounds\n",
    "    bounds = calculate_global_bounds(tif_files)\n",
    "    print(f\"Current bounds at slice {idx_z}: {bounds}\")\n",
    "    \n",
    "    for idx_z, f in enumerate(tqdm(tif_files, desc=\"Croping and Saving\")):\n",
    "        # crop edges without content, save and remove tmp file\n",
    "        path = os.path.join(DOWNLOAD_DIR, f)\n",
    "        cropped_numpy = crop_foreground(tiff_path=path, bounds=bounds)\n",
    "        output_path = os.path.join(OUTPUT_DIR_chunk, f)\n",
    "        tifffile.imwrite(output_path, cropped_numpy, compression='deflate')\n",
    "        os.remove(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea2dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8c25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43936c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
