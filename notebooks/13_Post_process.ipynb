{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a1d517",
   "metadata": {},
   "source": [
    "# Creating code for post processing the segmented sheets\n",
    "* Just gave up on second step segmentation\n",
    "* Let's try ideas from Gemini!\n",
    "    * apply_hysteresis_threshold (3D)\n",
    "    * binary_closing (2D)\n",
    "    * binary_fill_holes (2D)\n",
    "    * Invert and Filter (3D)\n",
    "* might be good to remove holes and modified Frangi filter that enhances surfaceness rather than vesselness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85aa03",
   "metadata": {},
   "source": [
    "### Create the object to run inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f75d8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageSequence\n",
    "import sys\n",
    "import os\n",
    "import tifffile\n",
    "sys.path.append(os.path.abspath(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/topological-metrics-kaggle/src\"))\n",
    "import topometrics.leaderboard\n",
    "import nibabel as nib\n",
    "\n",
    "case_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3545147380.tif\"\n",
    "\n",
    "numpy_array = tifffile.imread(case_path)\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/vol_3545147380.nii.gz\"\n",
    "nii_data = np.transpose(numpy_array, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "numpy_array = tifffile.imread(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\")\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/gt_3545147380.nii.gz\"\n",
    "nii_data = np.transpose(numpy_array, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "\n",
    "numpy_array = tifffile.imread(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3545147380.tif\")\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/pred_3545147380.nii.gz\"\n",
    "nii_data = np.transpose(numpy_array, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "ðŸš€ Starting inference on dataset: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "ðŸ“‹ Using the following configuration:\n",
      "  ðŸ”¹ architecture: STU-Net\n",
      "  ðŸ”¹ patch_size: [128, 128, 128]\n",
      "  ðŸ”¹ device: cuda\n",
      "  ðŸ”¹ batch_size: 1\n",
      "  ðŸ”¹ num_workers: 4\n",
      "  ðŸ”¹ infer_sw_batch_size: 1\n",
      "  ðŸ”¹ blend_mode: gaussian\n",
      "  ðŸ”¹ deep_supervision: False\n",
      "  ðŸ”¹ activation: False\n",
      "  ðŸ”¹ infer_overlap: 0.5\n",
      "  ðŸ”¹ TTA: True\n",
      "  ðŸ”¹ TH: 0.5\n",
      "  ðŸ”¹ checkpoint_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "  ðŸ”¹ dataset_path_imgs: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "  ðŸ”¹ pred_save_dir: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from infer_class import VesuviusInferer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/topological-metrics-kaggle/src\"))\n",
    "from torch.nn.functional import sigmoid\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageSequence\n",
    "import sys\n",
    "import os\n",
    "import tifffile\n",
    "\n",
    "config_content = {\n",
    "  \"architecture\": \"STU-Net\",\n",
    "  \"patch_size\": [128, 128, 128],\n",
    "  \"device\": \"cuda\",\n",
    "  \"batch_size\": 1,\n",
    "  \"num_workers\": 4,\n",
    "\n",
    "  \"infer_sw_batch_size\": 1,\n",
    "  \"blend_mode\": \"gaussian\",\n",
    "  \"deep_supervision\": False,\n",
    "  \"activation\": False,\n",
    "\n",
    "  \"infer_overlap\": 0.5,\n",
    "  \"TTA\": True,\n",
    "  \"TH\": 0.5,\n",
    "\n",
    "  \"checkpoint_path\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\", \n",
    "  \"dataset_path_imgs\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\",\n",
    "  \"pred_save_dir\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\"\n",
    "}\n",
    "\n",
    "\n",
    "# ðŸ§ª Initialize Inference Object\n",
    "infer_object = VesuviusInferer(config_content)\n",
    "\n",
    "print(f\"ðŸš€ Starting inference on dataset: {config_content['dataset_path_imgs']}\")\n",
    "print(\"ðŸ“‹ Using the following configuration:\")\n",
    "for key, value in config_content.items():\n",
    "    print(f\"  ðŸ”¹ {key}: {value}\")\n",
    "\n",
    "\n",
    "### Select manually a case to run!\n",
    "input_data = {\n",
    "    'image': str(case_path),\n",
    "    'gt': None\n",
    "}\n",
    "\n",
    "logits_pred, pred_list = infer_object.infer(\n",
    "    input=input_data, \n",
    "    test=True, \n",
    "    threshold_list=[0.5] # CHANGED FROM 0.5\n",
    ")\n",
    "infer_object.save_nifti(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/2536049117.nii.gz\", \n",
    "    real_file=None\n",
    ")\n",
    "\n",
    "infer_object.save_tiff(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/2536049117.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68a4388",
   "metadata": {},
   "source": [
    "### Create object for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfda1eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\"\\npred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2536049117.tif\"\\n\\n\\n\\noutput_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_2536049117.tif\"\\n\\nfinal_volume = split_by_object(pred_path, output_path)\\n\\nscore_report = score_single_tif(\\n    gt_path=gt_path,\\n    pred_path=pred_path,\\n    surface_tolerance=2.0,\\n    voi_connectivity=26,\\n    voi_transform=\\'one_over_one_plus\\',\\n    voi_alpha=0.3,\\n    topo_weight=0.3,\\n    surface_dice_weight=0.35,\\n    voi_weight=0.35,\\n)\\nprint(pred_path)\\nscore_report'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/topological-metrics-kaggle/src\"))\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageSequence\n",
    "import topometrics.leaderboard\n",
    "\n",
    "def score_single_tif(\n",
    "    gt_path,\n",
    "    pred_path,\n",
    "    surface_tolerance,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    "    ):\n",
    "    gt: np.ndarray = load_volume(gt_path)\n",
    "    pr: np.ndarray = load_volume(pred_path)\n",
    "\n",
    "    #install_dependencies()\n",
    "    # The import is here to ensure dependencies are loaded first.\n",
    "    try:\n",
    "        # Use a standard import now that the path is reliably set.\n",
    "        import topometrics.leaderboard\n",
    "    except Exception as err:\n",
    "        raise HostVisibleError(f'Failed to import topometrics after installation: {err}')\n",
    "\n",
    "    score_report = topometrics.leaderboard.compute_leaderboard_score(\n",
    "        predictions=pr,\n",
    "        labels=gt,\n",
    "        dims=(0, 1, 2),\n",
    "        spacing=(1.0, 1.0, 1.0),  # (z, y, x)\n",
    "        surface_tolerance=surface_tolerance,  # in spacing units\n",
    "        voi_connectivity=voi_connectivity,\n",
    "        voi_transform=voi_transform,\n",
    "        voi_alpha=voi_alpha,\n",
    "        combine_weights=(topo_weight, surface_dice_weight, voi_weight),  # (Topo, SurfaceDice, VOI)\n",
    "        fg_threshold=None,  # None => legacy \"!= 0\"; else uses \"x > threshold\"\n",
    "        ignore_label=2,  # voxels with this GT label are ignored\n",
    "        ignore_mask=None,  # or pass an explicit boolean mask\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'image_score': np.clip(score_report.score, 0.0, 1.0),\n",
    "        'topo_score': score_report.topo.toposcore,\n",
    "        'surface_dice': score_report.surface_dice,\n",
    "        'voi_score': score_report.voi.voi_score,\n",
    "        'voi_split': score_report.voi.voi_split,\n",
    "        'voi_merge': score_report.voi.voi_merge\n",
    "    }\n",
    "\n",
    "def load_volume(path):\n",
    "    im = Image.open(path)\n",
    "    slices = []\n",
    "    for i, page in enumerate(ImageSequence.Iterator(im)):\n",
    "        slice_array = np.array(page)\n",
    "        slices.append(slice_array)\n",
    "    volume = np.stack(slices, axis=0)\n",
    "    return volume #(z,y,x)\n",
    "\n",
    "\"\"\"gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\"\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2536049117.tif\"\n",
    "\n",
    "\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_2536049117.tif\"\n",
    "\n",
    "final_volume = split_by_object(pred_path, output_path)\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77cde3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.3875621574520175),\n",
       " 'topo_score': 0.04236180904522613,\n",
       " 'surface_dice': 0.3972573748403367,\n",
       " 'voi_score': 0.6737529529838052,\n",
       " 'voi_split': 0.7607155566923927,\n",
       " 'voi_merge': 0.8533629447888303}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CESoftDiceclDiceLoss_step3_DAsafe/model_epoch_Final\n",
    "{'image_score': np.float64(0.3789896346704825),\n",
    " 'topo_score': 0.053815470880591305,\n",
    " 'surface_dice': 0.4147439170596602,\n",
    " 'voi_score': 0.6219560641012114,\n",
    " 'voi_split': 1.078506929732625,\n",
    " 'voi_merge': 0.9475951146569563}\n",
    "\n",
    "# CESoftDiceclDiceLoss_step2_DAsafe/model_epoch_Final\n",
    "{'image_score': np.float64(0.4170240898070778),\n",
    " 'topo_score': 0.014990347490347491,\n",
    " 'surface_dice': 0.43251531692557793,\n",
    " 'voi_score': 0.7461332132457749,\n",
    " 'voi_split': 0.2754663703842506,\n",
    " 'voi_merge': 0.858677784428142}\n",
    "\n",
    "# Real results of th 0.5 (no post-processing) -> Model before (BCE_Tversky_DAsafe/model_epoch_160.pth)\n",
    "{'image_score': np.float64(0.3875621574520175),\n",
    " 'topo_score': 0.04236180904522613,\n",
    " 'surface_dice': 0.3972573748403367,\n",
    " 'voi_score': 0.6737529529838052,\n",
    " 'voi_split': 0.7607155566923927,\n",
    " 'voi_merge': 0.8533629447888303}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8e96d",
   "metadata": {},
   "source": [
    "### Select each individual object, and remove bellow threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77665a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.measure import label\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def split_by_object(input_path, output_path):\n",
    "    print(\"Loading image...\")\n",
    "    volume = tifffile.imread(input_path)\n",
    "\n",
    "    # Ensure the volume is treated as a binary mask for labeling\n",
    "    # (This assumes all objects you want to separate are non-zero)\n",
    "    binary_mask = volume > 0\n",
    "\n",
    "    # 2. Perform Connected Component Labeling\n",
    "    # connectivity=None defaults to allowing diagonal connections. \n",
    "    # Use connectivity=1 for strict face-to-face connections only.\n",
    "    labeled_volume = label(binary_mask, connectivity=None)\n",
    "\n",
    "    # 3. Optimize Data Type to save space\n",
    "    # We check how many objects were found to choose the smallest file size possible.\n",
    "    num_features = np.max(labeled_volume)\n",
    "    if num_features < 255:\n",
    "        final_volume = labeled_volume.astype(np.uint8)\n",
    "    elif num_features < 65535:\n",
    "        final_volume = labeled_volume.astype(np.uint16)\n",
    "    else:\n",
    "        final_volume = labeled_volume.astype(np.uint32)\n",
    "\n",
    "    # 4. Save the new TIFF\n",
    "    print(f\"Saving to {output_path}\")\n",
    "    tifffile.imwrite(output_path, final_volume)\n",
    "\n",
    "    nii_data = np.transpose(binary_mask, (2, 1, 0)).astype(np.uint16)\n",
    "    nii_data = np.flip(nii_data, axis=0) \n",
    "    nii_data = np.flip(nii_data, axis=1)\n",
    "    output_path_nii = output_path.replace('.tif', '_B.nii.gz')\n",
    "    nib.save(nib.Nifti1Image(nii_data.astype(np.uint16), np.eye(4)), output_path_nii)\n",
    "\n",
    "    nii_data = np.transpose(final_volume, (2, 1, 0)).astype(np.uint16)\n",
    "    nii_data = np.flip(nii_data, axis=0) \n",
    "    nii_data = np.flip(nii_data, axis=1)\n",
    "    output_path_nii = output_path.replace('.tif', '.nii.gz')\n",
    "    nib.save(nib.Nifti1Image(nii_data.astype(np.uint16), np.eye(4)), output_path_nii)\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return final_volume\n",
    "\n",
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/2536049117.tif\"\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_2536049117.tif\"\n",
    "\n",
    "#final_volume = split_by_object(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54ac59",
   "metadata": {},
   "source": [
    "* A lot of small segmentations without any connection. Removing those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e609a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.measure import label\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def split_by_object_np(binary_mask):\n",
    "    # Ensure the volume is treated as a binary mask for labeling\n",
    "    # (This assumes all objects you want to separate are non-zero)\n",
    "    binary_mask = binary_mask > 0\n",
    "\n",
    "    # 2. Perform Connected Component Labeling\n",
    "    # connectivity=None defaults to allowing diagonal connections. \n",
    "    # Use connectivity=1 for strict face-to-face connections only.\n",
    "    labeled_volume = label(binary_mask, connectivity=None)\n",
    "\n",
    "    # 3. Optimize Data Type to save space\n",
    "    # We check how many objects were found to choose the smallest file size possible.\n",
    "    num_features = np.max(labeled_volume)\n",
    "    if num_features < 255:\n",
    "        final_volume = labeled_volume.astype(np.uint8)\n",
    "    elif num_features < 65535:\n",
    "        final_volume = labeled_volume.astype(np.uint16)\n",
    "    else:\n",
    "        final_volume = labeled_volume.astype(np.uint32)\n",
    "    return final_volume\n",
    "\n",
    "def remove_bellow_th(input_path, th, output_path):\n",
    "    binary_mask = tifffile.imread(input_path)\n",
    "    labeled_volume = split_by_object_np(binary_mask) \n",
    "    \n",
    "    # 3. Remove Small Objects\n",
    "    # connectivity=1 ensures we stick to the same face-to-face logic as before\n",
    "    print(f\"Removing objects smaller than {th} voxels...\")\n",
    "    filtered_volume = remove_small_objects(labeled_volume, min_size=th, connectivity=1)\n",
    "\n",
    "    # Note: remove_small_objects might return a boolean if the input was boolean. \n",
    "    # We ensure it stays labeled by multiplying by the original labels (masking).\n",
    "    if filtered_volume.dtype == bool:\n",
    "        filtered_volume =  label(filtered_volume)\n",
    "    num_features  = np.unique(filtered_volume)\n",
    "    print(f\"After filtering, count: {len(num_features)} elements.\")\n",
    "    if output_path!=None:\n",
    "        # 4. Save\n",
    "        print(f\"Saving to {output_path}\")\n",
    "        tifffile.imwrite(output_path, filtered_volume.astype(np.uint16)) # categorical label\n",
    "\n",
    "        # Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "        output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "        nii_data = np.transpose(filtered_volume, (2, 1, 0)).astype(np.uint16)\n",
    "        nii_data = np.flip(nii_data, axis=0) \n",
    "        nii_data = np.flip(nii_data, axis=1)\n",
    "        nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "        nii_data[nii_data>0.5] = 1 \n",
    "        output_path_nii = f\"{output_path.replace('.tif', '_B.nii.gz')}\"\n",
    "        nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "        filtered_volume_b = np.zeros_like(filtered_volume)\n",
    "        filtered_volume_b[filtered_volume>0.5] = 1\n",
    "        output_path = f\"{output_path.replace('.tif', '_B.tif')}\"\n",
    "        tifffile.imwrite(f\"{output_path}\", filtered_volume_b.astype(np.uint16))\n",
    "\n",
    "        diff_vol = (labeled_volume-filtered_volume).astype(np.uint16)\n",
    "        nii_data = np.transpose(diff_vol, (2, 1, 0)).astype(np.uint16)\n",
    "        nii_data = np.flip(nii_data, axis=0) \n",
    "        nii_data = np.flip(nii_data, axis=1)\n",
    "        output_path_nii = f\"{output_path.replace('_B.tif', '_diff.nii.gz')}\"\n",
    "        nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "    print(\"Done.\")\n",
    "    return filtered_volume, filtered_volume_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcfe968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 58 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 20 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117_B.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.608705707343169),\n",
       " 'topo_score': 0.1467789258834035,\n",
       " 'surface_dice': 0.951426136804701,\n",
       " 'voi_score': 0.6619225191328646,\n",
       " 'voi_split': 0.8073663566711468,\n",
       " 'voi_merge': 0.8951364342900751}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_volume_th = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/2536049117.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\")\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117_B.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71077bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'image_score': np.float64(0.6051958352815727),\n",
    " 'topo_score': 0.1349917081260365,\n",
    " 'surface_dice': 0.9515386536493884,\n",
    " 'voi_score': 0.6618851259042164,\n",
    " 'voi_split': 0.807663674979235,\n",
    " 'voi_merge': 0.8951236157603629}\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'image_score': np.float64(0.4169773941561092),\n",
    " 'topo_score': 0.015107769885926884, #(a bit better)\n",
    " 'surface_dice': 0.43201433613258, #(a bit worst)\n",
    " 'voi_score': 0.7464001301255088, #(a bit better)\n",
    " 'voi_split': 0.2738130046588314,\n",
    " 'voi_merge': 0.8587335551059598}\n",
    "\n",
    "# Removing small objects reduce slightly the topo_score and voi_score, increase sligthly the dice, (OLD)\n",
    "original_results = {'image_score': np.float64(0.3875621574520175),\n",
    " 'topo_score': 0.04236180904522613,\n",
    " 'surface_dice': 0.3972573748403367,\n",
    " 'voi_score': 0.6737529529838052,\n",
    " 'voi_split': 0.7607155566923927,\n",
    " 'voi_merge': 0.8533629447888303}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a598b",
   "metadata": {},
   "source": [
    "### Remove the corners (check if the noise created there produces such bad results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c9a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/corner_removed_small_2536049117.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.7006303641862162),\n",
       " 'topo_score': 0.5044776119402985,\n",
       " 'surface_dice': 0.9172864259190723,\n",
       " 'voi_score': 0.6521052329498606,\n",
       " 'voi_split': 0.8894989436585066,\n",
       " 'voi_merge': 0.8888171392452924}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_borders(volume, thickness=5):\n",
    "    # Create a copy to avoid modifying the original if needed\n",
    "    cleaned = volume.copy()\n",
    "    \n",
    "    # Zero out the faces of the 3D cube\n",
    "    cleaned[:thickness, :, :] = 0  # Top\n",
    "    cleaned[-thickness:, :, :] = 0 # Bottom\n",
    "    cleaned[:, :thickness, :] = 0  # Front\n",
    "    cleaned[:, -thickness:, :] = 0 # Back\n",
    "    cleaned[:, :, :thickness] = 0  # Left\n",
    "    cleaned[:, :, -thickness:] = 0 # Right\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "binary_pred_here = prob_pred>0.5\n",
    "binary_pred_here = mask_borders(binary_pred_here, thickness=15)\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/corner_removed_small_2536049117.tif\"\n",
    "tifffile.imwrite(output_path, binary_pred_here.astype(np.uint16)) # categorical label\n",
    "\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/corner_removed_small_2536049117.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64980d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_corner_removed_small_2536049117.tif\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/corner_removed_small_2536049117.tif\"\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_corner_removed_small_2536049117.tif\"\n",
    "\n",
    "final_volume = split_by_object(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_borders(binary_pred_here, thickness=3)\n",
    "{'image_score': np.float64(0.6075685870946677),\n",
    " 'topo_score': 0.14337035751475186,\n",
    " 'surface_dice': 0.951139313542954,\n",
    " 'voi_score': 0.6618820574291663,\n",
    " 'voi_split': 0.8086779664586242,\n",
    " 'voi_merge': 0.8941326716588209}\n",
    "\n",
    "# mask_borders(binary_pred_here, thickness=5)\n",
    "{'image_score': np.float64(0.620543871998595),\n",
    " 'topo_score': 0.1851451091731234,\n",
    " 'surface_dice': 0.9537665060204878,\n",
    " 'voi_score': 0.6605201775413919,\n",
    " 'voi_split': 0.8216025117197475,\n",
    " 'voi_merge': 0.8915917958446843}\n",
    "\n",
    "# mask_borders(binary_pred_here, thickness=7)\n",
    "{'image_score': np.float64(0.6478875382507037),\n",
    " 'topo_score': 0.28624269954574955,\n",
    " 'surface_dice': 0.946833278770648,\n",
    " 'voi_score': 0.6589230880492913,\n",
    " 'voi_split': 0.8350876632402718,\n",
    " 'voi_merge': 0.8903383545389787}\n",
    "\n",
    "# mask_borders(binary_pred_here, thickness=9)\n",
    "{'image_score': np.float64(0.6922823126894415),\n",
    " 'topo_score': 0.44346399868787933,\n",
    " 'surface_dice': 0.9405331110012576,\n",
    " 'voi_score': 0.6573043549503931,\n",
    " 'voi_split': 0.8483567493287503,\n",
    " 'voi_merge': 0.8895273955560556}\n",
    "\n",
    "# mask_borders(binary_pred_here, thickness=12)\n",
    "{'image_score': np.float64(0.7046475944805687),\n",
    " 'topo_score': 0.4997539773659177,\n",
    " 'surface_dice': 0.93010923173767,\n",
    " 'voi_score': 0.6548090576074538,\n",
    " 'voi_split': 0.8684439641439806,\n",
    " 'voi_merge': 0.8887651967158658}\n",
    "\n",
    "# mask_borders(binary_pred_here, thickness=15)\n",
    "{'image_score': np.float64(0.7006303641862162),\n",
    " 'topo_score': 0.5044776119402985,\n",
    " 'surface_dice': 0.9172864259190723,\n",
    " 'voi_score': 0.6521052329498606,\n",
    " 'voi_split': 0.8894989436585066,\n",
    " 'voi_merge': 0.8888171392452924}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b0673",
   "metadata": {},
   "source": [
    "### Try to fill the holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad4f3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\n",
      "Done!\n",
      "Closing with ball radius 6...\n",
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_rm_holes_2536049117.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_rm_holes_2536049117.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.7142958290213111),\n",
       " 'topo_score': 0.5701492537313433,\n",
       " 'surface_dice': 0.9049234867129121,\n",
       " 'voi_score': 0.6472223787211105,\n",
       " 'voi_split': 0.9000569239982591,\n",
       " 'voi_merge': 0.9168230896170828}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import morphology \n",
    "from scipy import ndimage\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "binary_pred_here = prob_pred>0.5\n",
    "\n",
    "# Removing the small objects\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\"\n",
    "tifffile.imwrite(output_path, binary_pred_here.astype(np.uint16)) # categorical label\n",
    "_ = split_by_object(input_path, output_path)\n",
    "\n",
    "rm_small_2536049117 = load_volume(output_path)\n",
    "\n",
    "# FILL HOLES (Keep this to fix internal bubbles, but don't rely on it for rips)\n",
    "mask_holes_filled = morphology.remove_small_holes(\n",
    "    rm_small_2536049117.astype(bool), \n",
    "    area_threshold=1000\n",
    ")\n",
    "\n",
    "# 2. ROBUST BINARY CLOSING\n",
    "# Switch from a 'cross' to a 'ball' to fill diagonal gaps and round holes better.\n",
    "# Radius 2 closes gaps ~4 pixels wide. Radius 3 closes gaps ~6 pixels wide.\n",
    "closing_radius = 6\n",
    "structure_close = morphology.ball(closing_radius)\n",
    "\n",
    "print(f\"Closing with ball radius {closing_radius}...\")\n",
    "mask_closed = ndimage.binary_closing(\n",
    "    mask_holes_filled, \n",
    "    structure=structure_close, \n",
    "    iterations=1 # Keep iterations low, rely on radius instead for shape control\n",
    ")\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_holes_2536049117.tif\"\n",
    "tifffile.imwrite(output_path, mask_closed.astype(np.uint16)) # categorical label\n",
    "\n",
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_holes_2536049117.tif\"\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_rm_holes_2536049117.tif\"\n",
    "\n",
    "final_volume = split_by_object(input_path, output_path)\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_holes_2536049117.tif\",\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(output_path)\n",
    "score_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 20 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_small_2536049117.tif\n",
      "Done.\n",
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_filled_holes_2536049117.tif\n",
      "Done!\n",
      "Loading categorical volume...\n",
      "finding objects...\n",
      "Processing 19 objects with Bounding Box optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:02<02:05, 10.47s/it]"
     ]
    }
   ],
   "source": [
    "from skimage import morphology \n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "binary_pred_here = prob_pred>0.5\n",
    "\n",
    "# Removing the small objects\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_small_2536049117.tif\"\n",
    "tifffile.imwrite(output_path, binary_pred_here.astype(np.uint16)) # categorical label\n",
    "_ = remove_bellow_th(input_path=output_path, th=1000, output_path=output_path)\n",
    "\n",
    "rm_small_2536049117 = load_volume(output_path)\n",
    "\n",
    "# FILL HOLES (Keep this to fix internal bubbles, but don't rely on it for rips)\n",
    "mask_holes_filled = morphology.remove_small_holes(\n",
    "    rm_small_2536049117.astype(bool), \n",
    "    area_threshold=1000\n",
    ")\n",
    "\n",
    "# 2. SPLIT BY OBJECT (Create Categorical Volume)\n",
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/filled_holes_2536049117.tif\"\n",
    "categorical_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_filled_holes_2536049117.tif\" \n",
    "\n",
    "# Save intermediate if needed for split_by_object\n",
    "tifffile.imwrite(input_path, mask_holes_filled.astype(np.uint16))\n",
    "_ = split_by_object(input_path, categorical_path)\n",
    "\n",
    "# ==========================================\n",
    "# 3. FAST PER-LABEL CLOSING (Bounding Box Optimization)\n",
    "# ==========================================\n",
    "\n",
    "print(\"Loading categorical volume...\")\n",
    "categorical_vol = tifffile.imread(categorical_path)\n",
    "\n",
    "# Setup: Radius 12 is VERY large (diameter ~25). \n",
    "# This requires significant padding to avoid edge artifacts.\n",
    "closing_radius = 7\n",
    "structure_close = morphology.ball(closing_radius)\n",
    "\n",
    "print(f\"finding objects...\")\n",
    "# find_objects returns a list of slices (bounding boxes) for labels 1, 2, 3...\n",
    "# This is the key to the speedup.\n",
    "object_slices = ndimage.find_objects(categorical_vol)\n",
    "\n",
    "final_closed_vol = np.zeros_like(categorical_vol)\n",
    "\n",
    "print(f\"Processing {len(object_slices)} objects with Bounding Box optimization...\")\n",
    "\n",
    "for idx, sl in enumerate(tqdm(object_slices)):\n",
    "    if sl is None: continue # Label was skipped/missing\n",
    "    \n",
    "    label_id = idx + 1\n",
    "    \n",
    "    # A. EXPAND SLICE (PADDING)\n",
    "    # We must pad the bounding box by the closing radius, otherwise\n",
    "    # the closing operation will hit the edge of the crop and fail.\n",
    "    z_sl, y_sl, x_sl = sl\n",
    "    \n",
    "    # Pad and clip to volume boundaries\n",
    "    z_min = max(0, z_sl.start - closing_radius)\n",
    "    z_max = min(categorical_vol.shape[0], z_sl.stop + closing_radius)\n",
    "    y_min = max(0, y_sl.start - closing_radius)\n",
    "    y_max = min(categorical_vol.shape[1], y_sl.stop + closing_radius)\n",
    "    x_min = max(0, x_sl.start - closing_radius)\n",
    "    x_max = min(categorical_vol.shape[2], x_sl.stop + closing_radius)\n",
    "    \n",
    "    padded_slice = (slice(z_min, z_max), slice(y_min, y_max), slice(x_min, x_max))\n",
    "    \n",
    "    # B. CROP\n",
    "    vol_crop = categorical_vol[padded_slice]\n",
    "    obj_mask_crop = (vol_crop == label_id)\n",
    "    \n",
    "    # C. CLOSE (Fast because volume is small)\n",
    "    obj_closed_crop = ndimage.binary_closing(\n",
    "        obj_mask_crop, \n",
    "        structure=structure_close, \n",
    "        iterations=1\n",
    "    )\n",
    "    \n",
    "    # D. PASTE BACK\n",
    "    # We only update the specific region in the final volume\n",
    "    # Use simple boolean indexing on the crop\n",
    "    \n",
    "    # Get the current crop from the final volume to handle overlaps safely\n",
    "    final_crop = final_closed_vol[padded_slice]\n",
    "    \n",
    "    # \"Last label wins\" strategy (simple overwrite)\n",
    "    # Only write where we actually have a closed object\n",
    "    final_crop[obj_closed_crop] = label_id\n",
    "    \n",
    "    # Assign back to main volume\n",
    "    final_closed_vol[padded_slice] = final_crop\n",
    "\n",
    "# ==========================================\n",
    "# 4. SAVE AND SCORE\n",
    "# ==========================================\n",
    "\n",
    "output_path_final = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/rm_holes_2536049117.tif\"\n",
    "tifffile.imwrite(output_path_final, final_closed_vol.astype(np.uint16))\n",
    "print(f\"Saved closed volume to: {output_path_final}\")\n",
    "\n",
    "_ = split_by_object(output_path_final, \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_4/categorical_rm_holes_2536049117.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=output_path_final,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c4d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 112 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 24 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_1013184726.tif\n",
      "Done.\n",
      "Labeling individual elements...\n",
      "Found 54 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 24 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\n",
      "Done.\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 23 elements.\n",
      "Found 23 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5322698397359252),\n",
       " 'topo_score': 0.2670856245090338,\n",
       " 'surface_dice': 0.7428282548700696,\n",
       " 'voi_score': 0.5490121805105447,\n",
       " 'voi_split': 1.6716041120374625,\n",
       " 'voi_merge': 1.0665732636148524}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage import generate_binary_structure, binary_opening\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1013184726.tif\"\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1013184726.tif\"\n",
    "binary_pred_here = load_volume(pred_path)\n",
    "\n",
    "# Removing the small objects\n",
    "rm_small_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_1013184726.tif\"\n",
    "tifffile.imwrite(rm_small_path, binary_pred_here.astype(np.uint16)) # categorical label\n",
    "filtered_volume, filtered_volume_b = remove_bellow_th(\n",
    "    input_path=rm_small_path, \n",
    "    th=1000, \n",
    "    output_path=rm_small_path)\n",
    "\n",
    "rm_small_path_B = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_1013184726_B.tif\"\n",
    "\n",
    "# Binary opening\n",
    "rm_bridges = binary_opening(filtered_volume_b, structure=np.ones((3,1,3)))\n",
    "rm_bridges_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_bridges_1013184726.tif\"\n",
    "tifffile.imwrite(rm_bridges_path, rm_bridges.astype(np.uint16)) # categorical label\n",
    "\n",
    "rm_bridges_rm_small_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\"\n",
    "filtered_volume, filtered_volume_b = remove_bellow_th(\n",
    "    input_path=rm_bridges_path, \n",
    "    th=1000, \n",
    "    output_path=rm_bridges_rm_small_path)\n",
    "\n",
    "rm_bridges_rm_small_path_B = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726_B.tif\"\n",
    "\n",
    "# Save intermediate if needed for split_by_object\n",
    "_ = split_by_object(rm_bridges_rm_small_path_B, rm_bridges_rm_small_path)\n",
    "print(rm_bridges_rm_small_path.replace('.tif', '.nii.gz'))\n",
    "\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=rm_bridges_rm_small_path_B,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60ed7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_opening\n",
    "\n",
    "def erode_2d(vol, s):\n",
    "    # assume shape = (z, y, x)\n",
    "    # xy-plane\n",
    "    vol_xy = np.stack([binary_opening(vol[i, :, :], structure=np.ones((s, s))) for i in range(vol.shape[0])], axis=0)\n",
    "\n",
    "    # xz-plane\n",
    "    vol_xz = np.stack([binary_opening(vol[:, j, :], structure=np.ones((s, s))) for j in range(vol.shape[1])], axis=1)\n",
    "\n",
    "    # yz-plane\n",
    "    vol_yz = np.stack([binary_opening(vol[:, :, k], structure=np.ones((s, s))) for k in range(vol.shape[2])], axis=2)\n",
    "\n",
    "    # combine results\n",
    "    rm_bridges = vol_xy | vol_xz | vol_yz\n",
    "    return rm_bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df099ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 50 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 23 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\n",
      "Done.\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 22 elements.\n",
      "Found 22 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5367764802419565),\n",
       " 'topo_score': 0.2819237147595357,\n",
       " 'surface_dice': 0.7427706250347151,\n",
       " 'voi_score': 0.5492275630055584,\n",
       " 'voi_split': 1.6704664476229587,\n",
       " 'voi_merge': 1.0653299529780524}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_small_path_B = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_1013184726_B.tif\"\n",
    "rm_bridges=erode_2d(vol=load_volume(rm_small_path_B), s=3)\n",
    "rm_bridges_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_bridges_1013184726.tif\"\n",
    "tifffile.imwrite(rm_bridges_path, rm_bridges.astype(np.uint16)) # categorical label\n",
    "\n",
    "rm_bridges_rm_small_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726.tif\"\n",
    "filtered_volume, filtered_volume_b = remove_bellow_th(\n",
    "    input_path=rm_bridges_path, \n",
    "    th=1000, \n",
    "    output_path=rm_bridges_rm_small_path)\n",
    "\n",
    "rm_bridges_rm_small_path_B = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_bridges_1013184726_B.tif\"\n",
    "\n",
    "_ = split_by_object(rm_bridges_rm_small_path_B, rm_bridges_rm_small_path)\n",
    "print(rm_bridges_rm_small_path.replace('.tif', '.nii.gz'))\n",
    "\n",
    "\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=rm_bridges_rm_small_path_B,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n",
    "\n",
    "# erosion (3) -> 22 elements\n",
    "# erosion (5) -> 38 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64072c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "{'image_score': np.float64(0.4882821996410088),\n",
    " 'topo_score': 0.12257552815631985,\n",
    " 'surface_dice': 0.7409740257701427,\n",
    " 'voi_score': 0.5490532347844651,\n",
    " 'voi_split': 1.675570628474354,\n",
    " 'voi_merge': 1.0621527630322238}\n",
    "\n",
    "# in the next cell (2D erosion and 3D fill holes)\n",
    "{'image_score': np.float64(0.5193702573700877),\n",
    " 'topo_score': 0.27159974774017237,\n",
    " 'surface_dice': 0.7009397715603349,\n",
    " 'voi_score': 0.5501754657197676,\n",
    " 'voi_split': 1.6384501603188388,\n",
    " 'voi_merge': 1.0868896770471015}\n",
    "\n",
    "# # in the next cell (2D erosion and 3D fill holes) -> less agressive (3,3,7)\n",
    "{'image_score': np.float64(0.5266403974739573),\n",
    " 'topo_score': 0.2664179104477612,\n",
    " 'surface_dice': 0.730360307830454,\n",
    " 'voi_score': 0.5459683331399141,\n",
    " 'voi_split': 1.6721598269374063,\n",
    " 'voi_merge': 1.0998670428806532}\n",
    "\n",
    "# 2D (3) erosion\n",
    "{'image_score': np.float64(0.5367764802419565),\n",
    " 'topo_score': 0.2819237147595357,\n",
    " 'surface_dice': 0.7427706250347151,\n",
    " 'voi_score': 0.5492275630055584,\n",
    " 'voi_split': 1.6704664476229587,\n",
    " 'voi_merge': 1.0653299529780524}\n",
    "\n",
    "# 2d (1) erosion\n",
    "{'image_score': np.float64(0.4955838446400916),\n",
    " 'topo_score': 0.1466655163488914,\n",
    " 'surface_dice': 0.7410665837104861,\n",
    " 'voi_score': 0.5491739583907256,\n",
    " 'voi_split': 1.6741187853307682,\n",
    " 'voi_merge': 1.062270020202755}\n",
    "\n",
    "## just some erosion\n",
    "{'image_score': np.float64(0.5322698397359252),\n",
    " 'topo_score': 0.2670856245090338,\n",
    " 'surface_dice': 0.7428282548700696,\n",
    " 'voi_score': 0.5490121805105447,\n",
    " 'voi_split': 1.6716041120374625,\n",
    " 'voi_merge': 1.0665732636148524}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9374842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 73 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 15 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\n",
      "Done.\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 21 elements.\n",
      "Found 21 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_filled_holes_2536049117.tif\n",
      "Done!\n",
      "Number of sheets: 21\n",
      "Creating kernels and moving to GPU...\n",
      "Processing 21 sheets on CUDA 13.0 GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:07<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_holes_2536049117.tif\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 12 elements.\n",
      "Found 12 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_holes_2536049117.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.7882637960836423),\n",
       " 'topo_score': 0.9743589743589743,\n",
       " 'surface_dice': 0.8558458386594815,\n",
       " 'voi_score': 0.5611716007003755,\n",
       " 'voi_split': 1.3514921274294143,\n",
       " 'voi_merge': 1.2551282524564094}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXED CODE, GOOD RESULTS!\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import cupy as cp\n",
    "import cupyx.scipy.ndimage as ndimage_gpu\n",
    "from skimage import morphology \n",
    "from skimage.measure import regionprops, label\n",
    "from tqdm import tqdm\n",
    "\n",
    "#prob_pred = sigmoid(logits_pred)\n",
    "#prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "#binary_pred_here = prob_pred>0.5\n",
    "binary_pred_here = load_volume(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3515764944.tif\")\n",
    "\n",
    "# Removing the small objects\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_small_2536049117.tif\"\n",
    "tifffile.imwrite(output_path, binary_pred_here.astype(np.uint16)) # categorical label\n",
    "_ = remove_bellow_th(input_path=output_path, th=1000, output_path=output_path)\n",
    "\n",
    "rm_small_2536049117 = load_volume(output_path)\n",
    "\n",
    "# FILL HOLES (Keep this to fix internal bubbles, but don't rely on it for rips)\n",
    "mask_holes_filled = morphology.remove_small_holes(\n",
    "    rm_small_2536049117.astype(bool), \n",
    "    area_threshold=1000\n",
    ")\n",
    "\n",
    "# Remove bridges # added LATER!\n",
    "# Didn't change the results for the case 2536049117!\n",
    "mask_holes_filled = erode_2d(vol=mask_holes_filled, s=3)\n",
    "\n",
    "# 2. SPLIT BY OBJECT (Create Categorical Volume)\n",
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/filled_holes_2536049117.tif\"\n",
    "categorical_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_filled_holes_2536049117.tif\" \n",
    "\n",
    "# Save intermediate if needed for split_by_object\n",
    "tifffile.imwrite(input_path, mask_holes_filled.astype(np.uint16))\n",
    "_ = split_by_object(input_path, categorical_path)\n",
    "\n",
    "\n",
    "# Load your labels (CPU is fine for loading)\n",
    "labels = tifffile.imread(categorical_path)\n",
    "n_labels = labels.max()\n",
    "print(f\"Number of sheets: {n_labels}\")\n",
    "\n",
    "# Prepare output\n",
    "dtype_out = np.uint32 if n_labels > np.iinfo(np.uint16).max else np.uint16\n",
    "filled_labels = np.zeros_like(labels, dtype=dtype_out)\n",
    "\n",
    "# ==========================================================\n",
    "# TUNING FOR \"STRAIGHT PAPER\" LOOK\n",
    "# ==========================================================\n",
    "# Balanced Dilation/Erosion = No thickening, just filling.\n",
    "DILATION_RADIUS = 5 # 5\n",
    "EROSION_RADIUS = 5   # 5\n",
    "# Median filter \"irons\" the sheet flat and straightens edges\n",
    "MEDIAN_FILTER_SIZE = 3 # 3 \n",
    "# Remove edge artifacts from U-Net\n",
    "CROP_MARGIN = 13 # 13      \n",
    "# Padding to prevent \"invisible wall\" squeezing\n",
    "PAD_WIDTH = DILATION_RADIUS + 4\n",
    "\n",
    "# ==========================================================\n",
    "# GPU SETUP: PRE-LOAD KERNELS\n",
    "# ==========================================================\n",
    "print(\"Creating kernels and moving to GPU...\")\n",
    "# 1. Create balls on CPU\n",
    "cpu_ball_dilate = morphology.ball(DILATION_RADIUS)\n",
    "cpu_ball_erode = morphology.ball(EROSION_RADIUS)\n",
    "\n",
    "# 2. Move to GPU (do this ONCE, not in the loop)\n",
    "gpu_ball_dilate = cp.array(cpu_ball_dilate)\n",
    "gpu_ball_erode = cp.array(cpu_ball_erode)\n",
    "\n",
    "print(f\"Processing {n_labels} sheets on CUDA 13.0 GPU...\")\n",
    "\n",
    "for region in tqdm(regionprops(labels), total=n_labels):\n",
    "\n",
    "    label_id = region.label\n",
    "\n",
    "    # --- CPU PART (Slicing is fast on CPU) ---\n",
    "    bbox = region.bbox\n",
    "    minr, minc, mins, maxr, maxc, maxs = bbox\n",
    "    slices = (slice(minr, maxr), slice(minc, maxc), slice(mins, maxs))\n",
    "\n",
    "    # Extract binary sub-volume\n",
    "    sub = (labels[slices] == label_id)\n",
    "    \n",
    "    # 1. Pre-Cleaning (Remove artifacts)\n",
    "    if CROP_MARGIN > 0:\n",
    "        sub[:CROP_MARGIN, :, :] = 0\n",
    "        sub[-CROP_MARGIN:, :, :] = 0\n",
    "        sub[:, :CROP_MARGIN, :] = 0\n",
    "        sub[:, -CROP_MARGIN:, :] = 0\n",
    "        sub[:, :, :CROP_MARGIN] = 0\n",
    "        sub[:, :, -CROP_MARGIN:] = 0\n",
    "\n",
    "    # 2. Pad (CPU)\n",
    "    sub_padded = np.pad(sub, PAD_WIDTH, mode='constant', constant_values=0)\n",
    "\n",
    "    # --- GPU PART (Heavy lifting) ---\n",
    "    # 3. Transfer to VRAM\n",
    "    gpu_sub = cp.array(sub_padded)\n",
    "\n",
    "    # 4. Solidify (Dilation + Erosion)\n",
    "    # Note: We use 'structure=' to pass our pre-loaded ball\n",
    "    gpu_sub = ndimage_gpu.binary_dilation(gpu_sub, structure=gpu_ball_dilate)\n",
    "    gpu_sub = ndimage_gpu.binary_erosion(gpu_sub, structure=gpu_ball_erode)\n",
    "\n",
    "    # 5. Fill Internal Holes\n",
    "    gpu_sub = ndimage_gpu.binary_fill_holes(gpu_sub)\n",
    "\n",
    "    # 6. Ironing / Straightening (Median Filter)\n",
    "    if MEDIAN_FILTER_SIZE > 0:\n",
    "        gpu_sub = ndimage_gpu.median_filter(gpu_sub, size=MEDIAN_FILTER_SIZE)\n",
    "\n",
    "    # --- RETRIEVE PART ---\n",
    "    # 7. Pull back to CPU\n",
    "    sub_filled = gpu_sub.get()\n",
    "\n",
    "    # 8. Un-pad\n",
    "    sub_final = sub_filled[PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH]\n",
    "\n",
    "    # 9. Write back\n",
    "    out_block = filled_labels[slices]\n",
    "    out_block[sub_final] = label_id\n",
    "    filled_labels[slices] = out_block\n",
    "\n",
    "# ==========================================\n",
    "# 4. SAVE AND SCORE\n",
    "# ==========================================\n",
    "\n",
    "output_path_final = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/rm_holes_2536049117.tif\"\n",
    "tifffile.imwrite(output_path_final, filled_labels.astype(np.uint16))\n",
    "print(f\"Saved closed volume to: {output_path_final}\")\n",
    "\n",
    "_ = split_by_object(output_path_final, \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_holes_2536049117.tif\")\n",
    "\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3515764944.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=output_path_final,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8908bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n",
      "Path exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 114235076.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/114235076.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3527825464.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:30<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3527825464.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2737376036.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:25<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2737376036.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1693721638.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [00:52<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1693721638.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 4216652155.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:28<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4216652155.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1796762532.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:19<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1796762532.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2116132949.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:20<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2116132949.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 363381119.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:09<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/363381119.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 928131323.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:23<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/928131323.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1966171058.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:25<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1966171058.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1471460767.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:33<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1471460767.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3922476405.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:33<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3922476405.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3662102503.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:32<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3662102503.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3335656968.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:31<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3335656968.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3237609845.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:18<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3237609845.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 4015222329.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:36<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4015222329.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1189767014.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:51<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1189767014.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2708764018.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:24<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2708764018.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1013184726.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:46<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1013184726.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2689046967.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:03<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2689046967.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 206065757.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:23<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/206065757.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 571334887.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:14<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/571334887.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1351645019.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:25<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1351645019.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2136851012.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:41<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2136851012.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 663106834.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:32<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/663106834.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2203617984.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:24<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2203617984.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3545147380.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3545147380.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1127903126.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:12<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1127903126.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1704770049.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:37<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1704770049.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 216657071.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:11<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/216657071.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 693501383.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/693501383.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2536049117.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:25<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2536049117.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2821927657.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2821927657.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 149409101.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:40<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/149409101.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 3686818985.tif: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:40<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3686818985.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a function with the cell before, looks very nice the results!\n",
    "# FIXED CODE, GOOD RESULTS!\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import cupy as cp\n",
    "import cupyx.scipy.ndimage as ndimage_gpu\n",
    "from skimage import morphology \n",
    "from skimage.measure import regionprops, label\n",
    "from tqdm import self.config['post_process_hysteresis_low_th']tqdm\n",
    "\n",
    "\n",
    "def post_process(previous_pred_path, output_path):\n",
    "    binary_pred_here = load_volume(previous_pred_path)\n",
    "    # Remove small objects\n",
    "    \n",
    "    labeled_volume = split_by_object_np(binary_pred_here) \n",
    "    filtered_volume = remove_small_objects(labeled_volume, min_size=1000, connectivity=1)\n",
    "    \n",
    "    # FILL HOLES (Keep this to fix internal bubbles, but don't rely on it for rips)\n",
    "    mask_holes_filled = morphology.remove_small_holes(\n",
    "        split_by_object_np(filtered_volume).astype(bool), \n",
    "        area_threshold=1000\n",
    "    )\n",
    "\n",
    "    # Remove bridges\n",
    "    # Didn't change the results for the case 2536049117!\n",
    "    mask_holes_filled = erode_2d(vol=mask_holes_filled, s=3)\n",
    "    labeled_volume = split_by_object_np(mask_holes_filled) \n",
    "\n",
    "    n_labels = labeled_volume.max()\n",
    "\n",
    "    # Prepare output\n",
    "    dtype_out = np.uint32 if n_labels > np.iinfo(np.uint16).max else np.uint16\n",
    "    filled_labels = np.zeros_like(labeled_volume, dtype=dtype_out)\n",
    "\n",
    "    # ==========================================================\n",
    "    # TUNING FOR \"STRAIGHT PAPER\" LOOK\n",
    "    # ==========================================================\n",
    "    # Balanced Dilation/Erosion = No thickening, just filling.\n",
    "    DILATION_RADIUS = 5 # 5\n",
    "    EROSION_RADIUS = 5   # 5\n",
    "    # Median filter \"irons\" the sheet flat and straightens edges\n",
    "    MEDIAN_FILTER_SIZE = 3 # 3 \n",
    "    # Remove edge artifacts from U-Net\n",
    "    CROP_MARGIN = 13 # 13      \n",
    "    # Padding to prevent \"invisible wall\" squeezing\n",
    "    PAD_WIDTH = DILATION_RADIUS + 4\n",
    "\n",
    "    # ==========================================================\n",
    "    # GPU SETUP: PRE-LOAD KERNELS\n",
    "    # ==========================================================\n",
    "\n",
    "    # 1. Create balls on CPU\n",
    "    cpu_ball_dilate = morphology.ball(DILATION_RADIUS)\n",
    "    cpu_ball_erode = morphology.ball(EROSION_RADIUS)\n",
    "\n",
    "    # 2. Move to GPU (do this ONCE, not in the loop)\n",
    "    gpu_ball_dilate = cp.array(cpu_ball_dilate)\n",
    "    gpu_ball_erode = cp.array(cpu_ball_erode)\n",
    "\n",
    "    case_name = previous_pred_path.split('/')[-1]\n",
    "\n",
    "    for region in tqdm(regionprops(labeled_volume), total=n_labels, desc=f\"Processing {case_name}\"):\n",
    "\n",
    "        label_id = region.label\n",
    "\n",
    "        # --- CPU PART (Slicing is fast on CPU) ---\n",
    "        bbox = region.bbox\n",
    "        minr, minc, mins, maxr, maxc, maxs = bbox\n",
    "        slices = (slice(minr, maxr), slice(minc, maxc), slice(mins, maxs))\n",
    "\n",
    "        # Extract binary sub-volume\n",
    "        sub = (labeled_volume[slices] == label_id)\n",
    "        \n",
    "        # 1. Pre-Cleaning (Remove artifacts)\n",
    "        if CROP_MARGIN > 0:\n",
    "            sub[:CROP_MARGIN, :, :] = 0\n",
    "            sub[-CROP_MARGIN:, :, :] = 0\n",
    "            sub[:, :CROP_MARGIN, :] = 0\n",
    "            sub[:, -CROP_MARGIN:, :] = 0\n",
    "            sub[:, :, :CROP_MARGIN] = 0\n",
    "            sub[:, :, -CROP_MARGIN:] = 0\n",
    "\n",
    "        # 2. Pad (CPU)\n",
    "        sub_padded = np.pad(sub, PAD_WIDTH, mode='constant', constant_values=0)\n",
    "\n",
    "        # --- GPU PART (Heavy lifting) ---\n",
    "        # 3. Transfer to VRAM\n",
    "        gpu_sub = cp.array(sub_padded)\n",
    "\n",
    "        # 4. Solidify (Dilation + Erosion)\n",
    "        # Note: We use 'structure=' to pass our pre-loaded ball\n",
    "        gpu_sub = ndimage_gpu.binary_dilation(gpu_sub, structure=gpu_ball_dilate)\n",
    "        gpu_sub = ndimage_gpu.binary_erosion(gpu_sub, structure=gpu_ball_erode)\n",
    "\n",
    "        # 5. Fill Internal Holes\n",
    "        gpu_sub = ndimage_gpu.binary_fill_holes(gpu_sub)\n",
    "\n",
    "        # 6. Ironing / Straightening (Median Filter)\n",
    "        if MEDIAN_FILTER_SIZE > 0:\n",
    "            gpu_sub = ndimage_gpu.median_filter(gpu_sub, size=MEDIAN_FILTER_SIZE)\n",
    "\n",
    "        # --- RETRIEVE PART ---\n",
    "        # 7. Pull back to CPU\n",
    "        sub_filled = gpu_sub.get()\n",
    "\n",
    "        # 8. Un-pad\n",
    "        sub_final = sub_filled[PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH]\n",
    "\n",
    "        # 9. Write back\n",
    "        out_block = filled_labels[slices]\n",
    "        out_block[sub_final] = label_id\n",
    "        filled_labels[slices] = out_block\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. SAVE AND SCORE\n",
    "    # ==========================================\n",
    "    \n",
    "    output_path_final = os.path.join(output_path, case_name)\n",
    "    tifffile.imwrite(output_path, filled_labels.astype(np.uint16))\n",
    "    print(f\"Saved closed volume to: {output_path}\")\n",
    "\n",
    "\n",
    "root_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5\"\n",
    "for file_name in os.listdir(root_path):\n",
    "    if not file_name.endswith('.tif'):\n",
    "        continue\n",
    "    output_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/{file_name}\"\n",
    "    if os.path.exists(output_path):\n",
    "      print(\"Path exists!\")  \n",
    "    else:\n",
    "        post_process(\n",
    "            previous_pred_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/{file_name}\",\n",
    "            output_path=output_path\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b33765d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1669670049.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1669670049.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 2/79 [00:20<12:57, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/541673255.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/541673255.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 3/79 [00:51<24:00, 18.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3090197578.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3090197578.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 4/79 [01:17<27:11, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3924902780.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3924902780.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 5/79 [01:58<34:56, 28.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1566185731.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1566185731.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 6/79 [02:29<35:17, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3921562037.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3921562037.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 7/79 [03:08<38:45, 32.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3406708348.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3406708348.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 8/79 [03:40<38:01, 32.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4233602520.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4233602520.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 9/79 [03:56<31:46, 27.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3897872090.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3897872090.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 10/79 [04:32<34:20, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2881190689.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2881190689.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 11/79 [05:11<36:58, 32.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2012359760.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2012359760.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 12/79 [05:41<35:39, 31.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1734818300.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1734818300.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 13/79 [06:25<39:14, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/803213133.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/803213133.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 14/79 [07:04<39:41, 36.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4024884955.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4024884955.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 15/79 [07:39<38:33, 36.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/378779937.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/378779937.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 16/79 [08:17<38:28, 36.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3694884789.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3694884789.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 17/79 [08:49<36:21, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2660177791.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2660177791.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 18/79 [09:23<35:32, 34.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/118041886.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/118041886.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 19/79 [09:57<34:40, 34.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1746646794.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1746646794.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 20/79 [10:32<34:12, 34.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2961547523.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2961547523.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 21/79 [11:07<33:35, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2632109508.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2632109508.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 22/79 [11:43<33:26, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3608009641.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3608009641.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 23/79 [12:25<34:41, 37.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4105398542.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4105398542.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 24/79 [13:05<34:55, 38.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/917058676.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/917058676.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [13:44<34:28, 38.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3436049398.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3436049398.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/79 [14:15<32:00, 36.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/821686014.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/821686014.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [14:47<30:13, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3767466977.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3767466977.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/79 [15:17<28:25, 33.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2067397446.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2067397446.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [15:58<29:37, 35.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1655876858.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1655876858.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [16:32<28:50, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2489372663.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2489372663.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/79 [17:06<27:54, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1845578058.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1845578058.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/79 [17:39<26:49, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1442179410.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1442179410.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/79 [18:16<26:48, 34.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4026460947.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4026460947.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [18:33<22:20, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3977024865.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3977024865.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [18:51<19:13, 26.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1004283650.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1004283650.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [19:22<19:44, 27.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3681179135.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3681179135.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/79 [19:52<19:43, 28.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1332121747.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1332121747.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/79 [20:31<21:34, 31.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4020494299.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4020494299.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [21:06<21:42, 32.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3515764944.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3515764944.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [21:39<21:16, 32.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1522833038.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1522833038.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/79 [22:10<20:25, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4023763904.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4023763904.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/79 [22:42<19:44, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1435658104.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1435658104.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/79 [23:17<19:43, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4081240825.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4081240825.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [23:54<19:56, 34.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3198627305.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3198627305.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [24:33<20:13, 35.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/114235076.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/114235076.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/79 [25:07<19:24, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3527825464.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3527825464.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/79 [25:47<19:29, 36.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2737376036.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2737376036.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/79 [26:18<18:00, 34.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1693721638.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1693721638.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [27:14<20:42, 41.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4216652155.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4216652155.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [27:54<19:40, 40.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1796762532.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1796762532.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/79 [28:40<19:51, 42.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2116132949.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2116132949.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/79 [29:20<18:43, 41.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/363381119.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/363381119.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/79 [29:37<14:51, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/928131323.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/928131323.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [30:13<14:27, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1966171058.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1966171058.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [30:47<13:48, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1471460767.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1471460767.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/79 [31:21<13:12, 34.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3922476405.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3922476405.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/79 [31:57<12:48, 34.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3662102503.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3662102503.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/79 [32:43<13:24, 38.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3335656968.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3335656968.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [33:16<12:15, 36.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3237609845.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3237609845.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [33:48<11:07, 35.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4015222329.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/4015222329.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/79 [34:20<10:15, 34.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1189767014.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1189767014.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/79 [34:57<09:55, 35.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2708764018.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2708764018.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [35:33<09:26, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1013184726.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1013184726.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [36:09<08:55, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2689046967.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2689046967.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [36:26<06:59, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/206065757.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/206065757.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/79 [36:56<06:28, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/571334887.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/571334887.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/79 [37:26<05:58, 29.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1351645019.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1351645019.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/79 [37:58<05:36, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2136851012.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2136851012.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [38:32<05:15, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/663106834.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/663106834.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [39:01<04:39, 31.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2203617984.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2203617984.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/79 [39:41<04:27, 33.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3545147380.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [39:59<03:23, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1127903126.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1127903126.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/79 [40:41<03:17, 32.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1704770049.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/1704770049.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [41:15<02:46, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/216657071.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/216657071.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [41:31<01:51, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/693501383.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/693501383.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/79 [42:04<01:28, 29.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2536049117.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/79 [42:34<00:59, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2821927657.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2821927657.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/79 [42:50<00:25, 25.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/149409101.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/149409101.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [43:26<00:00, 28.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3686818985.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/3686818985.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [43:56<00:00, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Š FINAL AGGREGATED METRICS\n",
      "==============================\n",
      "  id  image_score  topo_score  surface_dice  voi_score  voi_split  voi_merge\n",
      "MEAN     0.542944    0.325685      0.726135   0.545976    1.29212   1.512489\n",
      "==============================\n",
      "âœ… Saved detailed metrics with Mean row to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/results_post.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from infer_class import VesuviusInferer\n",
    "from compute_metrics_obj import VesuviusMetric\n",
    "def create_dfs(path_dir):\n",
    "    # Generate DataFrame\n",
    "    result_df = glob.glob(os.path.join(path_dir, '**/*.tif'), recursive=True)\n",
    "    result_df = pd.DataFrame({'tif_paths': result_df})\n",
    "    result_df['id'] = result_df['tif_paths'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "    # save dataframe to csv (take name from the path_dir last folder)\n",
    "    csv_name = os.path.basename(os.path.normpath(path_dir)) + '_df.csv'\n",
    "    result_df.to_csv(os.path.join(path_dir, csv_name), index=False)\n",
    "    return result_df\n",
    "\n",
    "create_dfs(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/\")\n",
    "\n",
    "test_metric_obj = VesuviusMetric(\n",
    "    solution_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/val_labels_df.csv\",\n",
    "    submission_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/th_0.5_df.csv\",\n",
    "    output_file=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/results_post.csv\"\n",
    ")\n",
    "\n",
    "test_metric_obj._run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745b814e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# case 3515764944 with 2D erode\u001b[39;00m\n\u001b[32m      3\u001b[39m {\u001b[33m'\u001b[39m\u001b[33mimage_score\u001b[39m\u001b[33m'\u001b[39m: np.float64(\u001b[32m0.7882637960836423\u001b[39m),\n\u001b[32m      4\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mtopo_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9743589743589743\u001b[39m,\n\u001b[32m      5\u001b[39m  \u001b[33m'\u001b[39m\u001b[33msurface_dice\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.8558458386594815\u001b[39m,\n\u001b[32m      6\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.5611716007003755\u001b[39m,\n\u001b[32m      7\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_split\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1.3514921274294143\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_merge\u001b[39m\u001b[33m'\u001b[39m: \u001b[32;43m1.2551282524564094\u001b[39;49m}\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Original 2536049117\u001b[39;00m\n\u001b[32m     11\u001b[39m {\u001b[33m'\u001b[39m\u001b[33mimage_score\u001b[39m\u001b[33m'\u001b[39m: np.float64(\u001b[32m0.6051958352815727\u001b[39m),\n\u001b[32m     12\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mtopo_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.1349917081260365\u001b[39m,\n\u001b[32m     13\u001b[39m  \u001b[33m'\u001b[39m\u001b[33msurface_dice\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9515386536493884\u001b[39m,\n\u001b[32m     14\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.6618851259042164\u001b[39m,\n\u001b[32m     15\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_split\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.807663674979235\u001b[39m,\n\u001b[32m     16\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_merge\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.8951236157603629\u001b[39m}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# case 3515764944 with 2D erode\u001b[39;00m\n\u001b[32m      3\u001b[39m {\u001b[33m'\u001b[39m\u001b[33mimage_score\u001b[39m\u001b[33m'\u001b[39m: np.float64(\u001b[32m0.7882637960836423\u001b[39m),\n\u001b[32m      4\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mtopo_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9743589743589743\u001b[39m,\n\u001b[32m      5\u001b[39m  \u001b[33m'\u001b[39m\u001b[33msurface_dice\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.8558458386594815\u001b[39m,\n\u001b[32m      6\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.5611716007003755\u001b[39m,\n\u001b[32m      7\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_split\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1.3514921274294143\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_merge\u001b[39m\u001b[33m'\u001b[39m: \u001b[32;43m1.2551282524564094\u001b[39;49m}\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Original 2536049117\u001b[39;00m\n\u001b[32m     11\u001b[39m {\u001b[33m'\u001b[39m\u001b[33mimage_score\u001b[39m\u001b[33m'\u001b[39m: np.float64(\u001b[32m0.6051958352815727\u001b[39m),\n\u001b[32m     12\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mtopo_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.1349917081260365\u001b[39m,\n\u001b[32m     13\u001b[39m  \u001b[33m'\u001b[39m\u001b[33msurface_dice\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.9515386536493884\u001b[39m,\n\u001b[32m     14\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_score\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.6618851259042164\u001b[39m,\n\u001b[32m     15\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_split\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.807663674979235\u001b[39m,\n\u001b[32m     16\u001b[39m  \u001b[33m'\u001b[39m\u001b[33mvoi_merge\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.8951236157603629\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[39m, in \u001b[36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/topo-metrics-3d/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/topo-metrics-3d/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/topo-metrics-3d/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/topo-metrics-3d/lib/python3.11/threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# case 3515764944 with 2D erode\n",
    "{'image_score': np.float64(0.7882637960836423),\n",
    " 'topo_score': 0.9743589743589743,\n",
    " 'surface_dice': 0.8558458386594815,\n",
    " 'voi_score': 0.5611716007003755,\n",
    " 'voi_split': 1.3514921274294143,\n",
    " 'voi_merge': 1.2551282524564094}\n",
    "\n",
    "# Original 2536049117\n",
    "{'image_score': np.float64(0.6051958352815727),\n",
    " 'topo_score': 0.1349917081260365,\n",
    " 'surface_dice': 0.9515386536493884,\n",
    " 'voi_score': 0.6618851259042164,\n",
    " 'voi_split': 0.807663674979235,\n",
    " 'voi_merge': 0.8951236157603629}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806de96",
   "metadata": {},
   "source": [
    "#### apply_hysteresis_threshold (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# The predictions from MONAI are transposed\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Need to change back!\u001b[39;00m\n\u001b[32m     15\u001b[39m prob_pred = sigmoid(logits_pred)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m prob_pred = \u001b[43mnp\u001b[49m.transpose(prob_pred.squeeze().cpu().numpy(), (\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.filters import apply_hysteresis_threshold\n",
    "# Original case without any post-process\n",
    "\"\"\"\n",
    "input_data = {\n",
    "    'image': str(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/114235076.tif\"),\n",
    "    'gt': None\n",
    "}\n",
    "logits_pred, pred = infer_object.infer(\n",
    "    input=input_data, \n",
    "    test=True, \n",
    "    threshold=0.5 # CHANGED FROM 0.5\n",
    ")\n",
    "\"\"\"\n",
    "# The predictions from MONAI are transposed\n",
    "# Need to change back!\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27c6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred_here = prob_pred>0.5\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/pred_bin_114235076_original_step2.tif\"\n",
    "tifffile.imwrite(output_path, binary_pred_here.astype(np.uint16)) # categorical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eab16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 320, 320)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strong = 0.8 (High confidence)\n",
    "# weak = 0.4 (Low confidence to fill gaps)\n",
    "from skimage.filters import apply_hysteresis_threshold\n",
    "hysteresis_th0408_mask = apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "prob_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6a2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/hysteresisth0306_114235076_original_step2.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.42506195607724895),\n",
       " 'topo_score': 0.022449367503441044,\n",
       " 'surface_dice': 0.4498825537293728,\n",
       " 'voi_score': 0.7453378629169602,\n",
       " 'voi_split': 0.2776122491090761,\n",
       " 'voi_merge': 0.8612991527008893}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/hysteresisth0306_114235076_original_step2.tif\"\n",
    "tifffile.imwrite(output_path, hysteresis_th0408_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "nii_data = np.transpose(hysteresis_th0408_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dab00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# apply_hysteresis_threshold(prob_pred, 0.3, 0.8) / apply_hysteresis_threshold(prob_pred, 0.3, 0.7) / apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "{'image_score': np.float64(0.4250627816266543),\n",
    " 'topo_score': 0.022449367503441044,\n",
    " 'surface_dice': 0.44988506234095993,\n",
    " 'voi_score': 0.7453377130179598,\n",
    " 'voi_split': 0.2776121850446437,\n",
    " 'voi_merge': 0.8613001162032592}\n",
    "\n",
    "# apply_hysteresis_threshold(prob_pred, 0.5, 0.8)\n",
    "{'image_score': np.float64(0.4164614636310076),\n",
    " 'topo_score': 0.01589706132155597,\n",
    " 'surface_dice': 0.42982216008774154,\n",
    " 'voi_score': 0.7464416834395179,\n",
    " 'voi_split': 0.27298504675551283,\n",
    " 'voi_merge': 0.8593129040239527}\n",
    "\n",
    "# Original\n",
    "{'image_score': np.float64(0.417026590342083),\n",
    " 'topo_score': 0.014997131209421713,\n",
    " 'surface_dice': 0.43251717612714397,\n",
    " 'voi_score': 0.7461326838135888,\n",
    " 'voi_split': 0.27546518298702793,\n",
    " 'voi_merge': 0.858682141806286}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "#(prob_pred, 0.1, 0.6)/(prob_pred, 0.1, 0.5) -> 3 Âº best topo_score â¬‡ï¸â¬‡ï¸ | 1Âº best surface_dice â¬†ï¸â¬†ï¸ | 1Âº best voi_score â¬†ï¸â¬†ï¸\n",
    "{'image_score': np.float64(0.43291155605791964),\n",
    " 'topo_score': 0.01021792298480274,\n",
    " 'surface_dice': 0.4877857312370883,\n",
    " 'voi_score': 0.7403462092271368,\n",
    " 'voi_split': 0.2942298236737297,\n",
    " 'voi_merge': 0.8748348991848787}\n",
    "\n",
    "\n",
    "# (prob_pred, 0.4, 0.6)/(prob_pred, 0.4, 0.5) -> 2Âº best topo_score â¬‡ï¸ | 2Âº best surface_dice â¬†ï¸ | 1Âº best voi_score â¬†ï¸â¬†ï¸\n",
    "{'image_score': np.float64(0.4139674579625019),\n",
    " 'topo_score': 0.028642246642246644,\n",
    " 'surface_dice': 0.4152043704381358,\n",
    " 'voi_score': 0.7430092980470867,\n",
    " 'voi_split': 0.26621442121472194,\n",
    " 'voi_merge': 0.8867128374722746}\n",
    "\n",
    "\n",
    "# Real results of th 0.5 (no post-processing)\n",
    "{'image_score': np.float64(0.3875621574520175),\n",
    " 'topo_score': 0.04236180904522613,\n",
    " 'surface_dice': 0.3972573748403367,\n",
    " 'voi_score': 0.6737529529838052,\n",
    " 'voi_split': 0.7607155566923927,\n",
    " 'voi_merge': 0.8533629447888303}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6e4e679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 10 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 10 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_hysteresisth0306_114235076_original_step2.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_hysteresisth0306_114235076_original_step2.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.42506195607724895),\n",
       " 'topo_score': 0.022449367503441044,\n",
       " 'surface_dice': 0.4498825537293728,\n",
       " 'voi_score': 0.7453378629169602,\n",
       " 'voi_split': 0.2776122491090761,\n",
       " 'voi_merge': 0.8612991527008893}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_small_obj_hysteresisth0406_114235076_original = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/hysteresisth0306_114235076_original_step2.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_hysteresisth0306_114235076_original_step2.tif\"\n",
    "    )\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_hysteresisth0306_114235076_original_step2.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955a1b9",
   "metadata": {},
   "source": [
    "#### morphological opening (remove the bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 23 elements.\n",
      "Found 23 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_hysteresisth0306_114235076_original_step2categorical.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_hysteresisth0306_114235076_original_step2categorical.tif\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_hysteresisth0306_114235076_original_step2.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.42960935551974644),\n",
       " 'topo_score': 0.041951640759930915,\n",
       " 'surface_dice': 0.44682589262753275,\n",
       " 'voi_score': 0.7446708596346588,\n",
       " 'voi_split': 0.28223171545206566,\n",
       " 'voi_merge': 0.8606854855361559}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# improves topo score, but dice and voi-score are similar to the baseline \n",
    "# file after hysteresisth0406\n",
    "from scipy.ndimage import binary_opening\n",
    "\n",
    "# 1. Run your current 3D Hysteresis\n",
    "hysteresisth0306_114235076_original = apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "\n",
    "# 2. Break the bridges\n",
    "# We use a small kernel. This erodes 1 pixel (snapping thin bridges) \n",
    "# and then dilates back (restoring the sheet volume).\n",
    "opened_hysteresisth0306_114235076_original = binary_opening(hysteresisth0306_114235076_original, structure=np.ones((3,3,3)))\n",
    "\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_hysteresisth0306_114235076_original_step2.tif\"\n",
    "tifffile.imwrite(output_path, opened_hysteresisth0306_114235076_original.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "nii_data = np.transpose(opened_hysteresisth0306_114235076_original, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedaaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "{'image_score': np.float64(0.42506195607724895),\n",
    " 'topo_score': 0.022449367503441044,\n",
    " 'surface_dice': 0.4498825537293728,\n",
    " 'voi_score': 0.7453378629169602,\n",
    " 'voi_split': 0.2776122491090761,\n",
    " 'voi_merge': 0.8612991527008893}\n",
    "\n",
    "# morphological open\n",
    "{'image_score': np.float64(0.42960935551974644),\n",
    " 'topo_score': 0.041951640759930915,\n",
    " 'surface_dice': 0.44682589262753275,\n",
    " 'voi_score': 0.7446708596346588,\n",
    " 'voi_split': 0.28223171545206566,\n",
    " 'voi_merge': 0.8606854855361559}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old\n",
    "# only apply_hysteresis_threshold(prob_pred, 0.4, 0.6)/(prob_pred, 0.4, 0.5) \n",
    "{'image_score': np.float64(0.4139674579625019),\n",
    " 'topo_score': 0.028642246642246644,\n",
    " 'surface_dice': 0.4152043704381358,\n",
    " 'voi_score': 0.7430092980470867,\n",
    " 'voi_split': 0.26621442121472194,\n",
    " 'voi_merge': 0.8867128374722746}\n",
    "\n",
    "# apply_hysteresis_threshold with binary opening -> 1Âº best topo_score â¬†ï¸ | 3Âº best surface_dice --  | 3Âº best voi_score â¬‡ï¸\n",
    "{'image_score': np.float64(0.4080548261067526),\n",
    " 'topo_score': 0.11740136054421768,\n",
    " 'surface_dice': 0.3921057543415669,\n",
    " 'voi_score': 0.6731354397826823,\n",
    " 'voi_split': 0.784066827086829,\n",
    " 'voi_merge': 0.8345502738185694}\n",
    "\n",
    "# Real results of th 0.5 (no post-processing)\n",
    "{'image_score': np.float64(0.3875621574520175),\n",
    " 'topo_score': 0.04236180904522613,\n",
    " 'surface_dice': 0.3972573748403367,\n",
    " 'voi_score': 0.6737529529838052,\n",
    " 'voi_split': 0.7607155566923927,\n",
    " 'voi_merge': 0.8533629447888303}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ca74a",
   "metadata": {},
   "source": [
    "# Didn't improve anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b5058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/safe_2d_open_hysteresisth0306_114235076_original.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.38833766422225846),\n",
       " 'topo_score': 0.04299961195188203,\n",
       " 'surface_dice': 0.39831017053128825,\n",
       " 'voi_score': 0.6743692027164084,\n",
       " 'voi_split': 0.7782432074585012,\n",
       " 'voi_merge': 0.8313142672498488}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't result, the results are similar to not using any post-processing\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_opening\n",
    "\n",
    "def safe_2d_opening(mask):\n",
    "    # Standard 3x3 square for 2D slices\n",
    "    kernel_2d = np.ones((3,3), dtype=bool)\n",
    "    \n",
    "    result = np.zeros_like(mask)\n",
    "    # Process slice by slice\n",
    "    for z in range(mask.shape[0]):\n",
    "        result[z] = binary_opening(mask[z], structure=kernel_2d)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply\n",
    "hysteresisth0306_114235076_original = apply_hysteresis_threshold(prob_pred, 0.4, 0.6)\n",
    "safe_2d_open_hysteresisth0306_114235076_original = safe_2d_opening(hysteresisth0306_114235076_original)\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/safe_2d_open_hysteresisth0306_114235076_original.tif\"\n",
    "tifffile.imwrite(output_path, safe_2d_open_hysteresisth0306_114235076_original.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "nii_data = np.transpose(safe_2d_open_hysteresisth0306_114235076_original, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac73f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/watershed_hysteresisth0306_114235076_original.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.3611867062647005),\n",
       " 'topo_score': 0.00477387287457351,\n",
       " 'surface_dice': 0.3542049603708464,\n",
       " 'voi_score': 0.673665166492949,\n",
       " 'voi_split': 0.6674853456891917,\n",
       " 'voi_merge': 0.9472378617162813}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import watershed, find_boundaries\n",
    "from scipy.ndimage import label, distance_transform_edt\n",
    "from skimage.filters import apply_hysteresis_threshold\n",
    "\n",
    "def watershed_rescue(prob_map, core_thresh=0.75, mask_low=0.4, mask_high=0.6):\n",
    "    \"\"\"\n",
    "    Uses Watershed to cut thick bridges between sheets without eroding the sheets themselves.\n",
    "    \"\"\"\n",
    "    # 1. The Mask (Your Hysteresis Result)\n",
    "    # This defines the total volume we want to keep.\n",
    "    mask = apply_hysteresis_threshold(prob_map, mask_low, mask_high)\n",
    "    \n",
    "    # 2. The Markers (High Confidence Cores)\n",
    "    # These are the \"safe\" centers of the sheets.\n",
    "    # We label them 1, 2, 3... so they are distinct basins.\n",
    "    core_mask = prob_map > core_thresh\n",
    "    markers, _ = label(core_mask)\n",
    "    \n",
    "    # 3. The Landscape (Distance Transform)\n",
    "    # We want to grow from the center of the sheet to the edge.\n",
    "    # Using distance transform ensures we grow geometrically.\n",
    "    distance = distance_transform_edt(mask)\n",
    "    \n",
    "    # 4. Run Watershed\n",
    "    # -distance makes the \"peaks\" (centers) into \"valleys\" for the water to fill.\n",
    "    # It fills the 'mask' starting from 'markers'.\n",
    "    w_labels = watershed(-distance, markers, mask=mask)\n",
    "    \n",
    "    # 5. The \"Dam\" (Boundary Removal)\n",
    "    # Watershed returns touching labels (e.g., Label 1 touches Label 2).\n",
    "    # To fix Topology, we must physically separate them with 0s.\n",
    "    boundaries = find_boundaries(w_labels, mode='thick')\n",
    "    \n",
    "    # Remove boundaries from the original mask\n",
    "    final_mask = mask.copy()\n",
    "    final_mask[boundaries] = 0\n",
    "    \n",
    "    return final_mask.astype(np.uint8)\n",
    "\n",
    "# --- Apply it ---\n",
    "# Adjust core_thresh if your model is very confident (try 0.8) or unsure (try 0.7)\n",
    "watershed_mask = watershed_rescue(prob_pred, core_thresh=0.75, mask_low=0.4, mask_high=0.6)\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/watershed_hysteresisth0306_114235076_original.tif\"\n",
    "tifffile.imwrite(output_path, watershed_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "nii_data = np.transpose(watershed_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "099a3940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.3599932381733456),\n",
       " 'topo_score': 0.0041923316201568205,\n",
       " 'surface_dice': 0.35443929413312997,\n",
       " 'voi_score': 0.6705193878305802,\n",
       " 'voi_split': 0.6832966715990239,\n",
       " 'voi_merge': 0.9546406157697626}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# watershed_rescue(prob_pred, core_thresh=0.75, mask_low=0.4, mask_high=0.6)\n",
    "{'image_score': np.float64(0.36099775268716866),\n",
    " 'topo_score': 0.004588647391893799,\n",
    " 'surface_dice': 0.3549358963738418,\n",
    " 'voi_score': 0.6725531278250167,\n",
    " 'voi_split': 0.6729972145660972,\n",
    " 'voi_merge': 0.949907398852922}\n",
    "\n",
    "#watershed_rescue(prob_pred, core_thresh=0.8, mask_low=0.4, mask_high=0.6)\n",
    "{'image_score': np.float64(0.3599932381733456),\n",
    " 'topo_score': 0.0041923316201568205,\n",
    " 'surface_dice': 0.35443929413312997,\n",
    " 'voi_score': 0.6705193878305802,\n",
    " 'voi_split': 0.6832966715990239,\n",
    " 'voi_merge': 0.9546406157697626}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 650 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 19 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/rm_small_watershed_hysteresisth0306_114235076_original.tif\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import label\n",
    "rm_small_obj_hysteresisth0406_114235076_original = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/watershed_hysteresisth0306_114235076_original.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_watershed_hysteresisth0306_114235076_original.tif\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01c221ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import watershed, find_boundaries\n",
    "from scipy.ndimage import label, distance_transform_edt, binary_fill_holes, binary_closing\n",
    "from skimage.filters import apply_hysteresis_threshold, gaussian\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "def watershed_rescue_v4(prob_map, sigma=1.0, core_thresh=0.75, min_seed_size=1000):\n",
    "    \"\"\"\n",
    "    v4 Improvements:\n",
    "    1. Aggressive Size Filter (1000+ voxels).\n",
    "    2. Seed Fusion: Merges split cores using binary closing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Step 1: The Mask (Boundaries) ---\n",
    "    mask = apply_hysteresis_threshold(prob_map, 0.4, 0.6)\n",
    "    \n",
    "    # --- Step 2: The Cores ---\n",
    "    smoothed_prob = gaussian(prob_map, sigma=sigma)\n",
    "    core_mask = smoothed_prob > core_thresh\n",
    "    \n",
    "    # --- Step 3: FUSION (The Fix) ---\n",
    "    # Close gaps between nearby seed fragments.\n",
    "    # A 3x3x3 kernel connects fragments within 1-2 voxels.\n",
    "    # Iterations=2 extends this reach to ~4 voxels.\n",
    "    core_mask = binary_closing(core_mask, structure=np.ones((3,3,3)), iterations=2)\n",
    "    \n",
    "    # --- Step 4: Aggressive Filtering ---\n",
    "    # Real sheets are big. Dust is small.\n",
    "    # Try 500 first, then 1000 if you still have >20 seeds.\n",
    "    core_mask = remove_small_objects(core_mask, min_size=min_seed_size)\n",
    "    \n",
    "    # Label the fused, large seeds\n",
    "    markers, num_markers = label(core_mask)\n",
    "    print(f\"Found {num_markers} unique sheets (seeds) after Fusion & Filtering.\")\n",
    "\n",
    "    # --- Step 5: Watershed ---\n",
    "    distance = distance_transform_edt(mask)\n",
    "    w_labels = watershed(-distance, markers, mask=mask)\n",
    "    \n",
    "    # --- Step 6: Cut & Heal ---\n",
    "    boundaries = find_boundaries(w_labels, mode='thick')\n",
    "    \n",
    "    final_mask = mask.copy()\n",
    "    final_mask[boundaries] = 0\n",
    "    \n",
    "    # 2D Heal (Slice-by-slice)\n",
    "    for z in range(final_mask.shape[0]):\n",
    "        final_mask[z] = binary_fill_holes(final_mask[z])\n",
    "\n",
    "    return final_mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5cd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 unique sheets (seeds) after Fusion & Filtering.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/watershedV4_hysteresisth0306_114235076_original.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.36191352061581733),\n",
       " 'topo_score': 0.005427408412483039,\n",
       " 'surface_dice': 0.35545616561823895,\n",
       " 'voi_score': 0.6739304003591107,\n",
       " 'voi_split': 0.6641997843201765,\n",
       " 'voi_merge': 0.948576052606702}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Apply it ---\n",
    "# Adjust core_thresh if your model is very confident (try 0.8) or unsure (try 0.7)\n",
    "watershed_mask = watershed_rescue_v4(prob_pred,  sigma=1.0, core_thresh=0.75, min_seed_size=1000)\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/watershedV4_hysteresisth0306_114235076_original.tif\"\n",
    "tifffile.imwrite(output_path, watershed_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "nii_data = np.transpose(watershed_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfefbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 280 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 18 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/rm_small_watershedV4_hysteresisth0306_114235076_original.tif\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import label\n",
    "rm_small_obj_hysteresisth0406_114235076_original = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/watershedV4_hysteresisth0306_114235076_original.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_watershedV4_hysteresisth0306_114235076_original.tif\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66bc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling individual elements...\n",
      "Found 225 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 23 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/rm_small_opened_core_114235076_original.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/opened_core_114235076_original.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.33917118749368297),\n",
       " 'topo_score': 0.009390211624989932,\n",
       " 'surface_dice': 0.32175708696170763,\n",
       " 'voi_score': 0.6392546959131095,\n",
       " 'voi_split': 0.9309669363801343,\n",
       " 'voi_merge': 0.9501054353115218}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage import generate_binary_structure, binary_opening\n",
    "from skimage.measure import label\n",
    "\n",
    "prob_pred_th75 = prob_pred>0.75\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/core_114235076_original.tif\"\n",
    "tifffile.imwrite(output_path, prob_pred_th75.astype(np.uint16)) # categorical label\n",
    "\n",
    "cross_kernel = generate_binary_structure(rank=3, connectivity=1)\n",
    "opened_prob_pred_th75 = binary_opening(prob_pred_th75, structure=cross_kernel)\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_core_114235076_original.tif\"\n",
    "tifffile.imwrite(output_path, opened_prob_pred_th75.astype(np.uint16)) # categorical label\n",
    "\n",
    "rm_small_opened_core_114235076_original = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_core_114235076_original.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_opened_core_114235076_original.tif\"\n",
    "    )\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/opened_core_114235076_original.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d4ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing labels from input file.\n",
      "Using as seeds 23 elemets.\n",
      "Labeling individual elements...\n",
      "Found 7 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 8 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/rm_small_grow_seeds_back_opened_prob_pred_th75.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/grow_seeds_back_opened_prob_pred_th75.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.41388934583166737),\n",
       " 'topo_score': 0.029472527472527474,\n",
       " 'surface_dice': 0.4138934281930054,\n",
       " 'voi_score': 0.7433853934924491,\n",
       " 'voi_split': 0.2634887168440685,\n",
       " 'voi_merge': 0.8871688413751251}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gives similar results as using only apply_hysteresis_threshold(prob_pred, 0.4, 0.6) \n",
    "import numpy as np\n",
    "from skimage.segmentation import watershed\n",
    "from scipy.ndimage import distance_transform_edt, binary_fill_holes\n",
    "from skimage.filters import apply_hysteresis_threshold\n",
    "import tifffile\n",
    "from skimage.measure import label\n",
    "\n",
    "import numpy as np\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "import numpy as np\n",
    "from skimage.segmentation import watershed\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.measure import label\n",
    "from scipy.ndimage import distance_transform_edt, binary_erosion\n",
    "def grow_seeds_back(prob_pred, seeds_mask, target_threshold=0.4):\n",
    "    \n",
    "    # 1. Prepare Markers (Your 23 seeds)\n",
    "    if seeds_mask.max() > 1:\n",
    "        print(\"Using existing labels from input file.\")\n",
    "        markers = seeds_mask\n",
    "    else:\n",
    "        print(\"Input is binary. Generating unique labels...\")\n",
    "        markers, num_features = label(seeds_mask > 0, connectivity=2) \n",
    "        print(f\"Found {num_features} unique seeds.\")\n",
    "    \n",
    "    num_features  = np.unique(markers)\n",
    "    print(f\"Using as seeds {len(num_features)} elemets.\")\n",
    "    \n",
    "    # 2. Prepare Mask (The Territory)\n",
    "    mask = prob_pred > target_threshold\n",
    "\n",
    "    # 3. Distance Transform\n",
    "    distance = distance_transform_edt(mask)\n",
    "\n",
    "    # 4. Watershed with Separation\n",
    "    final_labels = watershed(-distance, markers, mask=mask, watershed_line=True)\n",
    "    \n",
    "    # --- CRITICAL FIX: Safety Erosion ---\n",
    "    # We erode each object to ensure NO diagonal connections exist.\n",
    "    # We do this on the binary mask of the labels.\n",
    "    #print(\"Applying Safety Erosion to guarantee separation...\")\n",
    "    #binary_mask = final_labels > 0\n",
    "    #eroded_mask = binary_erosion(binary_mask)\n",
    "    \n",
    "    # Apply the erosion to the labels\n",
    "    #final_labels = final_labels * eroded_mask \n",
    "    \n",
    "    return final_labels\n",
    "\n",
    "# Run the growth\n",
    "grow_seeds_back_opened_prob_pred_th75 = grow_seeds_back(prob_pred, rm_small_opened_core_114235076_original, target_threshold=0.4)\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/grow_seeds_back_opened_prob_pred_th75.tif\"\n",
    "tifffile.imwrite(output_path, grow_seeds_back_opened_prob_pred_th75.astype(np.uint16)) # categorical label\n",
    "\n",
    "_ = remove_bellow_th(\n",
    "    input_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/grow_seeds_back_opened_prob_pred_th75.tif\", \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/rm_small_grow_seeds_back_opened_prob_pred_th75.tif\"\n",
    "    )\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/grow_seeds_back_opened_prob_pred_th75.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b45c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real results of th 0.5 (no post-processing)\n",
    "{'image_score': np.float64(0.3875621574520175),\n",
    " 'topo_score': 0.04236180904522613,\n",
    " 'surface_dice': 0.3972573748403367,\n",
    " 'voi_score': 0.6737529529838052,\n",
    " 'voi_split': 0.7607155566923927,\n",
    " 'voi_merge': 0.8533629447888303}\n",
    "\n",
    "# only apply_hysteresis_threshold(prob_pred, 0.4, 0.6) \n",
    "{'image_score': np.float64(0.4139674579625019),\n",
    " 'topo_score': 0.028642246642246644,\n",
    " 'surface_dice': 0.4152043704381358,\n",
    " 'voi_score': 0.7430092980470867,\n",
    " 'voi_split': 0.26621442121472194,\n",
    " 'voi_merge': 0.8867128374722746}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2287fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Generate & Fuse Seeds (2D) ---\n",
      "Found 10 unique sheets.\n",
      "--- Step 2: Watershed Growth ---\n",
      "--- Step 3: SAFE 2D Hole Filling ---\n",
      "--- Step 4: Surgical Boundary Cut (Anti-Merge) ---\n",
      "Labeling individual elements...\n",
      "Found 246 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 14 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/final_submission.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/final_safe_fix.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.36029888949372785),\n",
       " 'topo_score': 0.005149291593781473,\n",
       " 'surface_dice': 0.3532960955239081,\n",
       " 'voi_score': 0.6717156245206444,\n",
       " 'voi_split': 0.6801008883603463,\n",
       " 'voi_merge': 0.9489832235043475}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt, binary_fill_holes\n",
    "from skimage.measure import label\n",
    "from skimage.segmentation import watershed, find_boundaries\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk\n",
    "from skimage.filters import apply_hysteresis_threshold\n",
    "\n",
    "def final_safe_pipeline(prob_map, core_th=0.70, mask_low=0.4, mask_high=0.6):\n",
    "    \n",
    "    print(\"--- Step 1: Generate & Fuse Seeds (2D) ---\")\n",
    "    # 1. Base Cores\n",
    "    cores = prob_map > core_th\n",
    "    \n",
    "    # 2. ANISOTROPIC FUSION (Fixes Splits)\n",
    "    # We close gaps ONLY in X-Y planes to fix 'broken' sheets without bridging Z-gaps.\n",
    "    fused_cores = np.zeros_like(cores)\n",
    "    search_kernel = disk(4) # Radius 4 covers gaps up to ~8 pixels\n",
    "    \n",
    "    for z in range(cores.shape[0]):\n",
    "        fused_cores[z] = binary_closing(cores[z], footprint=search_kernel)\n",
    "        \n",
    "    # 3. Filter Dust\n",
    "    # Only keep massive seeds (>2000 voxels)\n",
    "    clean_seeds = remove_small_objects(fused_cores, min_size=2000)\n",
    "    \n",
    "    # 4. Label Seeds\n",
    "    markers, num_seeds = label(clean_seeds, connectivity=2, return_num=True)\n",
    "    print(f\"Found {num_seeds} unique sheets.\")\n",
    "\n",
    "    print(\"--- Step 2: Watershed Growth ---\")\n",
    "    # 5. Define Mask\n",
    "    mask = apply_hysteresis_threshold(prob_map, mask_low, mask_high)\n",
    "    \n",
    "    # 6. Distance Map\n",
    "    distance = distance_transform_edt(mask)\n",
    "    \n",
    "    # 7. Watershed\n",
    "    # watershed_line=True attempts to leave a gap\n",
    "    labeled_volume = watershed(-distance, markers, mask=mask, watershed_line=True)\n",
    "    \n",
    "    print(\"--- Step 3: SAFE 2D Hole Filling ---\")\n",
    "    # CRITICAL FIX: We must NOT overwrite existing labels.\n",
    "    \n",
    "    # Get IDs\n",
    "    ids = np.unique(labeled_volume)\n",
    "    ids = ids[ids > 0]\n",
    "    \n",
    "    for i in ids:\n",
    "        sheet_mask = (labeled_volume == i)\n",
    "        \n",
    "        for z in range(sheet_mask.shape[0]):\n",
    "            if np.any(sheet_mask[z]):\n",
    "                # Calculate the filled version\n",
    "                filled_slice = binary_fill_holes(sheet_mask[z])\n",
    "                \n",
    "                # BUG FIX: Only fill where the volume is currently EMPTY (0)\n",
    "                # If there is another label there, DO NOT touch it.\n",
    "                # This prevents Sheet 1 from eating Sheet 2.\n",
    "                safe_fill_locations = filled_slice & (labeled_volume[z] == 0)\n",
    "                \n",
    "                labeled_volume[z, safe_fill_locations] = i\n",
    "\n",
    "    print(\"--- Step 4: Surgical Boundary Cut (Anti-Merge) ---\")\n",
    "    # Even with watershed_line, diagonal pixels can touch in 3D.\n",
    "    # We find pixels that sit exactly between two DIFFERENT labels and delete them.\n",
    "    \n",
    "    # mode='thick' finds the boundary pixels on both sides\n",
    "    # background=0 ignores boundaries between Sheet and Air (we keep those)\n",
    "    boundaries = find_boundaries(labeled_volume, mode='thick', background=0)\n",
    "    \n",
    "    labeled_volume[boundaries] = 0\n",
    "\n",
    "    return labeled_volume.astype(np.uint16)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# 1. Run Pipeline\n",
    "final_result = final_safe_pipeline(prob_pred, core_th=0.70)\n",
    "\n",
    "# 2. Save\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_safe_fix.tif\"\n",
    "tifffile.imwrite(output_path, final_result)\n",
    "\n",
    "# 3. Filter & Score\n",
    "_ = remove_bellow_th(\n",
    "    input_path=output_path, \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_submission.tif\"\n",
    ")\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_safe_fix.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Hole Closing ---\n",
      "Processing 10 sheets individually...\n",
      "Labeling individual elements...\n",
      "Found 191 individual elements.\n",
      "Removing objects smaller than 1000 voxels...\n",
      "After filtering, count: 13 elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/categorical_final_closed_volume.tif\n",
      "Done.\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process/final_closed_volume.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.35968116171561904),\n",
       " 'topo_score': 0.0046960109803786156,\n",
       " 'surface_dice': 0.35274151747157173,\n",
       " 'voi_score': 0.6708937923041581,\n",
       " 'voi_split': 0.6849528995627435,\n",
       " 'voi_merge': 0.9502100798885929}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.morphology import binary_closing, disk\n",
    "\n",
    "def close_holes_instance_wise(labeled_volume):\n",
    "    \"\"\"\n",
    "    Closes holes inside each sheet individually to improve TopoScore (b1).\n",
    "    Prevents merging by checking for collisions with other sheets.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Hole Closing ---\")\n",
    "    \n",
    "    # Create a fresh volume for the result\n",
    "    final_volume = np.zeros_like(labeled_volume)\n",
    "    \n",
    "    # Get all unique sheet IDs (skip 0)\n",
    "    unique_ids = np.unique(labeled_volume)\n",
    "    unique_ids = unique_ids[unique_ids > 0] \n",
    "    \n",
    "    print(f\"Processing {len(unique_ids)} sheets individually...\")\n",
    "    \n",
    "    for i in unique_ids:\n",
    "        # 1. Isolate the Sheet (Binary Mask)\n",
    "        sheet_mask = (labeled_volume == i)\n",
    "        \n",
    "        # 2. Heal the Sheet (Slice-by-Slice 2D)\n",
    "        healed_mask = np.zeros_like(sheet_mask)\n",
    "        \n",
    "        for z in range(sheet_mask.shape[0]):\n",
    "            if np.any(sheet_mask[z]):\n",
    "                # A. Close small cracks (Fuses fragments)\n",
    "                # disk(3) = Radius 3 (approx 7x7 kernel). \n",
    "                # Good for closing gaps up to ~6 pixels.\n",
    "                closed_slice = binary_closing(sheet_mask[z], footprint=disk(3))\n",
    "                \n",
    "                # B. Fill Enclosed Holes (The 'Swiss Cheese' Fix)\n",
    "                # Fills any black region completely surrounded by white\n",
    "                filled_slice = binary_fill_holes(closed_slice)\n",
    "                \n",
    "                healed_mask[z] = filled_slice\n",
    "        \n",
    "        # 3. The \"Anti-Cannibalism\" Check (CRITICAL)\n",
    "        # If growing Sheet A accidentally covers Sheet B, we must block it.\n",
    "        # Collision = Where our new mask overlaps with a DIFFERENT label in original\n",
    "        collision_mask = (labeled_volume != 0) & (labeled_volume != i)\n",
    "        \n",
    "        # Delete pixels that would cause a merge\n",
    "        healed_mask[collision_mask] = 0\n",
    "        \n",
    "        # 4. Add to Final Volume\n",
    "        final_volume[healed_mask] = i\n",
    "        \n",
    "    return final_volume\n",
    "\n",
    "# 1. Load your Watershed result (The one that had good separation but holes)\n",
    "# This should be the result BEFORE you ran 'find_boundaries'\n",
    "# e.g. the output of 'watershed(..., watershed_line=True)'\n",
    "input_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_safe_fix.tif\"\n",
    "labeled_volume = tifffile.imread(input_path)\n",
    "\n",
    "# 2. Run the Polish\n",
    "final_closed_volume = close_holes_instance_wise(labeled_volume)\n",
    "\n",
    "# 3. Save\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_closed_volume.tif\"\n",
    "tifffile.imwrite(output_path, final_closed_volume.astype(np.uint16))\n",
    "\n",
    "# 4. Filter Small Objects & Score\n",
    "_ = remove_bellow_th(\n",
    "    input_path=output_path, \n",
    "    th=1000, \n",
    "    output_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/categorical_final_closed_volume.tif\"\n",
    ")\n",
    "\n",
    "\n",
    "pred_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_closed_volume.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7de2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5245b47",
   "metadata": {},
   "source": [
    "# New try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc6337c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply_hysteresis_threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndimage\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 0. Base Hysteresis (Your 0.4/0.6 baseline)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m hysteresis_mask = \u001b[43mapply_hysteresis_threshold\u001b[49m(prob_pred, \u001b[32m0.3\u001b[39m, \u001b[32m0.75\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. FILL HOLES (Fixes Topo k=2 Cavities)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Safe. Fills internal bubbles.\u001b[39;00m\n\u001b[32m     10\u001b[39m mask_holes_filled = morphology.remove_small_holes(\n\u001b[32m     11\u001b[39m     hysteresis_mask.astype(\u001b[38;5;28mbool\u001b[39m), \n\u001b[32m     12\u001b[39m     area_threshold=\u001b[32m100\u001b[39m\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'apply_hysteresis_threshold' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "# 0. Base Hysteresis (Your 0.4/0.6 baseline)\n",
    "hysteresis_mask = apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "\n",
    "# 1. FILL HOLES (Fixes Topo k=2 Cavities)\n",
    "# Safe. Fills internal bubbles.\n",
    "mask_holes_filled = morphology.remove_small_holes(\n",
    "    hysteresis_mask.astype(bool), \n",
    "    area_threshold=100\n",
    ")\n",
    "\n",
    "# 2. BINARY CLOSING (Fixes Topo k=1 Loops & Improves VOI)\n",
    "# Instead of smoothing (which cuts), we close (which connects).\n",
    "# This fills tiny loops (fixing topology) and reinforces thin bridges.\n",
    "# We use a small ball/cross structure.\n",
    "structure_close = ndimage.generate_binary_structure(3, 1) # connectivity 1 (cross)\n",
    "mask_closed = ndimage.binary_closing(\n",
    "    mask_holes_filled, \n",
    "    structure=structure_close, \n",
    "    iterations=1\n",
    ")\n",
    "\n",
    "# 3. REMOVE DUST (Fixes Topo k=0 Components)\n",
    "# lowered min_size to 100 to be safer. \n",
    "# Only remove things that are clearly noise, not valid fragments.\n",
    "final_mask = morphology.remove_small_objects(\n",
    "    mask_closed, \n",
    "    min_size=100\n",
    ")\n",
    "\n",
    "# Prepare for save...\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.tif\"\n",
    "tifffile.imwrite(output_path, final_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "print(output_path_nii)\n",
    "nii_data = np.transpose(final_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "_ = split_by_object(input_path=output_path, output_path=output_path.replace('.tif', 'categorical.tif'))\n",
    "print(output_path.replace('.tif', 'categorical.tif'))\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46e73ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.42506195607724895),\n",
       " 'topo_score': 0.022449367503441044,\n",
       " 'surface_dice': 0.4498825537293728,\n",
       " 'voi_score': 0.7453378629169602,\n",
       " 'voi_split': 0.2776122491090761,\n",
       " 'voi_merge': 0.8612991527008893}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "{'image_score': np.float64(0.42506195607724895),\n",
    " 'topo_score': 0.022449367503441044,\n",
    " 'surface_dice': 0.4498825537293728,\n",
    " 'voi_score': 0.7453378629169602,\n",
    " 'voi_split': 0.2776122491090761,\n",
    " 'voi_merge': 0.8612991527008893}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3992f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing bridges slice-by-slice...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [00:00<00:00, 1221.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.nii.gz\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 6 elements.\n",
      "Found 6 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2categorical.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2categorical.tif\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.4387828224445737),\n",
       " 'topo_score': 0.07122407170294495,\n",
       " 'surface_dice': 0.4473556263224002,\n",
       " 'voi_score': 0.7452603763452857,\n",
       " 'voi_split': 0.27857698955038457,\n",
       " 'voi_merge': 0.8607994026484641}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import morphology\n",
    "from scipy import ndimage\n",
    "import tqdm\n",
    "\n",
    "# 0. Base Hysteresis (Your 0.4/0.6 baseline)\n",
    "hysteresis_mask = apply_hysteresis_threshold(prob_pred, 0.3, 0.75)\n",
    "\n",
    "# 1. FILL HOLES (Fixes Topo k=2 Cavities)\n",
    "# Safe. Fills internal bubbles.\n",
    "mask_holes_filled = morphology.remove_small_holes(\n",
    "    hysteresis_mask.astype(bool), \n",
    "    area_threshold=100\n",
    ")\n",
    "\n",
    "# 2. BINARY CLOSING (Fixes Topo k=1 Loops & Improves VOI)\n",
    "# Instead of smoothing (which cuts), we close (which connects).\n",
    "# This fills tiny loops (fixing topology) and reinforces thin bridges.\n",
    "# We use a small ball/cross structure.\n",
    "structure_close = ndimage.generate_binary_structure(3, 1) # connectivity 1 (cross)\n",
    "mask_closed = ndimage.binary_closing(\n",
    "    mask_holes_filled, \n",
    "    structure=structure_close, \n",
    "    iterations=1\n",
    ")\n",
    "\n",
    "# 3. REMOVE DUST (Fixes Topo k=0 Components)\n",
    "# lowered min_size to 100 to be safer. \n",
    "# Only remove things that are clearly noise, not valid fragments.\n",
    "mask_solid = morphology.remove_small_objects(\n",
    "    mask_closed, \n",
    "    min_size=100\n",
    ")\n",
    "\n",
    "final_mask = np.zeros_like(mask_solid)\n",
    "BRIDGE_SIZE_LIMIT = 150  # Any 2D blob smaller than this is considered a bridge/noise.\n",
    "\n",
    "print(\"Removing bridges slice-by-slice...\")\n",
    "for z in tqdm.tqdm(range(mask_solid.shape[0])):\n",
    "    slice_2d = mask_solid[z, :, :]\n",
    "    \n",
    "    # If the slice is empty, skip\n",
    "    if not np.any(slice_2d):\n",
    "        continue\n",
    "        \n",
    "    # Remove small objects in 2D (Snips the vertical bridges)\n",
    "    slice_clean = morphology.remove_small_objects(\n",
    "        slice_2d.astype(bool), \n",
    "        min_size=BRIDGE_SIZE_LIMIT\n",
    "    )\n",
    "    \n",
    "    final_mask[z, :, :] = slice_clean\n",
    "\n",
    "# --- STEP 4: FINAL 3D DUSTING (Fix Topo k=0) ---\n",
    "# Remove any floating islands that survived the process\n",
    "final_mask = morphology.remove_small_objects(\n",
    "    final_mask.astype(bool), \n",
    "    min_size=200\n",
    ")\n",
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.tif\"\n",
    "tifffile.imwrite(output_path, final_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "print(output_path_nii)\n",
    "nii_data = np.transpose(final_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "_ = split_by_object(input_path=output_path, output_path=output_path.replace('.tif', 'categorical.tif'))\n",
    "print(output_path.replace('.tif', 'categorical.tif'))\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31066b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n",
    "\n",
    "def modified_frangi_surface_3d_debug(volume, scale_range=(1, 3), scale_step=1, alpha=0.5, beta=0.5):\n",
    "    \"\"\"\n",
    "    Debug version of the Modified Frangi Filter.\n",
    "    \"\"\"\n",
    "    sigmas = np.arange(scale_range[0], scale_range[1], scale_step)\n",
    "    filtered_max = np.zeros_like(volume)\n",
    "    \n",
    "    # DEBUG: Check input volume stats\n",
    "    print(f\"--- Frangi Input Stats ---\")\n",
    "    print(f\"Shape: {volume.shape}\")\n",
    "    print(f\"Min: {volume.min():.4f}, Max: {volume.max():.4f}, Mean: {volume.mean():.4f}\")\n",
    "    print(f\"Non-zero voxels: {np.count_nonzero(volume)}\")\n",
    "    \n",
    "    if np.max(volume) == 0:\n",
    "        print(\"!!! ERROR: Input volume is all zeros. Filter will return zeros.\")\n",
    "        return filtered_max\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        print(f\"\\nProcessing scale sigma={sigma}...\")\n",
    "        \n",
    "        # 1. Compute Hessian & Eigenvalues\n",
    "        H_elems = hessian_matrix(volume, sigma=sigma, order='rc')\n",
    "        eigvals = hessian_matrix_eigvals(H_elems)\n",
    "        \n",
    "        # 2. Sort by Absolute Magnitude\n",
    "        abs_eig = np.abs(eigvals)\n",
    "        abs_eig = np.sort(abs_eig, axis=0)\n",
    "        \n",
    "        lambda1 = abs_eig[0] # Smallest (Noise/Plane-1)\n",
    "        lambda2 = abs_eig[1] # Middle   (Plane-2)\n",
    "        lambda3 = abs_eig[2] # Largest  (Normal to surface)\n",
    "        \n",
    "        # 3. Compute Ratios\n",
    "        Ra = lambda2 / (lambda3 + 1e-15)\n",
    "        Rb = lambda1 / (np.sqrt(lambda2 * lambda3) + 1e-15)\n",
    "        S = np.sqrt(np.sum(eigvals**2, axis=0))\n",
    "        \n",
    "        # DEBUG: Check intermediate metrics\n",
    "        max_S = np.max(S)\n",
    "        print(f\"  Max Structureness (S): {max_S:.4f}\")\n",
    "        print(f\"  Mean Ra (Plate-ness): {np.mean(Ra):.4f} (Target: Low)\")\n",
    "        \n",
    "        if max_S == 0:\n",
    "            print(\"  !!! S is zero everywhere. Image likely constant or empty.\")\n",
    "            continue\n",
    "\n",
    "        # 4. Dynamic Gamma (Crucial for binary masks)\n",
    "        # We set gamma based on the max structure found in this scale\n",
    "        gamma = max_S / 2.0\n",
    "        \n",
    "        # 5. Compute Filter Response\n",
    "        term_Ra = np.exp(-(Ra**2) / (2 * alpha**2))\n",
    "        term_Rb = np.exp(-(Rb**2) / (2 * beta**2))\n",
    "        term_S  = (1 - np.exp(-(S**2) / (2 * gamma**2)))\n",
    "        \n",
    "        response = term_Ra * term_Rb * term_S\n",
    "        \n",
    "        print(f\"  Max Response for this scale: {np.max(response):.4f}\")\n",
    "        \n",
    "        filtered_max = np.maximum(filtered_max, response)\n",
    "        \n",
    "    return filtered_max\n",
    "\n",
    "def apply_post_processing_debug(prob_pred, threshold=0.75):\n",
    "    print(f\"--- Post-Processing Start ---\")\n",
    "    print(f\"Input Probabilities - Max: {prob_pred.max():.4f}, Mean: {prob_pred.mean():.4f}\")\n",
    "    \n",
    "    # 1. CHECK THRESHOLD\n",
    "    if prob_pred.max() < threshold:\n",
    "        print(f\"!!! WARNING: Max probability ({prob_pred.max():.4f}) is LESS than threshold ({threshold}).\")\n",
    "        print(\"!!! The mask will be empty. Returning zeros.\")\n",
    "        # OPTION: Auto-adjust threshold for debugging\n",
    "        # threshold = prob_pred.max() * 0.9\n",
    "        # print(f\"!!! Auto-adjusted threshold to {threshold} for testing.\")\n",
    "        return np.zeros_like(prob_pred)\n",
    "\n",
    "    # 2. Create Mask\n",
    "    mask = (prob_pred > threshold).astype(np.float32)\n",
    "    \n",
    "    # 3. Run Filter\n",
    "    # We use scale_range=(1, 2) and step=1 (only sigma=1) first to be safe and fast\n",
    "    surfaceiness = modified_frangi_surface_3d_debug(mask, scale_range=(1, 3))\n",
    "    \n",
    "    return surfaceiness\n",
    "\n",
    "# RUN IT\n",
    "# final_output = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e40bba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Post-Processing Start ---\n",
      "Input Probabilities - Max: 0.9990, Mean: 0.2335\n",
      "--- Frangi Input Stats ---\n",
      "Shape: (320, 320, 320)\n",
      "Min: 0.0000, Max: 1.0000, Mean: 0.1666\n",
      "Non-zero voxels: 5459220\n",
      "\n",
      "Processing scale sigma=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "use_gaussian_derivatives currently defaults to False, but will change to True in a future version. Please specify this argument explicitly to maintain the current behavior\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Max Structureness (S): 0.3872\n",
      "  Mean Ra (Plate-ness): 0.0791 (Target: Low)\n",
      "  Max Response for this scale: 0.8609\n",
      "\n",
      "Processing scale sigma=2...\n",
      "  Max Structureness (S): 0.1151\n",
      "  Mean Ra (Plate-ness): 0.0812 (Target: Low)\n",
      "  Max Response for this scale: 0.8633\n",
      "Surfaceness Max: 0.8632922172546387\n",
      "Final Mask Non-zeros: 14884127\n"
     ]
    }
   ],
   "source": [
    "# 1. Run the debug/filter function\n",
    "surfaceness_map = apply_post_processing_debug(prob_pred, threshold=0.75)\n",
    "\n",
    "print(f\"Surfaceness Max: {surfaceness_map.max()}\") \n",
    "# If this prints ~0.86, your data is there! It just needs formatting.\n",
    "\n",
    "# 2. Normalize for Visualization (Optional, helps you see it)\n",
    "# Scales 0.0-0.86 to 0-255\n",
    "debug_image = (surfaceness_map / surfaceness_map.max() * 255).astype(np.uint8)\n",
    "\n",
    "# 3. Create Final Binary Mask (The actual segmentation)\n",
    "# We threshold the surfaceness score. \n",
    "# Since Frangi suppresses noise effectively, a low threshold like 0.1 usually works well.\n",
    "final_binary_mask = (surfaceness_map > 0.1).astype(np.uint8)\n",
    "\n",
    "print(f\"Final Mask Non-zeros: {final_binary_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf5c7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask = final_binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "653d3eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.nii.gz\n",
      "Loading image...\n",
      "Labeling individual elements...\n",
      "Initial count: 42 elements.\n",
      "Found 42 individual elements.\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2categorical.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2categorical.tif\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.4319570491142923),\n",
       " 'topo_score': 0.0022264114750084347,\n",
       " 'surface_dice': 0.467906312364647,\n",
       " 'voi_score': 0.764348332411895,\n",
       " 'voi_split': 0.20391522700797338,\n",
       " 'voi_merge': 0.8237648572127385}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_2/final_mask_step2.tif\"\n",
    "tifffile.imwrite(output_path, final_mask.astype(np.uint16)) # categorical label\n",
    "\n",
    "# Save as .nii.gz (Nibabel handles the gzipping automatically based on the extension)\n",
    "output_path_nii = f\"{output_path.replace('.tif', '.nii.gz')}\"\n",
    "print(output_path_nii)\n",
    "nii_data = np.transpose(final_mask, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "_ = split_by_object(input_path=output_path, output_path=output_path.replace('.tif', 'categorical.tif'))\n",
    "print(output_path.replace('.tif', 'categorical.tif'))\n",
    "\n",
    "pred_path = output_path\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=pred_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b1342",
   "metadata": {},
   "source": [
    "# Trying to do the Frangi filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94522a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "ðŸš€ Starting inference on dataset: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "ðŸ“‹ Using the following configuration:\n",
      "  ðŸ”¹ architecture: STU-Net\n",
      "  ðŸ”¹ patch_size: [128, 128, 128]\n",
      "  ðŸ”¹ device: cuda\n",
      "  ðŸ”¹ batch_size: 1\n",
      "  ðŸ”¹ num_workers: 4\n",
      "  ðŸ”¹ infer_sw_batch_size: 1\n",
      "  ðŸ”¹ blend_mode: gaussian\n",
      "  ðŸ”¹ deep_supervision: False\n",
      "  ðŸ”¹ activation: False\n",
      "  ðŸ”¹ infer_overlap: 0.5\n",
      "  ðŸ”¹ TTA: True\n",
      "  ðŸ”¹ TH: 0.5\n",
      "  ðŸ”¹ checkpoint_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "  ðŸ”¹ dataset_path_imgs: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "  ðŸ”¹ pred_save_dir: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:09<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:09<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:09<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:09<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from infer_class import VesuviusInferer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/topological-metrics-kaggle/src\"))\n",
    "\n",
    "case_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/1013184726.tif\"\n",
    "\n",
    "config_content = {\n",
    "  \"architecture\": \"STU-Net\",\n",
    "  \"patch_size\": [128, 128, 128],\n",
    "  \"device\": \"cuda\",\n",
    "  \"batch_size\": 1,\n",
    "  \"num_workers\": 4,\n",
    "\n",
    "  \"infer_sw_batch_size\": 1,\n",
    "  \"blend_mode\": \"gaussian\",\n",
    "  \"deep_supervision\": False,\n",
    "  \"activation\": False,\n",
    "\n",
    "  \"infer_overlap\": 0.5,\n",
    "  \"TTA\": True,\n",
    "  \"TH\": 0.5,\n",
    "\n",
    "  \"checkpoint_path\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\", \n",
    "  \"dataset_path_imgs\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\",\n",
    "  \"pred_save_dir\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\"\n",
    "}\n",
    "\n",
    "\n",
    "# ðŸ§ª Initialize Inference Object\n",
    "infer_object = VesuviusInferer(config_content)\n",
    "\n",
    "print(f\"ðŸš€ Starting inference on dataset: {config_content['dataset_path_imgs']}\")\n",
    "print(\"ðŸ“‹ Using the following configuration:\")\n",
    "for key, value in config_content.items():\n",
    "    print(f\"  ðŸ”¹ {key}: {value}\")\n",
    "\n",
    "\n",
    "### Select manually a case to run!\n",
    "input_data = {\n",
    "    'image': str(case_path),\n",
    "    'gt': None\n",
    "}\n",
    "\n",
    "logits_pred, pred_list = infer_object.infer(\n",
    "    input=input_data, \n",
    "    test=True, \n",
    "    threshold_list=[0.5] # CHANGED FROM 0.5\n",
    ")\n",
    "infer_object.save_nifti(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/1013184726.nii.gz\", \n",
    "    real_file=None\n",
    ")\n",
    "\n",
    "infer_object.save_tiff(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/1013184726.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ecbef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/1013184726.tif\n"
     ]
    }
   ],
   "source": [
    "print(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/1013184726.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9baa4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def _gaussian_1d(sigma, device, dtype):\n",
    "    radius = int(3 * sigma)\n",
    "    x = torch.arange(-radius, radius + 1, device=device, dtype=dtype)\n",
    "    gauss = torch.exp(-x**2 / (2 * sigma**2))\n",
    "    gauss = gauss / gauss.sum()\n",
    "    d1 = -x / (sigma**2) * gauss\n",
    "    d2 = (x**2 - sigma**2) / (sigma**4) * gauss\n",
    "    return gauss, d1, d2\n",
    "\n",
    "\n",
    "def _conv_sep_3d(volume, kx, ky, kz):\n",
    "    volume = F.conv3d(volume, kx[None, None, :, None, None], padding=(kx.numel()//2, 0, 0))\n",
    "    volume = F.conv3d(volume, ky[None, None, None, :, None], padding=(0, ky.numel()//2, 0))\n",
    "    volume = F.conv3d(volume, kz[None, None, None, None, :], padding=(0, 0, kz.numel()//2))\n",
    "    return volume\n",
    "\n",
    "\n",
    "def _hessian_3d_torch(volume, sigma):\n",
    "    device = volume.device\n",
    "    dtype = volume.dtype\n",
    "    g, g1, g2 = _gaussian_1d(sigma, device, dtype)\n",
    "    Hxx = _conv_sep_3d(volume, g2, g, g)\n",
    "    Hyy = _conv_sep_3d(volume, g, g2, g)\n",
    "    Hzz = _conv_sep_3d(volume, g, g, g2)\n",
    "    Hxy = _conv_sep_3d(volume, g1, g1, g)\n",
    "    Hxz = _conv_sep_3d(volume, g1, g, g1)\n",
    "    Hyz = _conv_sep_3d(volume, g, g1, g1)\n",
    "    s2 = sigma ** 2\n",
    "    return Hxx * s2, Hyy * s2, Hzz * s2, Hxy * s2, Hxz * s2, Hyz * s2\n",
    "\n",
    "\n",
    "def frangi_surfaceness_3d_torch(\n",
    "    volume,\n",
    "    sigmas=(0.5, 1.0, 1.5, 2.0),\n",
    "    beta=0.5,\n",
    "    gamma=None,\n",
    "    bright_surface=True,\n",
    "    eps=1e-12\n",
    "):\n",
    "    # Ensure shape = (1,1,D,H,W)\n",
    "    if volume.ndim == 3:\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "    elif volume.ndim == 4:\n",
    "        volume = volume.unsqueeze(0)\n",
    "    elif volume.ndim != 5:\n",
    "        raise ValueError(\"volume must be 3D, 4D, or 5D tensor\")\n",
    "\n",
    "    volume = volume.float()\n",
    "    device = volume.device\n",
    "    output = torch.zeros_like(volume)\n",
    "\n",
    "    # sanitize input\n",
    "    volume = torch.nan_to_num(volume, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    volume = volume.clamp(0.0, 1.0)\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        sigma = float(sigma)\n",
    "        Hxx, Hyy, Hzz, Hxy, Hxz, Hyz = _hessian_3d_torch(volume, sigma)\n",
    "\n",
    "        # Build Hessian\n",
    "        H = torch.stack([\n",
    "            torch.stack([Hxx, Hxy, Hxz], dim=-1),\n",
    "            torch.stack([Hxy, Hyy, Hyz], dim=-1),\n",
    "            torch.stack([Hxz, Hyz, Hzz], dim=-1)\n",
    "        ], dim=-2)\n",
    "\n",
    "        # Clamp Hessian to remove NaNs/Infs\n",
    "        H = torch.nan_to_num(H, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        # Compute eigenvalues safely on CPU\n",
    "        eigvals = torch.linalg.eigvalsh(H.cpu()).to(device)\n",
    "\n",
    "        # Sort by absolute value\n",
    "        idx = torch.argsort(eigvals.abs(), dim=-1)\n",
    "        eigvals = torch.gather(eigvals, -1, idx)\n",
    "\n",
    "        l1 = eigvals[..., 0]\n",
    "        l2 = eigvals[..., 1]\n",
    "        l3 = eigvals[..., 2]\n",
    "\n",
    "        valid = l3 < 0 if bright_surface else l3 > 0\n",
    "\n",
    "        RB = l2.abs() / (l3.abs() + eps)\n",
    "        S = torch.sqrt(l1**2 + l2**2 + l3**2)\n",
    "        gamma_scale = gamma if gamma is not None else 0.5 * S.max()\n",
    "\n",
    "        term1 = torch.exp(-(RB**2) / (2 * beta**2))\n",
    "        term2 = 1 - torch.exp(-(S**2) / (2 * gamma_scale**2 + eps))\n",
    "\n",
    "        response = torch.zeros_like(volume)\n",
    "        response[valid] = (term1 * term2)[valid]\n",
    "\n",
    "        output = torch.maximum(output, response)\n",
    "\n",
    "    # Normalize\n",
    "    output = output / (output.max() + eps)\n",
    "    return output.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374aac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_pred: torch.Size([320, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "logits_pred = logits_pred.squeeze()\n",
    "print(f\"logits_pred: {logits_pred.shape}\")\n",
    "#prob = torch.sigmoid(logits_pred)[0][0].to(\"cuda\")  # shape (D, H, W) or (1, D, H, W)\n",
    "#surf = frangi_surfaceness_3d_torch(prob, sigmas=(0.5, 1.0, 1.5, 2.0))\n",
    "\n",
    "# Baseline\n",
    "prob = torch.sigmoid(logits_pred).to(\"cuda\")\n",
    "\n",
    "CROP_MARGIN = 9\n",
    "prob[:CROP_MARGIN, :, :] = 0\n",
    "prob[-CROP_MARGIN:, :, :] = 0\n",
    "prob[:, :CROP_MARGIN, :] = 0\n",
    "prob[:, -CROP_MARGIN:, :] = 0\n",
    "prob[:, :, :CROP_MARGIN] = 0\n",
    "prob[:, :, -CROP_MARGIN:] = 0\n",
    "\n",
    "#binary_mask = (prob > 0.75).float()  # threshold similar to baseline\n",
    "#surf = frangi_surfaceness_3d_torch(binary_mask, sigmas=(1.0,1.5,2.0))\n",
    "surf = frangi_surfaceness_3d_torch(prob, sigmas=(0.8, 1.2, 1.6, 2.0))  # slightly larger sigma\n",
    "enhanced = prob + 0.4 * surf * (1 - prob)\n",
    "binary = enhanced > 0.5\n",
    "binary_original = np.transpose(binary.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# fuse safely\n",
    "enhanced = binary_mask + 0.5 * surf  # alpha=0.5, baseline-style\n",
    "binary = enhanced > 0.5          # threshold after fusion\n",
    "binary = np.transpose(binary.squeeze().cpu().numpy(), (2, 1, 0))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enhanced = prob + 0.4 * surf * (1 - prob)\n",
    "#binary = enhanced > 0.75\n",
    "#binary = np.transpose(binary.squeeze().cpu().numpy(), (2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b95134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enhanced = prob_pred * (1 + surf)\n",
    "#binary = enhanced > 0.75\n",
    "#binary = np.transpose(binary.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "#binary = surf > 0.2\n",
    "#binary = np.transpose(binary.squeeze().cpu().numpy(), (2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ebcc9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_opening\n",
    "import numpy as np\n",
    "\n",
    "def erode_2d_yz(vol, s):\n",
    "    \"\"\"\n",
    "    Apply 2D binary opening on each slice along the yz-plane\n",
    "    to remove bridges along x while preserving sheets in y-z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vol : ndarray (z, y, x)\n",
    "    s : int : structuring element size along y and z\n",
    "    \"\"\"\n",
    "    z, y, x = vol.shape\n",
    "    se2 = np.ones((s, s))\n",
    "    \n",
    "    # Apply opening slice by slice along x (yz-plane)\n",
    "    vol_yz = np.stack([binary_opening(vol[:, :, i], structure=se2) for i in range(x)], axis=2)\n",
    "    return vol_yz\n",
    "\n",
    "binary = erode_2d_yz(vol=binary, s=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "717403e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def competitive_hysteresis(probs, low=0.55, high=0.85):\n",
    "    \"\"\"\n",
    "    Grows high-confidence sheets into low-confidence areas,\n",
    "    but prevents them from merging if they were originally separate.\n",
    "    \"\"\"\n",
    "    # 1. Create Masks\n",
    "    mask_high = probs > high  # The \"Seeds\" (Separated sheets)\n",
    "    mask_low  = probs > low   # The \"Land\" (Full shape with bridges)\n",
    "\n",
    "    # 2. Label the High Confidence Seeds\n",
    "    # Each sheet gets a unique ID (1, 2, 3...)\n",
    "    seeds, num_seeds = ndi.label(mask_high)\n",
    "    \n",
    "    # 3. Geodesic Reconstruction (Dilation)\n",
    "    # We want to reconstruct 'seeds' inside 'mask_low'.\n",
    "    # Standard 'reconstruction' would merge them if the low-mask connects them.\n",
    "    # To prevent merging, we can use a Watershed on the distance transform \n",
    "    # constrained to the 'mask_low'.\n",
    "    \n",
    "    # Calculate distance from the seeds *within* the low mask\n",
    "    # We invert logic: distance typically grows from background, so we construct\n",
    "    # a cost map where high-prob areas are 'cheap' to travel through.\n",
    "    cost_map = -probs \n",
    "    \n",
    "    # Use Watershed\n",
    "    # seeds: The markers (1, 2, 3...)\n",
    "    # mask: The valid area to grow into (mask_low)\n",
    "    from skimage.segmentation import watershed\n",
    "    \n",
    "    reconstructed_labels = watershed(cost_map, seeds, mask=mask_low)\n",
    "    \n",
    "    return reconstructed_labels > 0\n",
    "\n",
    "# Usage\n",
    "binary_original = competitive_hysteresis(enhanced.squeeze().cpu().numpy(), low=0.75, high=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fde27b0",
   "metadata": {},
   "source": [
    "# If bigger than a threshold of voxels, destroy harder individual elements (for cases with bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641efd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_certain_1013184726.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_certain_1013184726.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the sheets bigger than threshold = 50000\n",
    "THRESHOLD = 50000\n",
    "\n",
    "# Remove small objects\n",
    "binary_original = split_by_object_np(binary_original)\n",
    "binary_original = remove_small_objects(binary_original, min_size=5000, connectivity=1)\n",
    "binary_original[binary_original>0.5] = 1\n",
    "categorical_mask = split_by_object_np(binary_original) \n",
    "\n",
    "# Kepp only the volumes bigger than THRESHOLD\n",
    "labels, counts = np.unique(categorical_mask, return_counts=True)\n",
    "keep_labels = labels[(counts > THRESHOLD) & (labels != 0)]\n",
    "filtered_mask = np.where(np.isin(categorical_mask, keep_labels), categorical_mask, 0)\n",
    "\n",
    "# Make the filtered mask binary\n",
    "filtered_mask[filtered_mask>0.5] = 1\n",
    "\n",
    "# Remove the first prediction\n",
    "binary_original[filtered_mask==1] = 0\n",
    "\n",
    "# Add now the more certain volume in the region removed before\n",
    "binary_certain = enhanced > 0.90\n",
    "binary_certain = np.transpose(binary_certain.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "binary_original[binary_certain==1] = 1\n",
    "binary_original = split_by_object_np(binary_original)\n",
    "binary_original = remove_small_objects(binary_original, min_size=5000, connectivity=1)\n",
    "binary_original[binary_original>0.5] = 1\n",
    "\n",
    "#binary_original = apply_hysteresis_threshold(binary_original, 0.3, 0.75)\n",
    "\n",
    "output_path_final = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/binary_original_certain_1013184726.tif\"\n",
    "tifffile.imwrite(output_path_final, binary_original.astype(np.uint16))\n",
    "\n",
    "_ = split_by_object(\n",
    "    output_path_final, \n",
    "    \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_certain_1013184726.tif\")\n",
    "\n",
    "print(f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_certain_1013184726.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5d7baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing tunnels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [05:57<00:00, 13.26s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def close_tunnels_per_label_fast(volume, hole_radius=2):\n",
    "    \"\"\"\n",
    "    Optimized version: Process bounding boxes instead of full volumes.\n",
    "    \"\"\"\n",
    "    # 1. Label the volume (if not already labeled)\n",
    "    # Ensure this returns integer labels. \n",
    "    # If 'volume' is already labeled (int), you can skip split_by_object_np.\n",
    "    if volume.dtype == bool or (np.issubdtype(volume.dtype, np.integer) and volume.max() <= 1):\n",
    "        # Use existing function or fall back to ndi.label\n",
    "        try:\n",
    "            labeled_volume = split_by_object_np(volume)\n",
    "        except NameError:\n",
    "            labeled_volume, _ = ndi.label(volume)\n",
    "    else:\n",
    "        labeled_volume = volume\n",
    "\n",
    "    # 2. Find Bounding Boxes for all objects at once\n",
    "    # This is extremely fast and returns a list of slice tuples \n",
    "    # e.g. [(slice(0,10), slice(5,15), ...), ...]\n",
    "    object_slices = ndi.find_objects(labeled_volume)\n",
    "    \n",
    "    # 3. Define Footprint (Structuring Element)\n",
    "    structure_size = 2 * hole_radius + 1\n",
    "    z, y, x = np.ogrid[:structure_size, :structure_size, :structure_size]\n",
    "    center = hole_radius\n",
    "    footprint = ((z-center)**2 + (y-center)**2 + (x-center)**2 <= hole_radius**2)\n",
    "\n",
    "    # 4. Process each object in its own little box\n",
    "    output_volume = np.zeros_like(labeled_volume)\n",
    "\n",
    "    # Note: ndi.find_objects returns slices for labels 1, 2, 3... in order.\n",
    "    for idx, slices in tqdm(enumerate(object_slices), total=len(object_slices), desc=\"Closing tunnels\"):\n",
    "        if slices is None: continue # Label index might be missing in sequence\n",
    "        \n",
    "        label_id = idx + 1\n",
    "        \n",
    "        # --- KEY OPTIMIZATION: Expand the slice (Padding) ---\n",
    "        # We must pad the bounding box by 'hole_radius'. \n",
    "        # If we don't, the 'closing' (dilation) will hit the edge of the crop \n",
    "        # and be cut off, creating artifacts.\n",
    "        padded_slices = []\n",
    "        for dim, s in enumerate(slices):\n",
    "            # Pad start and stop, clipping to volume boundaries\n",
    "            start = max(0, s.start - hole_radius)\n",
    "            stop = min(labeled_volume.shape[dim], s.stop + hole_radius)\n",
    "            padded_slices.append(slice(start, stop))\n",
    "        padded_slices = tuple(padded_slices)\n",
    "\n",
    "        # --- Extract Crop ---\n",
    "        # This creates a view or small copy, much smaller than full volume\n",
    "        sub_vol = labeled_volume[padded_slices]\n",
    "        \n",
    "        # --- Local Mask ---\n",
    "        binary_sheet = (sub_vol == label_id)\n",
    "        \n",
    "        # --- Apply Closing (Fast on small array) ---\n",
    "        closed_sheet = ndi.binary_closing(binary_sheet, structure=footprint)\n",
    "        \n",
    "        # --- Write Back ---\n",
    "        # We only update the specific region in the output volume\n",
    "        # Use boolean indexing on the crop to assign the label\n",
    "        output_crop = output_volume[padded_slices]\n",
    "        output_crop[closed_sheet] = label_id\n",
    "\n",
    "    return output_volume\n",
    "\n",
    "binary_original = close_tunnels_per_label_fast(binary_original, hole_radius=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0ad4057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating kernels and moving to GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:14<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.measure import regionprops\n",
    "import cupy as cp\n",
    "import cupyx.scipy.ndimage as ndimage_gpu\n",
    "from skimage import morphology\n",
    "\n",
    "labeled_volume = split_by_object_np(binary_original) \n",
    "labeled_volume = remove_small_objects(labeled_volume, min_size=1000, connectivity=1)\n",
    "labels = split_by_object_np(labeled_volume) \n",
    "\n",
    "DILATION_RADIUS = 9\n",
    "EROSION_RADIUS = 9\n",
    "MEDIAN_FILTER_SIZE = 1\n",
    "\n",
    "print(\"Creating kernels and moving to GPU...\")\n",
    "# 1. Create balls on CPU\n",
    "cpu_ball_dilate = morphology.ball(DILATION_RADIUS)\n",
    "cpu_ball_erode = morphology.ball(EROSION_RADIUS)\n",
    "\n",
    "# 2. Move to GPU (do this ONCE, not in the loop)\n",
    "gpu_ball_dilate = cp.array(cpu_ball_dilate)\n",
    "gpu_ball_erode = cp.array(cpu_ball_erode)\n",
    "\n",
    "\n",
    "PAD_WIDTH = 3\n",
    "dtype_out =  np.uint16\n",
    "filled_labels = np.zeros_like(labels, dtype=dtype_out)\n",
    "for region in tqdm(regionprops(labeled_volume), desc=f\"Processing\"):\n",
    "\n",
    "    label_id = region.label\n",
    "\n",
    "    # --- CPU PART (Slicing is fast on CPU) ---\n",
    "    bbox = region.bbox\n",
    "    minr, minc, mins, maxr, maxc, maxs = bbox\n",
    "    slices = (slice(minr, maxr), slice(minc, maxc), slice(mins, maxs))\n",
    "\n",
    "    # Extract binary sub-volume\n",
    "    sub = (labeled_volume[slices] == label_id)\n",
    "\n",
    "    # 2. Pad (CPU)\n",
    "    sub_padded = np.pad(sub, PAD_WIDTH, mode='constant', constant_values=0)\n",
    "\n",
    "    # --- GPU PART (Heavy lifting) ---\n",
    "    # 3. Transfer to VRAM\n",
    "    gpu_sub = cp.array(sub_padded)\n",
    "\n",
    "    # 4. Solidify (Dilation + Erosion)\n",
    "    # Note: We use 'structure=' to pass our pre-loaded ball\n",
    "    gpu_sub = ndimage_gpu.binary_dilation(gpu_sub, structure=gpu_ball_dilate)\n",
    "    gpu_sub = ndimage_gpu.binary_erosion(gpu_sub, structure=gpu_ball_erode)\n",
    "\n",
    "    # 5. Fill Internal Holes\n",
    "    gpu_sub = ndimage_gpu.binary_fill_holes(gpu_sub)\n",
    "\n",
    "    # 6. Ironing / Straightening (Median Filter)\n",
    "    if MEDIAN_FILTER_SIZE > 0:\n",
    "        gpu_sub = ndimage_gpu.median_filter(gpu_sub, size=MEDIAN_FILTER_SIZE)\n",
    "\n",
    "    # --- RETRIEVE PART ---\n",
    "    # 7. Pull back to CPU\n",
    "    sub_filled = gpu_sub.get()\n",
    "\n",
    "    # 8. Un-pad\n",
    "    sub_final = sub_filled[PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH, PAD_WIDTH:-PAD_WIDTH]\n",
    "\n",
    "    # 9. Write back\n",
    "    out_block = filled_labels[slices]\n",
    "    out_block[sub_final] = label_id\n",
    "    filled_labels[slices] = out_block\n",
    "    \n",
    "binary_original = filled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ae25c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved closed volume to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/frangi_surfaceness_3d_1013184726.tif\n",
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_holes_1013184726.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.2668996050404696),\n",
       " 'topo_score': 0.008774570949288142,\n",
       " 'surface_dice': 0.2724496970251618,\n",
       " 'voi_score': 0.48259954227679,\n",
       " 'voi_split': 2.2499084304029036,\n",
       " 'voi_merge': 1.3237961451839801}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path_final = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/frangi_surfaceness_3d_1013184726.tif\"\n",
    "tifffile.imwrite(output_path_final, binary_original.astype(np.uint16))\n",
    "print(f\"Saved closed volume to: {output_path_final}\")\n",
    "\n",
    "_ = split_by_object(\n",
    "    output_path_final, \n",
    "    \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_3/categorical_rm_holes_1013184726.tif\")\n",
    "\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1013184726.tif\"\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=output_path_final,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781be2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os resultados sÃ£o muito afetados pelas pontes e pelos buracos\n",
    "# Quando hÃ¡ pontes, o DSc desce porque ao encher os burcaros cria mais pontes entre eles, criando muito mÃ¡s segmentaÃ§Ãµes. \n",
    "# Tentar criar o mÃ­nimo de pontes possiveis e depois encher os buracos parece a opÃ§Ã£o melhor\n",
    "{'image_score': np.float64(0.47798227345567024),\n",
    " 'topo_score': 0.12032620403138944,\n",
    " 'surface_dice': 0.7196147723640545,\n",
    " 'voi_score': 0.5429121197680981,\n",
    " 'voi_split': 1.6856426999634104,\n",
    " 'voi_merge': 1.1207530535343784}\n",
    "\n",
    "# baseline\n",
    "{'image_score': np.float64(0.48135781602218675),\n",
    " 'topo_score': 0.11849382528979469,\n",
    " 'surface_dice': 0.7291011117407524,\n",
    " 'voi_score': 0.5446407980742428,\n",
    " 'voi_split': 1.6841425705660977,\n",
    " 'voi_merge': 1.102765813429556}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5308cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2536049117\n",
    "{'image_score': np.float64(0.7855649923931747),\n",
    " 'topo_score': 0.8148148148148148,\n",
    " 'surface_dice': 0.9261704128848708,\n",
    " 'voi_score': 0.6198882955400724,\n",
    " 'voi_split': 1.0055659495696496,\n",
    " 'voi_merge': 1.0384136254318896}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9cff4",
   "metadata": {},
   "source": [
    "# Compare two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "326b104e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tif_paths_1</th>\n",
       "      <th>id</th>\n",
       "      <th>pred_paths_1</th>\n",
       "      <th>image_score_1</th>\n",
       "      <th>topo_score_1</th>\n",
       "      <th>surface_dice_1</th>\n",
       "      <th>voi_score_1</th>\n",
       "      <th>voi_split_1</th>\n",
       "      <th>voi_merge_1</th>\n",
       "      <th>tif_paths_2</th>\n",
       "      <th>pred_paths_2</th>\n",
       "      <th>image_score_2</th>\n",
       "      <th>topo_score_2</th>\n",
       "      <th>surface_dice_2</th>\n",
       "      <th>voi_score_2</th>\n",
       "      <th>voi_split_2</th>\n",
       "      <th>voi_merge_2</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>3545147380</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.530518</td>\n",
       "      <td>0.079482</td>\n",
       "      <td>0.898432</td>\n",
       "      <td>0.549207</td>\n",
       "      <td>1.132644</td>\n",
       "      <td>1.603384</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.511396</td>\n",
       "      <td>0.312285</td>\n",
       "      <td>0.640790</td>\n",
       "      <td>0.552668</td>\n",
       "      <td>1.256705</td>\n",
       "      <td>1.441316</td>\n",
       "      <td>0.257642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>1796762532</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.455817</td>\n",
       "      <td>0.128292</td>\n",
       "      <td>0.716930</td>\n",
       "      <td>0.475441</td>\n",
       "      <td>1.320494</td>\n",
       "      <td>2.357207</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.350261</td>\n",
       "      <td>0.032163</td>\n",
       "      <td>0.472553</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>1.381204</td>\n",
       "      <td>1.943801</td>\n",
       "      <td>0.244377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>1734818300</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.410514</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.654723</td>\n",
       "      <td>0.444899</td>\n",
       "      <td>1.868641</td>\n",
       "      <td>2.290368</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.380814</td>\n",
       "      <td>0.211443</td>\n",
       "      <td>0.451983</td>\n",
       "      <td>0.454821</td>\n",
       "      <td>1.701104</td>\n",
       "      <td>2.294460</td>\n",
       "      <td>0.202740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>3897872090</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.605422</td>\n",
       "      <td>0.261549</td>\n",
       "      <td>0.945433</td>\n",
       "      <td>0.560159</td>\n",
       "      <td>0.720299</td>\n",
       "      <td>1.897058</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.605860</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.743014</td>\n",
       "      <td>0.579853</td>\n",
       "      <td>0.644431</td>\n",
       "      <td>1.770819</td>\n",
       "      <td>0.202419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>928131323</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.609732</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>0.936340</td>\n",
       "      <td>0.578034</td>\n",
       "      <td>1.162442</td>\n",
       "      <td>1.270903</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.561472</td>\n",
       "      <td>0.352724</td>\n",
       "      <td>0.734871</td>\n",
       "      <td>0.566999</td>\n",
       "      <td>0.988218</td>\n",
       "      <td>1.557350</td>\n",
       "      <td>0.201468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>114235076</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.363203</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.395123</td>\n",
       "      <td>0.634450</td>\n",
       "      <td>1.124610</td>\n",
       "      <td>0.795953</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.350638</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.352294</td>\n",
       "      <td>0.632130</td>\n",
       "      <td>1.102530</td>\n",
       "      <td>0.837315</td>\n",
       "      <td>0.042829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>1013184726</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.488282</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>0.740974</td>\n",
       "      <td>0.549053</td>\n",
       "      <td>1.675571</td>\n",
       "      <td>1.062153</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.519370</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.700940</td>\n",
       "      <td>0.550175</td>\n",
       "      <td>1.638450</td>\n",
       "      <td>1.086890</td>\n",
       "      <td>0.040034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>821686014</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.055543</td>\n",
       "      <td>0.600934</td>\n",
       "      <td>0.620030</td>\n",
       "      <td>0.876180</td>\n",
       "      <td>1.166573</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.428734</td>\n",
       "      <td>0.046190</td>\n",
       "      <td>0.562462</td>\n",
       "      <td>0.622901</td>\n",
       "      <td>0.839672</td>\n",
       "      <td>1.178298</td>\n",
       "      <td>0.038472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>2536049117</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.624496</td>\n",
       "      <td>0.198421</td>\n",
       "      <td>0.952325</td>\n",
       "      <td>0.661873</td>\n",
       "      <td>0.805978</td>\n",
       "      <td>0.896902</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.773247</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.915851</td>\n",
       "      <td>0.650569</td>\n",
       "      <td>0.893910</td>\n",
       "      <td>0.896478</td>\n",
       "      <td>0.036474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>3406708348</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.179522</td>\n",
       "      <td>0.942109</td>\n",
       "      <td>0.586224</td>\n",
       "      <td>1.319197</td>\n",
       "      <td>1.033579</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>/home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...</td>\n",
       "      <td>0.669121</td>\n",
       "      <td>0.489694</td>\n",
       "      <td>0.911303</td>\n",
       "      <td>0.580733</td>\n",
       "      <td>1.220489</td>\n",
       "      <td>1.186055</td>\n",
       "      <td>0.030806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tif_paths_1          id  \\\n",
       "70  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  3545147380   \n",
       "49  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  1796762532   \n",
       "11  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  1734818300   \n",
       "8   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  3897872090   \n",
       "52  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   928131323   \n",
       "..                                                ...         ...   \n",
       "44  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   114235076   \n",
       "62  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  1013184726   \n",
       "25  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   821686014   \n",
       "75  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  2536049117   \n",
       "6   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...  3406708348   \n",
       "\n",
       "                                         pred_paths_1  image_score_1  \\\n",
       "70  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.530518   \n",
       "49  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.455817   \n",
       "11  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.410514   \n",
       "8   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.605422   \n",
       "52  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.609732   \n",
       "..                                                ...            ...   \n",
       "44  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.363203   \n",
       "62  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.488282   \n",
       "25  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.444000   \n",
       "75  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.624496   \n",
       "6   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.588773   \n",
       "\n",
       "    topo_score_1  surface_dice_1  voi_score_1  voi_split_1  voi_merge_1  \\\n",
       "70      0.079482        0.898432     0.549207     1.132644     1.603384   \n",
       "49      0.128292        0.716930     0.475441     1.320494     2.357207   \n",
       "11      0.085487        0.654723     0.444899     1.868641     2.290368   \n",
       "8       0.261549        0.945433     0.560159     0.720299     1.897058   \n",
       "52      0.265672        0.936340     0.578034     1.162442     1.270903   \n",
       "..           ...             ...          ...          ...          ...   \n",
       "44      0.009510        0.395123     0.634450     1.124610     0.795953   \n",
       "62      0.122576        0.740974     0.549053     1.675571     1.062153   \n",
       "25      0.055543        0.600934     0.620030     0.876180     1.166573   \n",
       "75      0.198421        0.952325     0.661873     0.805978     0.896902   \n",
       "6       0.179522        0.942109     0.586224     1.319197     1.033579   \n",
       "\n",
       "                                          tif_paths_2  \\\n",
       "70  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "49  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "11  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "8   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "52  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "..                                                ...   \n",
       "44  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "62  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "25  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "75  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "6   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...   \n",
       "\n",
       "                                         pred_paths_2  image_score_2  \\\n",
       "70  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.511396   \n",
       "49  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.350261   \n",
       "11  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.380814   \n",
       "8   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.605860   \n",
       "52  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.561472   \n",
       "..                                                ...            ...   \n",
       "44  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.350638   \n",
       "62  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.519370   \n",
       "25  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.428734   \n",
       "75  /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.773247   \n",
       "6   /home/shadowtwin/Desktop/AI_work/Vesuvius_Chal...       0.669121   \n",
       "\n",
       "    topo_score_2  surface_dice_2  voi_score_2  voi_split_2  voi_merge_2  \\\n",
       "70      0.312285        0.640790     0.552668     1.256705     1.441316   \n",
       "49      0.032163        0.472553     0.500625     1.381204     1.943801   \n",
       "11      0.211443        0.451983     0.454821     1.701104     2.294460   \n",
       "8       0.476190        0.743014     0.579853     0.644431     1.770819   \n",
       "52      0.352724        0.734871     0.566999     0.988218     1.557350   \n",
       "..           ...             ...          ...          ...          ...   \n",
       "44      0.020299        0.352294     0.632130     1.102530     0.837315   \n",
       "62      0.271600        0.700940     0.550175     1.638450     1.086890   \n",
       "25      0.046190        0.562462     0.622901     0.839672     1.178298   \n",
       "75      0.750000        0.915851     0.650569     0.893910     0.896478   \n",
       "6       0.489694        0.911303     0.580733     1.220489     1.186055   \n",
       "\n",
       "    difference  \n",
       "70    0.257642  \n",
       "49    0.244377  \n",
       "11    0.202740  \n",
       "8     0.202419  \n",
       "52    0.201468  \n",
       "..         ...  \n",
       "44    0.042829  \n",
       "62    0.040034  \n",
       "25    0.038472  \n",
       "75    0.036474  \n",
       "6     0.030806  \n",
       "\n",
       "[80 rows x 18 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_pred = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/BCE_Tversky_DAsafe_epoch_model_best_TTA_overlap_0.5_th_0.5.csv\"\n",
    "post_process = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/results_post.csv\"\n",
    "df1 = pd.read_csv(origin_pred)\n",
    "df2 = pd.read_csv(post_process)\n",
    "\n",
    "df1['id'] = df1['id'].astype(str)\n",
    "df2['id'] = df2['id'].astype(str)\n",
    "\n",
    "# 2. Merge\n",
    "merged_df = pd.merge(df1, df2, on='id', suffixes=('_1', '_2'))\n",
    "\n",
    "# 3. Calculate difference\n",
    "merged_df['difference'] = (merged_df['surface_dice_1'] - merged_df['surface_dice_2']).abs()\n",
    "\n",
    "# 4. Sort and view\n",
    "result = merged_df.sort_values(by='difference', ascending=False)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32a1a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7113a984",
   "metadata": {},
   "source": [
    "# Vesuvius post-processing proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d12113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "ðŸš€ Starting inference on dataset: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "ðŸ“‹ Using the following configuration:\n",
      "  ðŸ”¹ architecture: STU-Net\n",
      "  ðŸ”¹ patch_size: [128, 128, 128]\n",
      "  ðŸ”¹ device: cuda\n",
      "  ðŸ”¹ batch_size: 1\n",
      "  ðŸ”¹ num_workers: 4\n",
      "  ðŸ”¹ infer_sw_batch_size: 1\n",
      "  ðŸ”¹ blend_mode: gaussian\n",
      "  ðŸ”¹ deep_supervision: False\n",
      "  ðŸ”¹ activation: False\n",
      "  ðŸ”¹ infer_overlap: 0.5\n",
      "  ðŸ”¹ TTA: True\n",
      "  ðŸ”¹ TH: 0.5\n",
      "  ðŸ”¹ checkpoint_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\n",
      "  ðŸ”¹ dataset_path_imgs: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\n",
      "  ðŸ”¹ pred_save_dir: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from infer_class import VesuviusInferer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/topological-metrics-kaggle/src\"))\n",
    "from torch.nn.functional import sigmoid\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageSequence\n",
    "import sys\n",
    "import os\n",
    "import tifffile\n",
    "\n",
    "case_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3545147380.tif\"\n",
    "\n",
    "config_content = {\n",
    "  \"architecture\": \"STU-Net\",\n",
    "  \"patch_size\": [128, 128, 128],\n",
    "  \"device\": \"cuda\",\n",
    "  \"batch_size\": 1,\n",
    "  \"num_workers\": 4,\n",
    "\n",
    "  \"infer_sw_batch_size\": 1,\n",
    "  \"blend_mode\": \"gaussian\",\n",
    "  \"deep_supervision\": False,\n",
    "  \"activation\": False,\n",
    "\n",
    "  \"infer_overlap\": 0.5,\n",
    "  \"TTA\": True,\n",
    "  \"TH\": 0.5,\n",
    "\n",
    "  \"checkpoint_path\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/checkpoints/second_step/BCE_Tversky_DAsafe/model_best.pth\", \n",
    "  \"dataset_path_imgs\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\",\n",
    "  \"pred_save_dir\": \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash\"\n",
    "}\n",
    "\n",
    "\n",
    "# ðŸ§ª Initialize Inference Object\n",
    "infer_object = VesuviusInferer(config_content)\n",
    "\n",
    "print(f\"ðŸš€ Starting inference on dataset: {config_content['dataset_path_imgs']}\")\n",
    "print(\"ðŸ“‹ Using the following configuration:\")\n",
    "for key, value in config_content.items():\n",
    "    print(f\"  ðŸ”¹ {key}: {value}\")\n",
    "\n",
    "\n",
    "### Select manually a case to run!\n",
    "input_data = {\n",
    "    'image': str(case_path),\n",
    "    'gt': None\n",
    "}\n",
    "\n",
    "logits_pred, pred_list = infer_object.infer(\n",
    "    input=input_data, \n",
    "    test=True, \n",
    "    threshold_list=[0.5] # CHANGED FROM 0.5\n",
    ")\n",
    "infer_object.save_nifti(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/3545147380.nii.gz\", \n",
    "    real_file=None\n",
    ")\n",
    "\n",
    "infer_object.save_tiff(\n",
    "    torch_tensor=pred_list[0], \n",
    "    save_path=\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/3545147380.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "884af186",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = tifffile.imread(case_path)\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/vol_2536049117.nii.gz\"\n",
    "nii_data = np.transpose(numpy_array, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "numpy_array = tifffile.imread(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\")\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/gt_2536049117.nii.gz\"\n",
    "nii_data = np.transpose(numpy_array, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0597db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_no_post_pred_2536049117.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.6075685870946677),\n",
       " 'topo_score': 0.14337035751475186,\n",
       " 'surface_dice': 0.951139313542954,\n",
       " 'voi_score': 0.6618820574291663,\n",
       " 'voi_split': 0.8086779664586242,\n",
       " 'voi_merge': 0.8941326716588209}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No post-process\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "prob_pred = (prob_pred > 0.5).astype(np.uint16)\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/no_post_pred_2536049117.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\"\n",
    "tifffile.imwrite(out_path, prob_pred)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_no_post_pred_2536049117.tif\")\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "16a34faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_3545147380.tif\n",
      "Done!\n",
      "/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/2536049117.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5510487366220043),\n",
       " 'topo_score': 0.0067346938775510205,\n",
       " 'surface_dice': 0.8299907536265267,\n",
       " 'voi_score': 0.7386616133984414,\n",
       " 'voi_split': 0.22290054681191313,\n",
       " 'voi_merge': 0.9564323703687093}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.filters import apply_hysteresis_threshold\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "#prob_pred = (prob_pred > 0.8).astype(np.uint16)\n",
    "prob_pred = apply_hysteresis_threshold(prob_pred, 0.5, 0.50)\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/hysteresis_th0375_mask_3545147380.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, prob_pred)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_3545147380.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "print(pred_path)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a881e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_object_np(binary_mask):\n",
    "    # Ensure the volume is treated as a binary mask for labeling\n",
    "    # (This assumes all objects you want to separate are non-zero)\n",
    "    binary_mask = binary_mask > 0\n",
    "\n",
    "    # 2. Perform Connected Component Labeling\n",
    "    # connectivity=None defaults to allowing diagonal connections. \n",
    "    # Use connectivity=1 for strict face-to-face connections only.\n",
    "    labeled_volume = label(binary_mask, connectivity=None)\n",
    "\n",
    "    # 3. Optimize Data Type to save space\n",
    "    # We check how many objects were found to choose the smallest file size possible.\n",
    "    num_features = np.max(labeled_volume)\n",
    "    if num_features < 255:\n",
    "        final_volume = labeled_volume.astype(np.uint8)\n",
    "    elif num_features < 65535:\n",
    "        final_volume = labeled_volume.astype(np.uint16)\n",
    "    else:\n",
    "        final_volume = labeled_volume.astype(np.uint32)\n",
    "    return final_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "198d2e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_2536049117.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5398912721265068),\n",
       " 'topo_score': 0.11573710395391464,\n",
       " 'surface_dice': 0.8952125287867327,\n",
       " 'voi_score': 0.548130731042788,\n",
       " 'voi_split': 1.1320521080436656,\n",
       " 'voi_merge': 1.6158888688443123}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO don't use this code, it is the best until now and I don't want to mess with it. I will just run it on the other cases and submit to see if it generalizes well.\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import apply_hysteresis_threshold\n",
    "def crop_prob(prob, margin=9):\n",
    "    \"\"\"Crop probability map by margin.\"\"\"\n",
    "    prob[:margin, :, :] = 0\n",
    "    prob[-margin:, :, :] = 0\n",
    "    prob[:, :margin, :] = 0\n",
    "    prob[:, -margin:, :] = 0\n",
    "    prob[:, :, :margin] = 0\n",
    "    prob[:, :, -margin:] = 0\n",
    "    return prob\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n",
    "prob_pred = crop_prob(prob_pred, margin=5)\n",
    "\n",
    "# Remove small objects\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def clean_and_split_seeds(seeds, min_size=1000):\n",
    "    \"\"\"\n",
    "    Remove small seeds and split remaining seeds into separate objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seeds : np.ndarray\n",
    "        Boolean array of seed voxels (True = seed)\n",
    "    min_size : int\n",
    "        Minimum voxel count to keep a seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    seeds_clean : np.ndarray\n",
    "        Boolean array of cleaned seeds\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    labeled, num = ndi.label(seeds)\n",
    "\n",
    "    # Count voxel sizes per component\n",
    "    sizes = np.bincount(labeled.ravel())\n",
    "    sizes[0] = 0  # ignore background\n",
    "\n",
    "    # Keep only components >= min_size\n",
    "    keep_labels = np.where(sizes >= min_size)[0]\n",
    "    seeds_clean = np.isin(labeled, keep_labels)\n",
    "\n",
    "    # Split each object individually\n",
    "    seeds_clean = split_by_object_np(seeds_clean)\n",
    "\n",
    "    return seeds_clean\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "                           grow_threshold=0.5,\n",
    "                           connectivity=1):\n",
    "    \"\"\"\n",
    "    Competitive region growing (prevents sheet merging).\n",
    "\n",
    "    Returns:\n",
    "        final_labels (Z,Y,X) int32\n",
    "    \"\"\"\n",
    "\n",
    "    # 1ï¸âƒ£ Label seeds\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "    seed_labels, _ = ndi.label(seeds_clean, structure=structure)\n",
    "\n",
    "    # 2ï¸âƒ£ Allowed growth region\n",
    "    allowed = prob_pred > grow_threshold\n",
    "\n",
    "    # 3ï¸âƒ£ Use negative probability as \"height\"\n",
    "    # Watershed expands from seeds inside allowed region\n",
    "    elevation = -prob_pred\n",
    "\n",
    "    final_labels = watershed(\n",
    "        elevation,\n",
    "        markers=seed_labels,\n",
    "        mask=allowed,\n",
    "        connectivity=structure\n",
    "    )\n",
    "\n",
    "    return final_labels.astype(np.int16)\n",
    "\n",
    "def enforce_label_gap(labels, gap=3):\n",
    "    \"\"\"\n",
    "    Remove only voxels that are within `gap` voxels\n",
    "    of a different label (26-connectivity safe).\n",
    "    \"\"\"\n",
    "\n",
    "    output = labels.copy()\n",
    "\n",
    "    # 26-connectivity structure\n",
    "    structure = ndi.generate_binary_structure(3, 3)\n",
    "\n",
    "    # Dilate labels `gap` times\n",
    "    dilated = np.zeros_like(labels, dtype=np.int16)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        expanded = ndi.binary_dilation(\n",
    "            mask,\n",
    "            structure=structure,\n",
    "            iterations=gap\n",
    "        )\n",
    "\n",
    "        # mark expanded region with label id\n",
    "        dilated[expanded & (dilated == 0)] = lbl\n",
    "        # mark conflicts as -1\n",
    "        conflict = expanded & (dilated != 0) & (dilated != lbl)\n",
    "        dilated[conflict] = -1\n",
    "\n",
    "    # Remove conflict voxels from original labels\n",
    "    conflict_zone = dilated == -1\n",
    "    output[conflict_zone] = 0\n",
    "\n",
    "    return output.astype(np.int16)\n",
    "\n",
    "def small_label_erosion(labels, iterations=1):\n",
    "    \"\"\"\n",
    "    Perform a very small erosion per label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : int array (Z,Y,X)\n",
    "        Labeled volume (0=background, 1..N=labels)\n",
    "    iterations : int\n",
    "        Number of erosion iterations (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eroded_labels : int array\n",
    "        Labels slightly shrunk\n",
    "    \"\"\"\n",
    "\n",
    "    structure = ndi.generate_binary_structure(3, 3)  # 26-connectivity\n",
    "    eroded_labels = np.zeros_like(labels)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        eroded = ndi.binary_erosion(mask, structure=structure, iterations=iterations)\n",
    "        dilated = ndi.binary_dilation(eroded, structure=structure, iterations=iterations)\n",
    "        eroded_labels[dilated] = lbl\n",
    "\n",
    "    return eroded_labels.astype(np.int16)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "def pad_volume(volume, pad_size=32):\n",
    "    \"\"\"\n",
    "    Pad a 3D volume with zeros on all sides.\n",
    "    \n",
    "    Args:\n",
    "        volume (np.ndarray): 3D array (D, H, W)\n",
    "        pad_size (int or tuple): number of voxels to pad on each side. \n",
    "                                 If int, same padding for all dimensions.\n",
    "                                 If tuple of 3 ints, specifies (D, H, W).\n",
    "    \n",
    "    Returns:\n",
    "        padded_volume (np.ndarray): zero-padded volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \"\"\"\n",
    "    if isinstance(pad_size, int):\n",
    "        pad_size = (pad_size, pad_size, pad_size)\n",
    "    \n",
    "    pad_width = tuple((p, p) for p in pad_size)\n",
    "    padded_volume = np.pad(volume, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_volume, pad_width\n",
    "\n",
    "def unpad_volume(padded_volume, pad_width):\n",
    "    \"\"\"\n",
    "    Remove padding from a 3D volume.\n",
    "    \n",
    "    Args:\n",
    "        padded_volume (np.ndarray): zero-padded 3D volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \n",
    "    Returns:\n",
    "        volume (np.ndarray): volume with padding removed\n",
    "    \"\"\"\n",
    "    slices = tuple(slice(pw[0], -pw[1] if pw[1] > 0 else None) for pw in pad_width)\n",
    "    return padded_volume[slices]\n",
    "\n",
    "def solidify_sheets_by_label_force(labels, connectivity=3, iterations=3):\n",
    "    labels, pad_w = pad_volume(labels, pad_size=iterations)\n",
    "\n",
    "    solid_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "    \n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    \n",
    "        mask = labels == lbl\n",
    "\n",
    "        # Optional: first fill internal voids\n",
    "        mask = ndi.binary_fill_holes(mask, structure=structure)\n",
    "\n",
    "        # Then a *small* closing to aggressively seal thin tunnels\n",
    "        dilated = ndi.binary_dilation(mask, structure=structure, iterations=iterations)\n",
    "        closed = ndi.binary_erosion(dilated, structure=structure, iterations=iterations) \n",
    "\n",
    "        solid_labels[closed] = lbl\n",
    "    solid_labels = unpad_volume(solid_labels, pad_w)\n",
    "    return solid_labels\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "def enforce_min_thickness(labels, target_min_thick=2.0, connectivity=3):\n",
    "    thick_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    half = target_min_thick / 2.0\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl            # sheet\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # Distance from every background voxel to the sheet surface\n",
    "        dist_to_sheet = ndi.distance_transform_edt(~mask)\n",
    "\n",
    "        # Enforce that any background voxel closer than half the target is filled\n",
    "        # This will grow the sheet just enough to eliminate < 3â€‘voxel thin regions\n",
    "        enforced = mask | (dist_to_sheet < half)\n",
    "\n",
    "        thick_labels[enforced] = lbl\n",
    "\n",
    "    return thick_labels\n",
    "\n",
    "#grown_seeds = grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "#                           grow_threshold=0.5,\n",
    "#                           connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "#grown_seeds = enforce_label_gap(grown_seeds)\n",
    "#grown_seeds = apply_hysteresis_threshold(prob_pred, 0.45, 0.75)\n",
    "grown_seeds = prob_pred>0.5\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = solidify_sheets_by_label_force(grown_seeds, connectivity=3, iterations=1)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "\"\"\"grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = small_label_erosion(grown_seeds, iterations=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "\n",
    "\n",
    "#grown_seeds = enforce_label_gap(grown_seeds)\n",
    "#grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "#grown_seeds = enforce_min_thickness(grown_seeds, target_min_thick=3.0, connectivity=3)\n",
    "#grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\"\"\"\n",
    "\n",
    "\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/hysteresis_th0375_mask_2536049117.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, grown_seeds)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_2536049117.tif\")\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ed2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference & Post-Process:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/1669670049.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:17<00:00,  1.58it/s]\n",
      "Running Inference & Post-Process:   1%|â–         | 1/79 [01:34<2:02:24, 94.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/541673255.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n",
      "Running Inference & Post-Process:   3%|â–Ž         | 2/79 [05:02<3:26:51, 161.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3090197578.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n",
      "Running Inference & Post-Process:   4%|â–         | 3/79 [08:40<3:57:09, 187.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3924902780.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n",
      "Running Inference & Post-Process:   5%|â–Œ         | 4/79 [12:12<4:06:29, 197.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/1566185731.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n",
      "Running Inference & Post-Process:   6%|â–‹         | 5/79 [15:29<4:02:49, 196.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3921562037.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.50it/s]\n",
      "Running Inference & Post-Process:   8%|â–Š         | 6/79 [18:44<3:58:55, 196.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3406708348.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.55it/s]\n",
      "Running Inference & Post-Process:   9%|â–‰         | 7/79 [22:24<4:04:53, 204.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/4233602520.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:16<00:00,  1.64it/s]\n",
      "Running Inference & Post-Process:  10%|â–ˆ         | 8/79 [23:51<3:17:24, 166.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/3897872090.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:41<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n",
      "Running Inference & Post-Process:  11%|â–ˆâ–        | 9/79 [27:09<3:26:06, 176.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/2881190689.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:44<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:44<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:44<00:00,  1.45it/s]\n",
      "Running Inference & Post-Process:  13%|â–ˆâ–Ž        | 10/79 [30:40<3:35:14, 187.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/2012359760.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:47<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:46<00:00,  1.37it/s]\n",
      "Running Inference & Post-Process:  14%|â–ˆâ–        | 11/79 [34:10<3:40:09, 194.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/1734818300.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:43<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n",
      "Running Inference & Post-Process:  15%|â–ˆâ–Œ        | 12/79 [37:36<3:40:37, 197.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/803213133.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.50it/s]\n",
      "Running Inference & Post-Process:  16%|â–ˆâ–‹        | 13/79 [40:43<3:33:56, 194.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images/4024884955.tif\n",
      "Doing inference to these axes combinations:\n",
      "[(), (3,), (4,), (3, 4)]\n",
      "Doing axes: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing axes: (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_DIR = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_images\"\n",
    "OUTPUT_DIR = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated_ndi_binary_propagation_45_75\"\n",
    "GT_DIR = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Core Functions ---\n",
    "\n",
    "def crop_prob(prob, margin=5):\n",
    "    \"\"\"Crop probability map by margin.\"\"\"\n",
    "    prob[:margin, :, :] = 0\n",
    "    prob[-margin:, :, :] = 0\n",
    "    prob[:, :margin, :] = 0\n",
    "    prob[:, -margin:, :] = 0\n",
    "    prob[:, :, :margin] = 0\n",
    "    prob[:, :, -margin:] = 0\n",
    "    return prob\n",
    "\n",
    "def clean_and_split_seeds(seeds, min_size=1000):\n",
    "    \"\"\"Label components and remove those smaller than min_size.\"\"\"\n",
    "    labeled, _ = ndi.label(seeds)\n",
    "    sizes = np.bincount(labeled.ravel())\n",
    "    sizes[0] = 0  \n",
    "    keep_labels = np.where(sizes >= min_size)[0]\n",
    "    seeds_clean = np.isin(labeled, keep_labels)\n",
    "    \n",
    "    # Assuming split_by_object_np is available in your environment\n",
    "    return split_by_object_np(seeds_clean)\n",
    "\n",
    "def pad_volume(volume, pad_size=32):\n",
    "    if isinstance(pad_size, int):\n",
    "        pad_size = (pad_size, pad_size, pad_size)\n",
    "    pad_width = tuple((p, p) for p in pad_size)\n",
    "    padded_volume = np.pad(volume, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    return padded_volume, pad_width\n",
    "\n",
    "def unpad_volume(padded_volume, pad_width):\n",
    "    slices = tuple(slice(pw[0], -pw[1] if pw[1] > 0 else None) for pw in pad_width)\n",
    "    return padded_volume[slices]\n",
    "\n",
    "def solidify_sheets_by_label_force(labels, connectivity=3, iterations=1):\n",
    "    \"\"\"Fill holes and seal thin tunnels via closing (dilation then erosion).\"\"\"\n",
    "    labels, pad_w = pad_volume(labels, pad_size=iterations)\n",
    "    solid_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0: continue\n",
    "        \n",
    "        mask = labels == lbl\n",
    "        mask = ndi.binary_fill_holes(mask, structure=structure)\n",
    "        \n",
    "        dilated = ndi.binary_dilation(mask, structure=structure, iterations=iterations)\n",
    "        closed = ndi.binary_erosion(dilated, structure=structure, iterations=iterations) \n",
    "        solid_labels[closed] = lbl\n",
    "        \n",
    "    return unpad_volume(solid_labels, pad_w)\n",
    "\n",
    "# --- Processing Loop ---\n",
    "\n",
    "tif_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.tif')]\n",
    "\n",
    "for filename in tqdm(tif_files, desc=\"Running Inference & Post-Process\"):\n",
    "    file_id = filename.replace(\".tif\", \"\")\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"{filename}\")\n",
    "    if os.path.exists(out_path):\n",
    "        print(f\"Output already exists for {filename}, skipping.\")\n",
    "        continue\n",
    "    # 1. Inference \n",
    "    # (Ensure input_data for the specific file is loaded here)\n",
    "    input_data = os.path.join(INPUT_DIR, filename)\n",
    "    print(f\"Doing: {input_data}\")\n",
    "    logits_pred, _ = infer_object.infer(\n",
    "        input={'image': str(input_data), 'gt': None}, \n",
    "        test=True, \n",
    "        threshold_list=[0.5])\n",
    "\n",
    "    # 2. Probability Prep\n",
    "    prob_pred = sigmoid(logits_pred)\n",
    "    prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "    prob_pred = crop_prob(prob_pred, margin=5)\n",
    "\n",
    "    # 3. Refined Logic (Threshold -> Clean -> Solidify -> Clean)\n",
    "    #grown_seeds = prob_pred > 0.5 # first try doing th=0.5\n",
    "    grown_seeds = prob_pred > 0.45\n",
    "    strong_seeds = prob_pred > 0.75\n",
    "    grown_seeds = ndi.binary_propagation(strong_seeds, mask=grown_seeds) # Second try\n",
    "    grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "    grown_seeds = solidify_sheets_by_label_force(grown_seeds, connectivity=3, iterations=1)\n",
    "    grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "\n",
    "    grown_seeds = grown_seeds>0.5\n",
    "\n",
    "    # 4. Save\n",
    "    \n",
    "    tifffile.imwrite(out_path, grown_seeds.astype(np.uint16))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310e8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1669670049.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1669670049.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 2/79 [00:20<12:51, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/541673255.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/541673255.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 3/79 [00:51<23:46, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3090197578.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3090197578.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 4/79 [01:17<26:56, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3924902780.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3924902780.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 5/79 [01:54<33:23, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1566185731.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1566185731.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 6/79 [02:25<34:23, 28.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3921562037.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3921562037.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 7/79 [03:00<36:26, 30.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3406708348.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3406708348.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 8/79 [03:32<36:34, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4233602520.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4233602520.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 9/79 [03:48<30:45, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3897872090.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3897872090.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 10/79 [04:16<30:51, 26.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2881190689.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2881190689.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 11/79 [04:51<33:23, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2012359760.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2012359760.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 12/79 [05:22<33:14, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1734818300.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1734818300.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 13/79 [06:04<36:46, 33.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/803213133.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/803213133.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 14/79 [06:40<37:12, 34.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4024884955.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4024884955.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 15/79 [07:14<36:33, 34.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/378779937.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/378779937.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 16/79 [07:53<37:16, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3694884789.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3694884789.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 17/79 [08:25<35:45, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2660177791.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2660177791.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 18/79 [08:58<34:35, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/118041886.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/118041886.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 19/79 [09:31<33:48, 33.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1746646794.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1746646794.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 20/79 [10:06<33:34, 34.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2961547523.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2961547523.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 21/79 [10:41<33:06, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2632109508.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2632109508.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 22/79 [11:15<32:27, 34.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3608009641.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3608009641.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 23/79 [11:53<33:02, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4105398542.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4105398542.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 24/79 [12:33<33:39, 36.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/917058676.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/917058676.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [13:11<33:30, 37.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3436049398.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3436049398.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/79 [13:42<31:15, 35.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/821686014.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/821686014.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [14:14<29:44, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3767466977.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3767466977.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/79 [14:44<28:07, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2067397446.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2067397446.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [15:23<29:03, 34.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1655876858.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1655876858.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [15:57<28:17, 34.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2489372663.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2489372663.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/79 [16:31<27:28, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1845578058.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1845578058.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/79 [17:04<26:33, 33.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1442179410.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1442179410.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/79 [17:41<26:44, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4026460947.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4026460947.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [17:59<22:24, 29.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3977024865.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3977024865.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [18:17<19:14, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1004283650.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1004283650.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [18:48<19:46, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3681179135.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3681179135.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/79 [19:17<19:42, 28.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1332121747.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1332121747.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/79 [19:57<21:43, 31.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4020494299.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4020494299.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [20:33<21:54, 32.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3515764944.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3515764944.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [21:05<21:08, 32.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1522833038.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1522833038.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/79 [21:34<20:03, 31.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4023763904.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4023763904.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/79 [22:05<19:23, 31.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1435658104.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1435658104.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/79 [22:40<19:32, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4081240825.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4081240825.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [23:18<19:50, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3198627305.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3198627305.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [23:55<19:53, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/114235076.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/114235076.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/79 [24:29<19:03, 34.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3527825464.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3527825464.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/79 [25:08<19:07, 35.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2737376036.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2737376036.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/79 [25:38<17:37, 34.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1693721638.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1693721638.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [26:24<18:52, 37.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4216652155.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4216652155.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [27:02<18:16, 37.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1796762532.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1796762532.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/79 [27:39<17:30, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2116132949.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2116132949.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/79 [28:13<16:23, 36.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/363381119.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/363381119.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/79 [28:30<13:17, 30.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/928131323.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/928131323.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [29:03<13:03, 31.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1966171058.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1966171058.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [29:37<12:50, 32.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1471460767.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1471460767.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/79 [30:11<12:31, 32.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3922476405.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3922476405.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/79 [30:47<12:22, 33.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3662102503.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3662102503.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/79 [31:28<12:38, 36.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3335656968.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3335656968.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [32:01<11:43, 35.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3237609845.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3237609845.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [32:33<10:47, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/4015222329.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/4015222329.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/79 [33:05<10:03, 33.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1189767014.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1189767014.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/79 [33:42<09:46, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2708764018.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2708764018.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [34:17<09:14, 34.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1013184726.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1013184726.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [34:52<08:43, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2689046967.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2689046967.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [35:09<06:49, 29.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/206065757.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/206065757.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/79 [35:38<06:21, 29.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/571334887.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/571334887.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/79 [36:07<05:51, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1351645019.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1351645019.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/79 [36:39<05:31, 30.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2136851012.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2136851012.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [37:11<05:06, 30.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/663106834.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/663106834.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [37:40<04:30, 30.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2203617984.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2203617984.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/79 [38:16<04:15, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3545147380.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [38:31<03:08, 26.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1127903126.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1127903126.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/79 [39:13<03:08, 31.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/1704770049.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/1704770049.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [39:47<02:39, 31.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/216657071.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/216657071.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [40:02<01:47, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/693501383.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/693501383.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/79 [40:35<01:26, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2536049117.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/79 [41:04<00:57, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2821927657.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/2821927657.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/79 [41:21<00:25, 25.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/149409101.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/149409101.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [41:56<00:00, 28.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3686818985.tif\n",
      "pred_path: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/3686818985.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [42:25<00:00, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "ðŸ“Š FINAL AGGREGATED METRICS\n",
      "==============================\n",
      "  id  image_score  topo_score  surface_dice  voi_score  voi_split  voi_merge\n",
      "MEAN     0.566194    0.278841      0.829088   0.549603   1.340478   1.427932\n",
      "==============================\n",
      "âœ… Saved detailed metrics with Mean row to: /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/results_post.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from infer_class import VesuviusInferer\n",
    "from compute_metrics_obj import VesuviusMetric\n",
    "def create_dfs(path_dir):\n",
    "    # Generate DataFrame\n",
    "    result_df = glob.glob(os.path.join(path_dir, '**/*.tif'), recursive=True)\n",
    "    result_df = pd.DataFrame({'tif_paths': result_df})\n",
    "    result_df['id'] = result_df['tif_paths'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "    # save dataframe to csv (take name from the path_dir last folder)\n",
    "    csv_name = os.path.basename(os.path.normpath(path_dir)) + '_df.csv'\n",
    "    result_df.to_csv(os.path.join(path_dir, csv_name), index=False)\n",
    "    return result_df\n",
    "\n",
    "create_dfs(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated_ndi_binary_propagation_45_75/\")\n",
    "\n",
    "test_metric_obj = VesuviusMetric(\n",
    "    solution_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/val_labels_df.csv\",\n",
    "    submission_path=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated_ndi_binary_propagation_45_75/post_dilated_ndi_binary_propagation_45_75_df.csv\",\n",
    "    output_file=f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated_ndi_binary_propagation_45_75/results_post.csv\"\n",
    ")\n",
    "\n",
    "test_metric_obj._run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grow_seeds_competitive(seeds_clean, prob_pred,grow_threshold=0.4, connectivity=1)\n",
    "{'image_score': np.float64(0.5476696311406051),\n",
    " 'topo_score': 0.15965118229079323,\n",
    " 'surface_dice': 0.8748016197645412,\n",
    " 'voi_score': 0.5531248843879362,\n",
    " 'voi_split': 1.3989625523419127,\n",
    " 'voi_merge': 1.2940707223320127}\n",
    "\n",
    "# Added grown_seeds = ndi.binary_dilation(grown_seeds, structure=ndi.generate_binary_structure(3, 1), iterations=1)\n",
    "{'image_score': np.float64(0.5803267385474029),\n",
    " 'topo_score': 0.2799794132784354,\n",
    " 'surface_dice': 0.867418939951312,\n",
    " 'voi_score': 0.5506751016597516,\n",
    " 'voi_split': 1.3689204956354908,\n",
    " 'voi_merge': 1.350922214920875}\n",
    "\n",
    "# When not using enforce_min_thickness\n",
    "{'image_score': np.float64(0.6032754221973837),\n",
    " 'topo_score': 0.38663823738450603,\n",
    " 'surface_dice': 0.849665504849308,\n",
    " 'voi_score': 0.5425743550993544,\n",
    " 'voi_split': 1.0817019874739124,\n",
    " 'voi_merge': 1.7285158846730508}\n",
    "\n",
    "# having all\n",
    "{'image_score': np.float64(0.5710288547765316),\n",
    " 'topo_score': 0.24604251469923114,\n",
    " 'surface_dice': 0.8678840045981637,\n",
    " 'voi_score': 0.552733425021157,\n",
    " 'voi_split': 1.3954791739179504,\n",
    " 'voi_merge': 1.301822121377777}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dbf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO don't use this code, it is the best until now and I don't want to mess with it. I will just run it on the other cases and submit to see if it generalizes well.\n",
    "# TODO second try: best one ever now\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "def crop_prob(prob, margin=9):\n",
    "    \"\"\"Crop probability map by margin.\"\"\"\n",
    "    prob[:margin, :, :] = 0\n",
    "    prob[-margin:, :, :] = 0\n",
    "    prob[:, :margin, :] = 0\n",
    "    prob[:, -margin:, :] = 0\n",
    "    prob[:, :, :margin] = 0\n",
    "    prob[:, :, -margin:] = 0\n",
    "    return prob\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n",
    "prob_pred = crop_prob(prob_pred, margin=3)\n",
    "\n",
    "seeds = prob_pred>0.8\n",
    "\n",
    "# Remove small objects\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def clean_and_split_seeds(seeds, min_size=1000):\n",
    "    \"\"\"\n",
    "    Remove small seeds and split remaining seeds into separate objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seeds : np.ndarray\n",
    "        Boolean array of seed voxels (True = seed)\n",
    "    min_size : int\n",
    "        Minimum voxel count to keep a seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    seeds_clean : np.ndarray\n",
    "        Boolean array of cleaned seeds\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    labeled, num = ndi.label(seeds)\n",
    "\n",
    "    # Count voxel sizes per component\n",
    "    sizes = np.bincount(labeled.ravel())\n",
    "    sizes[0] = 0  # ignore background\n",
    "\n",
    "    # Keep only components >= min_size\n",
    "    keep_labels = np.where(sizes >= min_size)[0]\n",
    "    seeds_clean = np.isin(labeled, keep_labels)\n",
    "\n",
    "    # Split each object individually\n",
    "    seeds_clean = split_by_object_np(seeds_clean)\n",
    "\n",
    "    return seeds_clean\n",
    "\n",
    "seeds_clean = clean_and_split_seeds(seeds, min_size=1000)\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/seeds_clean.nii.gz\"\n",
    "nii_data = np.transpose(seeds_clean, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "                           grow_threshold=0.5,\n",
    "                           connectivity=1):\n",
    "    \"\"\"\n",
    "    Competitive region growing (prevents sheet merging).\n",
    "\n",
    "    Returns:\n",
    "        final_labels (Z,Y,X) int32\n",
    "    \"\"\"\n",
    "\n",
    "    # 1ï¸âƒ£ Label seeds\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "    seed_labels, _ = ndi.label(seeds_clean, structure=structure)\n",
    "\n",
    "    # 2ï¸âƒ£ Allowed growth region\n",
    "    allowed = prob_pred > grow_threshold\n",
    "\n",
    "    # 3ï¸âƒ£ Use negative probability as \"height\"\n",
    "    # Watershed expands from seeds inside allowed region\n",
    "    elevation = -prob_pred\n",
    "\n",
    "    final_labels = watershed(\n",
    "        elevation,\n",
    "        markers=seed_labels,\n",
    "        mask=allowed,\n",
    "        connectivity=structure\n",
    "    )\n",
    "\n",
    "    return final_labels.astype(np.int16)\n",
    "\n",
    "def enforce_label_gap(labels, gap=3):\n",
    "    \"\"\"\n",
    "    Remove only voxels that are within `gap` voxels\n",
    "    of a different label (26-connectivity safe).\n",
    "    \"\"\"\n",
    "\n",
    "    output = labels.copy()\n",
    "\n",
    "    # 26-connectivity structure\n",
    "    structure = ndi.generate_binary_structure(3, 3)\n",
    "\n",
    "    # Dilate labels `gap` times\n",
    "    dilated = np.zeros_like(labels, dtype=np.int16)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        expanded = ndi.binary_dilation(\n",
    "            mask,\n",
    "            structure=structure,\n",
    "            iterations=gap\n",
    "        )\n",
    "\n",
    "        # mark expanded region with label id\n",
    "        dilated[expanded & (dilated == 0)] = lbl\n",
    "        # mark conflicts as -1\n",
    "        conflict = expanded & (dilated != 0) & (dilated != lbl)\n",
    "        dilated[conflict] = -1\n",
    "\n",
    "    # Remove conflict voxels from original labels\n",
    "    conflict_zone = dilated == -1\n",
    "    output[conflict_zone] = 0\n",
    "\n",
    "    return output.astype(np.int16)\n",
    "\n",
    "def small_label_erosion(labels, iterations=1):\n",
    "    \"\"\"\n",
    "    Perform a very small erosion per label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : int array (Z,Y,X)\n",
    "        Labeled volume (0=background, 1..N=labels)\n",
    "    iterations : int\n",
    "        Number of erosion iterations (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eroded_labels : int array\n",
    "        Labels slightly shrunk\n",
    "    \"\"\"\n",
    "\n",
    "    structure = ndi.generate_binary_structure(3, 3)  # 26-connectivity\n",
    "    eroded_labels = np.zeros_like(labels)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        eroded = ndi.binary_erosion(mask, structure=structure, iterations=iterations)\n",
    "        dilated = ndi.binary_dilation(eroded, structure=structure, iterations=iterations)\n",
    "        eroded_labels[dilated] = lbl\n",
    "\n",
    "    return eroded_labels.astype(np.int16)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "def pad_volume(volume, pad_size=32):\n",
    "    \"\"\"\n",
    "    Pad a 3D volume with zeros on all sides.\n",
    "    \n",
    "    Args:\n",
    "        volume (np.ndarray): 3D array (D, H, W)\n",
    "        pad_size (int or tuple): number of voxels to pad on each side. \n",
    "                                 If int, same padding for all dimensions.\n",
    "                                 If tuple of 3 ints, specifies (D, H, W).\n",
    "    \n",
    "    Returns:\n",
    "        padded_volume (np.ndarray): zero-padded volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \"\"\"\n",
    "    if isinstance(pad_size, int):\n",
    "        pad_size = (pad_size, pad_size, pad_size)\n",
    "    \n",
    "    pad_width = tuple((p, p) for p in pad_size)\n",
    "    padded_volume = np.pad(volume, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_volume, pad_width\n",
    "\n",
    "def unpad_volume(padded_volume, pad_width):\n",
    "    \"\"\"\n",
    "    Remove padding from a 3D volume.\n",
    "    \n",
    "    Args:\n",
    "        padded_volume (np.ndarray): zero-padded 3D volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \n",
    "    Returns:\n",
    "        volume (np.ndarray): volume with padding removed\n",
    "    \"\"\"\n",
    "    slices = tuple(slice(pw[0], -pw[1] if pw[1] > 0 else None) for pw in pad_width)\n",
    "    return padded_volume[slices]\n",
    "\n",
    "def solidify_sheets_by_label_force(labels, connectivity=3, iterations=3):\n",
    "    labels, pad_w = pad_volume(labels, pad_size=iterations)\n",
    "\n",
    "    solid_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "    \n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    \n",
    "        mask = labels == lbl\n",
    "\n",
    "        # Optional: first fill internal voids\n",
    "        mask = ndi.binary_fill_holes(mask, structure=structure)\n",
    "\n",
    "        # Then a *small* closing to aggressively seal thin tunnels\n",
    "        dilated = ndi.binary_dilation(mask, structure=structure, iterations=iterations)\n",
    "        closed = ndi.binary_erosion(dilated, structure=structure, iterations=iterations+1) \n",
    "\n",
    "        solid_labels[closed] = lbl\n",
    "    solid_labels = unpad_volume(solid_labels, pad_w)\n",
    "    return solid_labels\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "def enforce_min_thickness(labels, target_min_thick=2.0, connectivity=3):\n",
    "    thick_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    half = target_min_thick / 2.0\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl            # sheet\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # Distance from every background voxel to the sheet surface\n",
    "        dist_to_sheet = ndi.distance_transform_edt(~mask)\n",
    "\n",
    "        # Enforce that any background voxel closer than half the target is filled\n",
    "        # This will grow the sheet just enough to eliminate < 3â€‘voxel thin regions\n",
    "        enforced = mask | (dist_to_sheet < half)\n",
    "\n",
    "        thick_labels[enforced] = lbl\n",
    "\n",
    "    return thick_labels\n",
    "\n",
    "grown_seeds = grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "                           grow_threshold=0.5,\n",
    "                           connectivity=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = small_label_erosion(grown_seeds, iterations=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "\n",
    "\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/grown_seeds_here.nii.gz\"\n",
    "nii_data = np.transpose(grown_seeds, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "\n",
    "grown_seeds = solidify_sheets_by_label_force(grown_seeds, connectivity=3, iterations=11)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "#grown_seeds = enforce_min_thickness(grown_seeds, target_min_thick=3.0, connectivity=3)\n",
    "#grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = ndi.binary_dilation(grown_seeds, structure=ndi.generate_binary_structure(3, 1), iterations=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/grown_seeds.nii.gz\"\n",
    "nii_data = np.transpose(grown_seeds, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/hysteresis_th0375_mask_3545147380.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, grown_seeds)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_3545147380.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0e55528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_3545147380.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5710288547765316),\n",
       " 'topo_score': 0.24604251469923114,\n",
       " 'surface_dice': 0.8678840045981637,\n",
       " 'voi_score': 0.552733425021157,\n",
       " 'voi_split': 1.3954791739179504,\n",
       " 'voi_merge': 1.301822121377777}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO don't use this code, it is the best until now and I don't want to mess with it. I will just run it on the other cases and submit to see if it generalizes well.\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "def crop_prob(prob, margin=9):\n",
    "    \"\"\"Crop probability map by margin.\"\"\"\n",
    "    prob[:margin, :, :] = 0\n",
    "    prob[-margin:, :, :] = 0\n",
    "    prob[:, :margin, :] = 0\n",
    "    prob[:, -margin:, :] = 0\n",
    "    prob[:, :, :margin] = 0\n",
    "    prob[:, :, -margin:] = 0\n",
    "    return prob\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n",
    "prob_pred = crop_prob(prob_pred, margin=9)\n",
    "\n",
    "seeds = prob_pred>0.8\n",
    "\n",
    "# Remove small objects\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def clean_and_split_seeds(seeds, min_size=1000):\n",
    "    \"\"\"\n",
    "    Remove small seeds and split remaining seeds into separate objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seeds : np.ndarray\n",
    "        Boolean array of seed voxels (True = seed)\n",
    "    min_size : int\n",
    "        Minimum voxel count to keep a seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    seeds_clean : np.ndarray\n",
    "        Boolean array of cleaned seeds\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    labeled, num = ndi.label(seeds)\n",
    "\n",
    "    # Count voxel sizes per component\n",
    "    sizes = np.bincount(labeled.ravel())\n",
    "    sizes[0] = 0  # ignore background\n",
    "\n",
    "    # Keep only components >= min_size\n",
    "    keep_labels = np.where(sizes >= min_size)[0]\n",
    "    seeds_clean = np.isin(labeled, keep_labels)\n",
    "\n",
    "    # Split each object individually\n",
    "    seeds_clean = split_by_object_np(seeds_clean)\n",
    "\n",
    "    return seeds_clean\n",
    "\n",
    "seeds_clean = clean_and_split_seeds(seeds, min_size=1000)\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/seeds_clean.nii.gz\"\n",
    "nii_data = np.transpose(seeds_clean, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "def grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "                           grow_threshold=0.5,\n",
    "                           connectivity=1):\n",
    "    \"\"\"\n",
    "    Competitive region growing (prevents sheet merging).\n",
    "\n",
    "    Returns:\n",
    "        final_labels (Z,Y,X) int32\n",
    "    \"\"\"\n",
    "\n",
    "    # 1ï¸âƒ£ Label seeds\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "    seed_labels, _ = ndi.label(seeds_clean, structure=structure)\n",
    "\n",
    "    # 2ï¸âƒ£ Allowed growth region\n",
    "    allowed = prob_pred > grow_threshold\n",
    "\n",
    "    # 3ï¸âƒ£ Use negative probability as \"height\"\n",
    "    # Watershed expands from seeds inside allowed region\n",
    "    elevation = -prob_pred\n",
    "\n",
    "    final_labels = watershed(\n",
    "        elevation,\n",
    "        markers=seed_labels,\n",
    "        mask=allowed,\n",
    "        connectivity=structure\n",
    "    )\n",
    "\n",
    "    return final_labels.astype(np.int16)\n",
    "\n",
    "def enforce_label_gap(labels, gap=3):\n",
    "    \"\"\"\n",
    "    Remove only voxels that are within `gap` voxels\n",
    "    of a different label (26-connectivity safe).\n",
    "    \"\"\"\n",
    "\n",
    "    output = labels.copy()\n",
    "\n",
    "    # 26-connectivity structure\n",
    "    structure = ndi.generate_binary_structure(3, 3)\n",
    "\n",
    "    # Dilate labels `gap` times\n",
    "    dilated = np.zeros_like(labels, dtype=np.int16)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        expanded = ndi.binary_dilation(\n",
    "            mask,\n",
    "            structure=structure,\n",
    "            iterations=gap\n",
    "        )\n",
    "\n",
    "        # mark expanded region with label id\n",
    "        dilated[expanded & (dilated == 0)] = lbl\n",
    "        # mark conflicts as -1\n",
    "        conflict = expanded & (dilated != 0) & (dilated != lbl)\n",
    "        dilated[conflict] = -1\n",
    "\n",
    "    # Remove conflict voxels from original labels\n",
    "    conflict_zone = dilated == -1\n",
    "    output[conflict_zone] = 0\n",
    "\n",
    "    return output.astype(np.int16)\n",
    "\n",
    "def small_label_erosion(labels, iterations=1):\n",
    "    \"\"\"\n",
    "    Perform a very small erosion per label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : int array (Z,Y,X)\n",
    "        Labeled volume (0=background, 1..N=labels)\n",
    "    iterations : int\n",
    "        Number of erosion iterations (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eroded_labels : int array\n",
    "        Labels slightly shrunk\n",
    "    \"\"\"\n",
    "\n",
    "    structure = ndi.generate_binary_structure(3, 3)  # 26-connectivity\n",
    "    eroded_labels = np.zeros_like(labels)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl\n",
    "        eroded = ndi.binary_erosion(mask, structure=structure, iterations=iterations)\n",
    "        dilated = ndi.binary_dilation(eroded, structure=structure, iterations=iterations)\n",
    "        eroded_labels[dilated] = lbl\n",
    "\n",
    "    return eroded_labels.astype(np.int16)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "def pad_volume(volume, pad_size=32):\n",
    "    \"\"\"\n",
    "    Pad a 3D volume with zeros on all sides.\n",
    "    \n",
    "    Args:\n",
    "        volume (np.ndarray): 3D array (D, H, W)\n",
    "        pad_size (int or tuple): number of voxels to pad on each side. \n",
    "                                 If int, same padding for all dimensions.\n",
    "                                 If tuple of 3 ints, specifies (D, H, W).\n",
    "    \n",
    "    Returns:\n",
    "        padded_volume (np.ndarray): zero-padded volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \"\"\"\n",
    "    if isinstance(pad_size, int):\n",
    "        pad_size = (pad_size, pad_size, pad_size)\n",
    "    \n",
    "    pad_width = tuple((p, p) for p in pad_size)\n",
    "    padded_volume = np.pad(volume, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_volume, pad_width\n",
    "\n",
    "def unpad_volume(padded_volume, pad_width):\n",
    "    \"\"\"\n",
    "    Remove padding from a 3D volume.\n",
    "    \n",
    "    Args:\n",
    "        padded_volume (np.ndarray): zero-padded 3D volume\n",
    "        pad_width (tuple): padding applied ((before_D, after_D), ...)\n",
    "    \n",
    "    Returns:\n",
    "        volume (np.ndarray): volume with padding removed\n",
    "    \"\"\"\n",
    "    slices = tuple(slice(pw[0], -pw[1] if pw[1] > 0 else None) for pw in pad_width)\n",
    "    return padded_volume[slices]\n",
    "\n",
    "def solidify_sheets_by_label_force(labels, connectivity=3, iterations=3):\n",
    "    labels, pad_w = pad_volume(labels, pad_size=iterations)\n",
    "\n",
    "    solid_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    structure = ndi.generate_binary_structure(3, connectivity)\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    \n",
    "        mask = labels == lbl\n",
    "\n",
    "        # Optional: first fill internal voids\n",
    "        mask = ndi.binary_fill_holes(mask, structure=structure)\n",
    "\n",
    "        # Then a *small* closing to aggressively seal thin tunnels\n",
    "        dilated = ndi.binary_dilation(mask, structure=structure, iterations=iterations)\n",
    "        closed = ndi.binary_erosion(dilated, structure=structure, iterations=iterations+1) \n",
    "\n",
    "        solid_labels[closed] = lbl\n",
    "    solid_labels = unpad_volume(solid_labels, pad_w)\n",
    "    return solid_labels\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "def enforce_min_thickness(labels, target_min_thick=2.0, connectivity=3):\n",
    "    thick_labels = np.zeros_like(labels, dtype=np.int32)\n",
    "    half = target_min_thick / 2.0\n",
    "\n",
    "    for lbl in np.unique(labels):\n",
    "        if lbl == 0:\n",
    "            continue\n",
    "\n",
    "        mask = labels == lbl            # sheet\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # Distance from every background voxel to the sheet surface\n",
    "        dist_to_sheet = ndi.distance_transform_edt(~mask)\n",
    "\n",
    "        # Enforce that any background voxel closer than half the target is filled\n",
    "        # This will grow the sheet just enough to eliminate < 3â€‘voxel thin regions\n",
    "        enforced = mask | (dist_to_sheet < half)\n",
    "\n",
    "        thick_labels[enforced] = lbl\n",
    "\n",
    "    return thick_labels\n",
    "\n",
    "grown_seeds = grow_seeds_competitive(seeds_clean, prob_pred,\n",
    "                           grow_threshold=0.5,\n",
    "                           connectivity=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = small_label_erosion(grown_seeds, iterations=1)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "\n",
    "\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/grown_seeds_here.nii.gz\"\n",
    "nii_data = np.transpose(grown_seeds, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "\n",
    "\n",
    "grown_seeds = solidify_sheets_by_label_force(grown_seeds, connectivity=3, iterations=11)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_min_thickness(grown_seeds, target_min_thick=3.0, connectivity=3)\n",
    "grown_seeds = clean_and_split_seeds(grown_seeds, min_size=1000)\n",
    "grown_seeds = enforce_label_gap(grown_seeds)\n",
    "\n",
    "output_path_nii = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/grown_seeds.nii.gz\"\n",
    "nii_data = np.transpose(grown_seeds, (2, 1, 0)).astype(np.uint16)\n",
    "nii_data = np.flip(nii_data, axis=0) \n",
    "nii_data = np.flip(nii_data, axis=1)\n",
    "nib.save(nib.Nifti1Image(nii_data, np.eye(4)), output_path_nii)\n",
    "\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/hysteresis_th0375_mask_3545147380.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, grown_seeds)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_hysteresis_th0375_mask_3545147380.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac3993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_anisotropic_struct(z_radius, xy_radius):\n",
    "    z, r = z_radius, xy_radius\n",
    "    if z == 0 and r == 0: return None\n",
    "    depth = 2 * z + 1\n",
    "    size = 2 * r + 1\n",
    "    struct = np.zeros((depth, size, size), dtype=bool)\n",
    "    cz, cy, cx = z, r, r\n",
    "    for dz in range(-z, z + 1):\n",
    "        for dy in range(-r, r + 1):\n",
    "            for dx in range(-r, r + 1):\n",
    "                if dy * dy + dx * dx <= r * r:\n",
    "                    struct[cz + dz, cy + dy, cx + dx] = True\n",
    "    return struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b486b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo_postprocess(probs, T_low, T_high, z_radius, xy_radius, dust_min_size):\n",
    "    # 1. Hysteresis\n",
    "    strong = probs >= T_high\n",
    "    weak = probs >= T_low\n",
    "    \n",
    "    if not strong.any(): return np.zeros_like(probs, dtype=np.uint8)\n",
    "    \n",
    "    struct_hyst = ndi.generate_binary_structure(3, 3)\n",
    "    mask = ndi.binary_propagation(strong, mask=weak, structure=struct_hyst)\n",
    "    \n",
    "    if not mask.any(): return np.zeros_like(probs, dtype=np.uint8)\n",
    "\n",
    "    # 2. Anisotropic Closing\n",
    "    struct = build_anisotropic_struct(z_radius, xy_radius)\n",
    "    if struct is not None:\n",
    "        mask = ndi.binary_closing(mask, structure=struct)\n",
    "\n",
    "    # 3. Dust Removal\n",
    "    if dust_min_size > 0:\n",
    "        mask = remove_small_objects(mask.astype(bool), min_size=dust_min_size)\n",
    "\n",
    "    return mask.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0710e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.morphology import remove_small_objects\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a563b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_3545147380.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.20629769104582085),\n",
       " 'topo_score': 0.0,\n",
       " 'surface_dice': 0.0,\n",
       " 'voi_score': 0.5894219744166309,\n",
       " 'voi_split': 6.410649199304792e-17,\n",
       " 'voi_merge': 2.3219246618108693}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-processing config (Tuned V24)\n",
    "T_LOW = 0.30        # Keep connectivity permissive\n",
    "T_HIGH = 0.80       # Lowered from 0.85 to find more seeds\n",
    "Z_RADIUS = 0        # Increased from 1 to 2 (Fixes vertical splits)\n",
    "XY_RADIUS = 0       # Keep 0 (Prevent mergers)\n",
    "DUST_MIN_SIZE = 300 # Lowered from 500 to keep smaller valid fragments\n",
    "CROP_MARGIN = 0\n",
    "\n",
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n",
    "prob_pred[:CROP_MARGIN, :, :] = 0\n",
    "prob_pred[-CROP_MARGIN:, :, :] = 0\n",
    "prob_pred[:, :CROP_MARGIN, :] = 0\n",
    "prob_pred[:, -CROP_MARGIN:, :] = 0\n",
    "prob_pred[:, :, :CROP_MARGIN] = 0\n",
    "prob_pred[:, :, -CROP_MARGIN:] = 0\n",
    "final_mask = topo_postprocess(\n",
    "            prob_pred, \n",
    "            T_low=T_LOW, \n",
    "            T_high=T_HIGH, \n",
    "            z_radius=Z_RADIUS, \n",
    "            xy_radius=XY_RADIUS, \n",
    "            dust_min_size=DUST_MIN_SIZE\n",
    "        )\n",
    "\n",
    "\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/final_pred_3545147380.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, final_mask)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_3545147380.tif\")\n",
    "\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "\n",
    "score_report\n",
    "\n",
    "# Original 0.5305181364493412\t0.07948210753461608\t0.8984319807505937\t0.5492066026464245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6276c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b3552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_LOW = 0.30        # Keep connectivity permissive\n",
    "#T_HIGH = 0.80       # Lowered from 0.85 to find more seeds\n",
    "#Z_RADIUS = 2        # Increased from 1 to 2 (Fixes vertical splits)\n",
    "#XY_RADIUS = 1       # Keep 0 (Prevent mergers)\n",
    "#DUST_MIN_SIZE = 300 # Lowered from 500 to keep smaller valid fragments\n",
    "#CROP_MARGIN = 9\n",
    "{'image_score': np.float64(0.6978754393297082),\n",
    " 'topo_score': 0.4622273249138921,\n",
    " 'surface_dice': 0.9441961676296846,\n",
    " 'voi_score': 0.6535388091004308,\n",
    " 'voi_split': 0.8403331996264144,\n",
    " 'voi_merge': 0.926770177021606}\n",
    "\n",
    "\n",
    "#T_LOW = 0.30 \n",
    "#T_HIGH = 0.80\n",
    "#Z_RADIUS = 9        # Increased from 1 to 2 (Fixes vertical splits)\n",
    "#XY_RADIUS = 1       # Keep 0 (Prevent mergers)\n",
    "#DUST_MIN_SIZE = 300 # Lowered from 500 to keep smaller valid fragments\n",
    "#CROP_MARGIN = 9\n",
    "{'image_score': np.float64(0.6993756080223525),\n",
    " 'topo_score': 0.4672789896670494,\n",
    " 'surface_dice': 0.9442800188316288,\n",
    " 'voi_score': 0.653411155803336,\n",
    " 'voi_split': 0.8405283482404348,\n",
    " 'voi_merge': 0.9275714723110456}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5f507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "768be0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.ndimage import binary_dilation\n",
    "from scipy import ndimage\n",
    "\n",
    "def frangi_filter_3d(image, sigmas=(1, 3, 5), beta1=0.5, beta2=15, gamma=None, black_ridges=True):\n",
    "    \"\"\"\n",
    "    Frangiæ»¤æ³¢å™¨ - ç”¨äºŽå¢žå¼º3Då›¾åƒä¸­çš„ç®¡çŠ¶ç»“æž„ï¼ˆå¦‚è¡€ç®¡ï¼‰ã€‚\n",
    "    \n",
    "    Frangiæ»¤æ³¢å™¨åŸºäºŽHessiançŸ©é˜µçš„ç‰¹å¾å€¼æ¥æ£€æµ‹ç®¡çŠ¶ç»“æž„ã€‚å®ƒé€šè¿‡åˆ†æžå±€éƒ¨äºŒé˜¶å¯¼æ•°\n",
    "    æ¥è¯†åˆ«å…·æœ‰\"ç®¡çŠ¶\"å‡ ä½•ç‰¹å¾çš„åŒºåŸŸã€‚\n",
    "    \n",
    "    åŽŸç†ï¼š\n",
    "    1. è®¡ç®—å›¾åƒåœ¨ä¸åŒå°ºåº¦ä¸‹çš„HessiançŸ©é˜µ\n",
    "    2. è®¡ç®—HessiançŸ©é˜µçš„ç‰¹å¾å€¼ï¼ˆÎ»1, Î»2, Î»3ï¼‰\n",
    "    3. æ ¹æ®ç‰¹å¾å€¼çš„å…³ç³»åˆ¤æ–­æ˜¯å¦ä¸ºç®¡çŠ¶ç»“æž„\n",
    "    4. ä½¿ç”¨Frangiå“åº”å‡½æ•°è®¡ç®—å¢žå¼ºå€¼\n",
    "    \n",
    "    å‚æ•°:\n",
    "        image: numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º (D, H, W) æˆ– (D, H, W, 1) çš„3Då›¾åƒ\n",
    "        sigmas: tupleï¼Œé«˜æ–¯æ ¸çš„æ ‡å‡†å·®èŒƒå›´ï¼Œç”¨äºŽå¤šå°ºåº¦æ£€æµ‹\n",
    "                ä¾‹å¦‚ (1, 3, 5) è¡¨ç¤ºæ£€æµ‹1åˆ°5åƒç´ å®½åº¦çš„è¡€ç®¡\n",
    "        beta1: floatï¼ŒæŽ§åˆ¶å¯¹åç¦»ç®¡çŠ¶ç»“æž„çš„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤0.5ï¼‰\n",
    "        beta2: floatï¼ŒæŽ§åˆ¶å¯¹èƒŒæ™¯çš„æ•æ„Ÿåº¦ï¼ˆé»˜è®¤15ï¼‰\n",
    "        gamma: floatï¼Œå½’ä¸€åŒ–å› å­ï¼Œå¦‚æžœä¸ºNoneåˆ™è‡ªåŠ¨è®¡ç®—\n",
    "        black_ridges: boolï¼ŒTrueè¡¨ç¤ºæ£€æµ‹æš—è‰²ç®¡çŠ¶ç»“æž„ï¼ˆè¡€ç®¡ï¼‰ï¼ŒFalseè¡¨ç¤ºæ£€æµ‹äº®è‰²ç»“æž„\n",
    "    \n",
    "    è¿”å›ž:\n",
    "        enhanced: numpyæ•°ç»„ï¼Œå¢žå¼ºåŽçš„å›¾åƒï¼Œå½¢çŠ¶ä¸Žè¾“å…¥ç›¸åŒ\n",
    "    \"\"\"\n",
    "    # ç¡®ä¿è¾“å…¥æ˜¯3Dæ•°ç»„\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[..., 0]\n",
    "    \n",
    "    # ç¡®ä¿æ˜¯floatç±»åž‹\n",
    "    image = image.astype(np.float64)\n",
    "    \n",
    "    # å¦‚æžœæ£€æµ‹æš—è‰²ç»“æž„ï¼Œåè½¬å›¾åƒ\n",
    "    if black_ridges:\n",
    "        image = -image\n",
    "    \n",
    "    # åˆå§‹åŒ–è¾“å‡º\n",
    "    enhanced = np.zeros_like(image)\n",
    "    \n",
    "    # å¯¹æ¯ä¸ªå°ºåº¦è®¡ç®—Frangiå“åº”\n",
    "    for sigma in sigmas:\n",
    "        # è®¡ç®—HessiançŸ©é˜µçš„å„ä¸ªåˆ†é‡\n",
    "        # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢çš„å¯¼æ•°\n",
    "        hxx = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=2), \n",
    "                sigma, axis=1, order=0), \n",
    "            sigma, axis=0, order=0)\n",
    "        \n",
    "        hyy = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=0), \n",
    "                sigma, axis=1, order=2), \n",
    "            sigma, axis=0, order=0)\n",
    "        \n",
    "        hzz = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=0), \n",
    "                sigma, axis=1, order=0), \n",
    "            sigma, axis=0, order=2)\n",
    "        \n",
    "        hxy = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=1), \n",
    "                sigma, axis=1, order=1), \n",
    "            sigma, axis=0, order=0)\n",
    "        \n",
    "        hxz = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=1), \n",
    "                sigma, axis=1, order=0), \n",
    "            sigma, axis=0, order=1)\n",
    "        \n",
    "        hyz = ndimage.gaussian_filter1d(\n",
    "            ndimage.gaussian_filter1d(\n",
    "                ndimage.gaussian_filter1d(image, sigma, axis=2, order=0), \n",
    "                sigma, axis=1, order=1), \n",
    "            sigma, axis=0, order=1)\n",
    "        \n",
    "        # æž„å»ºHessiançŸ©é˜µå¹¶è®¡ç®—ç‰¹å¾å€¼\n",
    "        # å¯¹äºŽ3Dï¼Œæˆ‘ä»¬éœ€è¦åœ¨æ¯ä¸ªä½“ç´ å¤„è®¡ç®—3x3çŸ©é˜µçš„ç‰¹å¾å€¼\n",
    "        # è¿™é‡Œä½¿ç”¨è¿‘ä¼¼æ–¹æ³•ï¼šè®¡ç®—ç‰¹å¾å€¼çš„å¹³æ–¹å’Œ\n",
    "        # æ›´ç²¾ç¡®çš„æ–¹æ³•éœ€è¦é€åƒç´ è®¡ç®—ç‰¹å¾å€¼ï¼Œä½†è®¡ç®—é‡å¤§\n",
    "        \n",
    "        # ç®€åŒ–çš„Frangiå“åº”è®¡ç®—ï¼ˆåŸºäºŽHessiançŸ©é˜µçš„è¿¹å’Œè¡Œåˆ—å¼ï¼‰\n",
    "        # å¯¹äºŽç®¡çŠ¶ç»“æž„ï¼šä¸€ä¸ªç‰¹å¾å€¼æŽ¥è¿‘0ï¼Œå¦å¤–ä¸¤ä¸ªè¾ƒå¤§ä¸”ç¬¦å·ç›¸åŒ\n",
    "        trace = hxx + hyy + hzz\n",
    "        det = (hxx * hyy * hzz + \n",
    "               2 * hxy * hxz * hyz - \n",
    "               hxx * hyz * hyz - \n",
    "               hyy * hxz * hxz - \n",
    "               hzz * hxy * hxy)\n",
    "        \n",
    "        # Frangiå“åº”å‡½æ•°\n",
    "        # å¯¹äºŽç®¡çŠ¶ç»“æž„ï¼Œæˆ‘ä»¬å¸Œæœ›ï¼š\n",
    "        # - ä¸€ä¸ªç‰¹å¾å€¼æŽ¥è¿‘0ï¼ˆæ²¿ç®¡è½´æ–¹å‘ï¼‰\n",
    "        # - å¦å¤–ä¸¤ä¸ªç‰¹å¾å€¼è¾ƒå¤§ä¸”åŒå·ï¼ˆåž‚ç›´äºŽç®¡è½´ï¼‰\n",
    "        \n",
    "        # ä½¿ç”¨è¿¹å’Œè¡Œåˆ—å¼çš„ç»„åˆæ¥è¿‘ä¼¼\n",
    "        # å½’ä¸€åŒ–\n",
    "        if gamma is None:\n",
    "            gamma = np.max(np.abs(trace))\n",
    "        \n",
    "        # è®¡ç®—å“åº”\n",
    "        # ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºŽHessiançŸ©é˜µçš„FrobeniusèŒƒæ•°\n",
    "        hessian_norm = np.sqrt(hxx**2 + hyy**2 + hzz**2 + \n",
    "                              2 * (hxy**2 + hxz**2 + hyz**2))\n",
    "        \n",
    "        # Frangiå“åº”\n",
    "        response = np.exp(-beta1 * (trace**2) / (hessian_norm + 1e-10)) * \\\n",
    "                   (1 - np.exp(-beta2 * hessian_norm**2 / (gamma**2 + 1e-10)))\n",
    "        \n",
    "        # åªä¿ç•™æ­£å€¼ï¼ˆç®¡çŠ¶ç»“æž„ï¼‰\n",
    "        response = np.maximum(response, 0)\n",
    "        \n",
    "        # å–æ‰€æœ‰å°ºåº¦ä¸­çš„æœ€å¤§å€¼\n",
    "        enhanced = np.maximum(enhanced, response)\n",
    "    \n",
    "    # å½’ä¸€åŒ–åˆ°[0, 1]\n",
    "    if enhanced.max() > 0:\n",
    "        enhanced = enhanced / enhanced.max()\n",
    "    \n",
    "    return enhanced.astype(np.float32)\n",
    "\n",
    "\n",
    "def apply_frangi_postprocessing(prediction, threshold=0.5, sigmas=(1, 3, 5), \n",
    "                                beta1=0.5, beta2=15, use_frangi=True):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨Frangiæ»¤æ³¢å™¨å¯¹åˆ†å‰²é¢„æµ‹ç»“æžœè¿›è¡ŒåŽå¤„ç†ã€‚\n",
    "    \n",
    "    è¿™ä¸ªæ–¹æ³•å¯ä»¥ï¼š\n",
    "    1. ä½¿ç”¨Frangiæ»¤æ³¢å™¨å¢žå¼ºé¢„æµ‹ç»“æžœä¸­çš„ç®¡çŠ¶ç»“æž„\n",
    "    2. ç»“åˆåŽŸå§‹é¢„æµ‹å’ŒFrangiå¢žå¼ºç»“æžœ\n",
    "    3. åº”ç”¨é˜ˆå€¼å¾—åˆ°æœ€ç»ˆçš„åˆ†å‰²æŽ©ç \n",
    "    \n",
    "    å‚æ•°:\n",
    "        prediction: numpyæ•°ç»„ï¼Œæ¨¡åž‹é¢„æµ‹çš„æ¦‚çŽ‡å›¾ï¼Œå½¢çŠ¶ä¸º (D, H, W) æˆ– (D, H, W, num_classes)\n",
    "        threshold: floatï¼ŒäºŒå€¼åŒ–é˜ˆå€¼ï¼ˆé»˜è®¤0.5ï¼‰\n",
    "        sigmas: tupleï¼ŒFrangiæ»¤æ³¢å™¨çš„å°ºåº¦å‚æ•°\n",
    "        beta1: floatï¼ŒFrangiå‚æ•°\n",
    "        beta2: floatï¼ŒFrangiå‚æ•°\n",
    "        use_frangi: boolï¼Œæ˜¯å¦ä½¿ç”¨Frangiæ»¤æ³¢å™¨ï¼ˆå¦‚æžœFalseï¼Œåªåšé˜ˆå€¼åŒ–ï¼‰\n",
    "    \n",
    "    è¿”å›ž:\n",
    "        processed_mask: numpyæ•°ç»„ï¼Œå¤„ç†åŽçš„äºŒå€¼æŽ©ç ï¼Œå½¢çŠ¶ä¸º (D, H, W)\n",
    "    \"\"\"\n",
    "    # å¤„ç†å¤šç±»åˆ«é¢„æµ‹\n",
    "    if len(prediction.shape) == 4:\n",
    "        # å¦‚æžœæ˜¯å¤šç±»åˆ«ï¼Œå–å‰æ™¯ç±»åˆ«ï¼ˆå‡è®¾ç±»åˆ«1æ˜¯è¡€ç®¡/å¢¨æ°´ï¼‰\n",
    "        if prediction.shape[-1] > 1:\n",
    "            pred_prob = prediction[..., 1]  # å–ç±»åˆ«1çš„æ¦‚çŽ‡\n",
    "        else:\n",
    "            pred_prob = prediction[..., 0]\n",
    "    else:\n",
    "        pred_prob = prediction\n",
    "    \n",
    "    if use_frangi:\n",
    "        # åº”ç”¨Frangiæ»¤æ³¢å™¨å¢žå¼ºç®¡çŠ¶ç»“æž„\n",
    "        frangi_enhanced = frangi_filter_3d(\n",
    "            pred_prob, \n",
    "            sigmas=sigmas, \n",
    "            beta1=beta1, \n",
    "            beta2=beta2,\n",
    "            black_ridges=True  # å‡è®¾æ£€æµ‹æš—è‰²ç»“æž„\n",
    "        )\n",
    "        \n",
    "        # ç»“åˆåŽŸå§‹é¢„æµ‹å’ŒFrangiå¢žå¼ºç»“æžœ\n",
    "        # æ–¹æ³•1ï¼šåŠ æƒå¹³å‡\n",
    "        combined = 0.7 * pred_prob + 0.3 * frangi_enhanced\n",
    "        \n",
    "        # æ–¹æ³•2ï¼šå–æœ€å¤§å€¼ï¼ˆä¿ç•™æ›´å¼ºçš„å“åº”ï¼‰\n",
    "        # combined = np.maximum(pred_prob, frangi_enhanced)\n",
    "        \n",
    "        # æ–¹æ³•3ï¼šåªåœ¨Frangiæ£€æµ‹åˆ°çš„åŒºåŸŸå¢žå¼º\n",
    "        # frangi_mask = frangi_enhanced > 0.3\n",
    "        # combined = pred_prob.copy()\n",
    "        # combined[frangi_mask] = np.maximum(pred_prob[frangi_mask], frangi_enhanced[frangi_mask])\n",
    "        \n",
    "        processed_prob = combined\n",
    "    else:\n",
    "        processed_prob = pred_prob\n",
    "    \n",
    "    # äºŒå€¼åŒ–\n",
    "    processed_mask = (processed_prob > threshold).astype(np.uint8)\n",
    "    \n",
    "    return processed_mask\n",
    "\n",
    "def build_anisotropic_struct(z_radius, xy_radius):\n",
    "    \"\"\"\n",
    "    æž„å»ºå„å‘å¼‚æ€§ç»“æž„å…ƒç´ ç”¨äºŽ3Dé—­è¿ç®—\n",
    "    \n",
    "    å‚æ•°:\n",
    "        z_radius: zæ–¹å‘çš„åŠå¾„\n",
    "        xy_radius: xyå¹³é¢çš„åŠå¾„\n",
    "    \n",
    "    è¿”å›ž:\n",
    "        structure: 3Dç»“æž„å…ƒç´ ï¼Œå¦‚æžœåŠå¾„éƒ½ä¸º0åˆ™è¿”å›žNone\n",
    "    \"\"\"\n",
    "    if z_radius == 0 and xy_radius == 0:\n",
    "        return None\n",
    "    \n",
    "    size_z = 2 * z_radius + 1\n",
    "    size_xy = 2 * xy_radius + 1\n",
    "    \n",
    "    struct = np.zeros((size_z, size_xy, size_xy), dtype=bool)\n",
    "    center_z = z_radius\n",
    "    center_xy = xy_radius\n",
    "    \n",
    "    # åˆ›å»ºå„å‘å¼‚æ€§ç»“æž„\n",
    "    for z in range(size_z):\n",
    "        for y in range(size_xy):\n",
    "            for x in range(size_xy):\n",
    "                dz = abs(z - center_z)\n",
    "                dxy = np.sqrt((x - center_xy)**2 + (y - center_xy)**2)\n",
    "                if dz <= z_radius and dxy <= xy_radius:\n",
    "                    struct[z, y, x] = True\n",
    "    \n",
    "    return struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58039d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topo_postprocess(\n",
    "    probs,          # (D, H, W)\n",
    "    T_low=0.90,\n",
    "    T_high=0.90,\n",
    "    z_radius=1,\n",
    "    xy_radius=0,\n",
    "    dust_min_size=100,\n",
    "):\n",
    "    # --- Step 1: 3D Hysteresis ---\n",
    "    strong = probs >= T_high\n",
    "    weak   = probs >= T_low\n",
    "\n",
    "    if not strong.any():\n",
    "        return np.zeros_like(probs, dtype=np.uint8)\n",
    "\n",
    "    struct_hyst = ndi.generate_binary_structure(3, 3)\n",
    "    mask = ndi.binary_propagation(strong, mask=weak, structure=struct_hyst)\n",
    "\n",
    "    if not mask.any():\n",
    "        return np.zeros_like(probs, dtype=np.uint8)\n",
    "\n",
    "    # --- Step 2: 3D Anisotropic Closing ---\n",
    "    if z_radius > 0 or xy_radius > 0:\n",
    "        struct_close = build_anisotropic_struct(z_radius, xy_radius)\n",
    "        if struct_close is not None:\n",
    "            mask = ndi.binary_closing(mask, structure=struct_close)\n",
    "\n",
    "    # --- Step 3: Dust Removal ---\n",
    "    if dust_min_size > 0:\n",
    "        mask = remove_small_objects(mask.astype(bool), min_size=dust_min_size)\n",
    "\n",
    "    return mask.astype(np.uint8)\n",
    "\n",
    "\n",
    "def topo_postprocess_with_frangi(\n",
    "    probs,          # (D, H, W)\n",
    "    T_low=0.90,\n",
    "    T_high=0.90,\n",
    "    z_radius=1,\n",
    "    xy_radius=0,\n",
    "    dust_min_size=100,\n",
    "    # Frangiå‚æ•°\n",
    "    use_frangi=True,\n",
    "    frangi_weight=0.3,      # Frangiå¢žå¼ºçš„æƒé‡ (0-1)\n",
    "    frangi_sigmas=(1, 3, 5),\n",
    "    frangi_beta1=0.5,\n",
    "    frangi_beta2=15,\n",
    "    frangi_mode='enhance_before',  # 'enhance_before', 'enhance_after', 'replace_hyst'\n",
    "):\n",
    "    \"\"\"\n",
    "    é›†æˆFrangiæ»¤æ³¢å™¨çš„æ‹“æ‰‘åŽå¤„ç†\n",
    "    \n",
    "    å‚æ•°:\n",
    "        probs: æ¦‚çŽ‡å›¾ (D, H, W)\n",
    "        T_low, T_high: Hysteresisé˜ˆå€¼\n",
    "        z_radius, xy_radius: å„å‘å¼‚æ€§é—­è¿ç®—å‚æ•°\n",
    "        dust_min_size: å°å¯¹è±¡åŽ»é™¤çš„æœ€å°å°ºå¯¸\n",
    "        use_frangi: æ˜¯å¦ä½¿ç”¨Frangiæ»¤æ³¢å™¨\n",
    "        frangi_weight: Frangiå¢žå¼ºçš„æƒé‡ï¼ˆ0-1ä¹‹é—´ï¼‰\n",
    "        frangi_sigmas: Frangiæ»¤æ³¢å™¨çš„å°ºåº¦å‚æ•°\n",
    "        frangi_beta1, frangi_beta2: Frangiå‚æ•°\n",
    "        frangi_mode: Frangié›†æˆæ¨¡å¼\n",
    "            - 'enhance_before': åœ¨Hysteresisä¹‹å‰å¢žå¼ºæ¦‚çŽ‡å›¾ï¼ˆæŽ¨èï¼‰\n",
    "            - 'enhance_after': åœ¨Hysteresisä¹‹åŽå¢žå¼ºæŽ©ç \n",
    "            - 'replace_hyst': ç”¨Frangiå¢žå¼ºçš„æ¦‚çŽ‡å›¾æ›¿ä»£Hysteresis\n",
    "    \n",
    "    è¿”å›ž:\n",
    "        mask: å¤„ç†åŽçš„äºŒå€¼æŽ©ç  (D, H, W) uint8\n",
    "    \"\"\"\n",
    "    if not use_frangi:\n",
    "        # å¦‚æžœä¸ä½¿ç”¨Frangiï¼Œç›´æŽ¥ä½¿ç”¨åŽŸå§‹åŽå¤„ç†\n",
    "        return topo_postprocess(\n",
    "            probs, T_low, T_high, z_radius, xy_radius, dust_min_size\n",
    "        )\n",
    "    \n",
    "    # åº”ç”¨Frangiæ»¤æ³¢å™¨å¢žå¼º\n",
    "    frangi_enhanced = frangi_filter_3d(\n",
    "        probs,\n",
    "        sigmas=frangi_sigmas,\n",
    "        beta1=frangi_beta1,\n",
    "        beta2=frangi_beta2,\n",
    "        black_ridges=True  # å‡è®¾æ£€æµ‹æš—è‰²ç»“æž„ï¼ˆè¡€ç®¡ï¼‰\n",
    "    )\n",
    "    \n",
    "    if frangi_mode == 'enhance_before':\n",
    "        # æ¨¡å¼1: åœ¨Hysteresisä¹‹å‰å¢žå¼ºæ¦‚çŽ‡å›¾ï¼ˆæŽ¨èï¼‰\n",
    "        # ç»“åˆåŽŸå§‹æ¦‚çŽ‡å’ŒFrangiå¢žå¼ºç»“æžœ\n",
    "        enhanced_probs = (1 - frangi_weight) * probs + frangi_weight * frangi_enhanced\n",
    "        \n",
    "        # ç„¶åŽè¿›è¡Œæ ‡å‡†çš„æ‹“æ‰‘åŽå¤„ç†\n",
    "        return topo_postprocess(\n",
    "            enhanced_probs, T_low, T_high, z_radius, xy_radius, dust_min_size\n",
    "        )\n",
    "    \n",
    "    elif frangi_mode == 'enhance_after':\n",
    "        # æ¨¡å¼2: åœ¨Hysteresisä¹‹åŽå¢žå¼ºæŽ©ç \n",
    "        # å…ˆè¿›è¡Œæ ‡å‡†æ‹“æ‰‘åŽå¤„ç†\n",
    "        mask = topo_postprocess(\n",
    "            probs, T_low, T_high, z_radius, xy_radius, dust_min_size\n",
    "        )\n",
    "        \n",
    "        # å°†æŽ©ç è½¬æ¢ä¸ºæ¦‚çŽ‡å›¾ï¼ˆç”¨äºŽFrangiï¼‰\n",
    "        mask_probs = mask.astype(np.float32)\n",
    "        \n",
    "        # åº”ç”¨Frangiå¢žå¼º\n",
    "        frangi_mask = frangi_filter_3d(\n",
    "            mask_probs,\n",
    "            sigmas=frangi_sigmas,\n",
    "            beta1=frangi_beta1,\n",
    "            beta2=frangi_beta2,\n",
    "            black_ridges=True\n",
    "        )\n",
    "        \n",
    "        # ç»“åˆåŽŸå§‹æŽ©ç å’ŒFrangiå¢žå¼ºç»“æžœ\n",
    "        enhanced_mask = np.maximum(\n",
    "            mask_probs,\n",
    "            frangi_mask * frangi_weight\n",
    "        )\n",
    "        \n",
    "        # äºŒå€¼åŒ–\n",
    "        return (enhanced_mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    elif frangi_mode == 'replace_hyst':\n",
    "        # æ¨¡å¼3: ç”¨Frangiå¢žå¼ºçš„æ¦‚çŽ‡å›¾æ›¿ä»£Hysteresis\n",
    "        # ç»“åˆåŽŸå§‹æ¦‚çŽ‡å’ŒFrangiå¢žå¼ºç»“æžœ\n",
    "        enhanced_probs = (1 - frangi_weight) * probs + frangi_weight * frangi_enhanced\n",
    "        \n",
    "        # ä½¿ç”¨ç®€å•çš„é˜ˆå€¼åŒ–æ›¿ä»£Hysteresis\n",
    "        mask = enhanced_probs >= T_high\n",
    "        \n",
    "        if not mask.any():\n",
    "            return np.zeros_like(probs, dtype=np.uint8)\n",
    "        \n",
    "        # ç„¶åŽè¿›è¡Œé—­è¿ç®—å’Œå°å¯¹è±¡åŽ»é™¤\n",
    "        if z_radius > 0 or xy_radius > 0:\n",
    "            struct_close = build_anisotropic_struct(z_radius, xy_radius)\n",
    "            if struct_close is not None:\n",
    "                mask = ndi.binary_closing(mask, structure=struct_close)\n",
    "        \n",
    "        if dust_min_size > 0:\n",
    "            mask = remove_small_objects(mask.astype(bool), min_size=dust_min_size)\n",
    "        \n",
    "        return mask.astype(np.uint8)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown frangi_mode: {frangi_mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8546b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pred = sigmoid(logits_pred)\n",
    "prob_pred = np.transpose(prob_pred.squeeze().cpu().numpy(), (2, 1, 0))\n",
    "\n",
    "T_low=0.50\n",
    "T_high=0.90\n",
    "z_radius=2\n",
    "xy_radius=0\n",
    "dust_min_size=100\n",
    "# Frangiå‚æ•°\n",
    "use_frangi=True\n",
    "frangi_weight=0.3\n",
    "frangi_sigmas=(1, 3, 5)\n",
    "frangi_beta1=0.5\n",
    "frangi_beta2=15\n",
    "frangi_mode='enhance_after'\n",
    "\n",
    "CROP_MARGIN = 9\n",
    "prob_pred[:CROP_MARGIN, :, :] = 0\n",
    "prob_pred[-CROP_MARGIN:, :, :] = 0\n",
    "prob_pred[:, :CROP_MARGIN, :] = 0\n",
    "prob_pred[:, -CROP_MARGIN:, :] = 0\n",
    "prob_pred[:, :, :CROP_MARGIN] = 0\n",
    "prob_pred[:, :, -CROP_MARGIN:] = 0\n",
    "\n",
    "final = topo_postprocess_with_frangi(\n",
    "        prob_pred,\n",
    "        T_low=T_low,\n",
    "        T_high=T_high,\n",
    "        z_radius=z_radius,\n",
    "        xy_radius=xy_radius,\n",
    "        dust_min_size=dust_min_size,\n",
    "        use_frangi=use_frangi,\n",
    "        frangi_weight=frangi_weight,\n",
    "        frangi_sigmas=frangi_sigmas,\n",
    "        frangi_beta1=frangi_beta1,\n",
    "        frangi_beta2=frangi_beta2,\n",
    "        frangi_mode=frangi_mode,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9593cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask = final\n",
    "#3545147380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de927f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_3545147380_2.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.5336816641958646),\n",
       " 'topo_score': 0.11994572591587517,\n",
       " 'surface_dice': 0.8763440854818639,\n",
       " 'voi_score': 0.545650047149856,\n",
       " 'voi_split': 1.1428135789370542,\n",
       " 'voi_merge': 1.6327746405538806}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/final_pred_3545147380_2.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/3545147380.tif\"\n",
    "tifffile.imwrite(out_path, final_mask)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_3545147380_2.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report\n",
    "# origin 0.5305181364493412\t0.07948210753461608\t0.8984319807505937\t0.5492066026464245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ced6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROP_MARGIN = 13\n",
    "\n",
    "\n",
    "#CROP_MARGIN = 9\n",
    "{'image_score': np.float64(0.6928263230558964),\n",
    " 'topo_score': 0.445279804451687,\n",
    " 'surface_dice': 0.9405297829991504,\n",
    " 'voi_score': 0.6573055933448219,\n",
    " 'voi_split': 0.848328060203944,\n",
    " 'voi_merge': 0.8895465302703475}\n",
    "\n",
    "# baseline\n",
    "{'image_score': np.float64(0.6104108550613401),\n",
    " 'topo_score': 0.1529262777023971,\n",
    " 'surface_dice': 0.9510553115288458,\n",
    " 'voi_score': 0.6618960363300709,\n",
    " 'voi_split': 0.8085355515981472,\n",
    " 'voi_merge': 0.8941687257713037}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image...\n",
      "Saving to /home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_2536049117_2.tif\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image_score': np.float64(0.6780419710157646),\n",
       " 'topo_score': 0.4046731857951621,\n",
       " 'surface_dice': 0.9347838644857932,\n",
       " 'voi_score': 0.6556161791633951,\n",
       " 'voi_split': 0.859161504979191,\n",
       " 'voi_merge': 0.8917807474225056}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remover os cantos Ã  mÃ£o nÃ£o resolveu nada\n",
    "import nibabel as nib\n",
    "\n",
    "prediction_post_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_2536049117_2.nii.gz-label.nii.gz\"\n",
    "# Load nifti\n",
    "nifti_img = nib.load(prediction_post_path)\n",
    "\n",
    "# 2. Get the actual data as a NumPy array\n",
    "prediction_post = nifti_img.get_fdata().astype(np.int16)\n",
    "prediction_post[prediction_post>0.5]=1\n",
    "\n",
    "#prediction_post = np.transpose(prediction_post, (2, 1, 0))\n",
    "#prediction_post = np.transpose(prediction_post, (2, 0, 1))\n",
    "#prediction_post = np.transpose(prediction_post, (0, 2, 1))\n",
    "#prediction_post = np.transpose(prediction_post, (2, 1, 0))\n",
    "#prediction_post = np.flip(prediction_post, axis=1)\n",
    "prediction_post = np.flip(prediction_post, axis=1)\n",
    "prediction_post = np.flip(prediction_post, axis=0) \n",
    "prediction_post = np.transpose(prediction_post, (2, 1, 0)).astype(np.uint16)\n",
    "\n",
    "\n",
    "\n",
    "out_path = f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/mine_final_pred_2536049117_2.tif\"\n",
    "gt_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/val_labels/2536049117.tif\"\n",
    "tifffile.imwrite(out_path, prediction_post)\n",
    "\n",
    "split_by_object(out_path, f\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_process_5/categorical_final_pred_2536049117_2.tif\")\n",
    "\n",
    "score_report = score_single_tif(\n",
    "    gt_path=gt_path,\n",
    "    pred_path=out_path,\n",
    "    surface_tolerance=2.0,\n",
    "    voi_connectivity=26,\n",
    "    voi_transform='one_over_one_plus',\n",
    "    voi_alpha=0.3,\n",
    "    topo_weight=0.3,\n",
    "    surface_dice_weight=0.35,\n",
    "    voi_weight=0.35,\n",
    ")\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51b4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo-metrics-3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
