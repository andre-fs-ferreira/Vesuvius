{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "307f0d24",
   "metadata": {},
   "source": [
    "# Develop a light GAN for post processing\n",
    "* The input must be the biggest size in the dataset\n",
    "* Both Generator and Discriminator must fit in the GPU (48GB VRAM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ecb6d",
   "metadata": {},
   "source": [
    "### Check biggest (384,384,384 although there is only 1 case with this shape...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the bigest shape\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "all_shapes = []\n",
    "root_dataset = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop\"\n",
    "for file_name in os.listdir(root_dataset):\n",
    "    if file_name.endswith('.nii.gz'):\n",
    "        file_path = os.path.join(root_dataset, file_name)\n",
    "        img_array = nib.load(file_path).get_fdata()\n",
    "        all_shapes.append(img_array.shape)\n",
    "        #if img_array.shape[0]>320:\n",
    "        print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_shapes = [shape_element[0] for shape_element in all_shapes]\n",
    "y_all_shapes = [shape_element[1] for shape_element in all_shapes]\n",
    "z_all_shapes = [shape_element[2] for shape_element in all_shapes]\n",
    "\n",
    "print(f\"Biggest x: {max(x_all_shapes)}\")\n",
    "print(f\"Biggest y: {max(y_all_shapes)}\")\n",
    "print(f\"Biggest z: {max(z_all_shapes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59e1f1",
   "metadata": {},
   "source": [
    "### Create MedNeXt network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb87cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_step():\n",
    "    # 1. Setup Device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    print(f\"Running on {device}...\")\n",
    "\n",
    "    # 2. Initialize Model, Optimizer, and Scaler (for AMP)\n",
    "    discriminator = PatchDiscriminator(in_channels=2, initial_filters=16).to(device)\n",
    "    optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "    criterion = nn.MSELoss() # Least Squares GAN (LSGAN) loss\n",
    "    scaler = GradScaler()     # Necessary for stable AMP training\n",
    "\n",
    "    # 3. Create Inputs\n",
    "    # Input: [B, 2, 320, 320, 320] -> (CT + Predicted_Mask)\n",
    "    input_tensor = torch.randn(1, 2, 320, 320, 320, device=device)\n",
    "    \n",
    "    print(f\"Starting training step with AMP...\")\n",
    "\n",
    "    # --- TRAINING STEP START ---\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass with AMP\n",
    "    with autocast(device_type=device.type):\n",
    "        output = discriminator(input_tensor)\n",
    "        print(f\"Discriminator Output Shape: {output.shape}\")\n",
    "        \n",
    "        # CRITICAL FIX: Creates target based on ACTUAL output shape (e.g., 38x38x38)\n",
    "        # We cannot use a 320x320x320 target for a PatchGAN output.\n",
    "        target = torch.randn_like(output, device=device) \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass with Scaler\n",
    "    print(\"Computing Gradients...\")\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # Optimizer Step\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # --- TRAINING STEP END ---\n",
    "\n",
    "    print(f\"Step successful. Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # 4. Measure Memory\n",
    "    if device.type == 'cuda':\n",
    "        peak_mem = torch.cuda.max_memory_allocated() / (1024 ** 3)\n",
    "        print(f\"Peak Training VRAM: {peak_mem:.2f} GiB\")\n",
    "    else:\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print(f\"System RAM used: {process.memory_info().rss / (1024 ** 3):.2f} GiB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c672da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.nn.utils import spectral_norm\n",
    "def run_test():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Running test on: {device}\")\n",
    "\n",
    "    # A. Create Dummy Data\n",
    "    # Batch=2, Size=64^3 (Small enough for CPU testing if needed)\n",
    "    B, D, H, W = 2, 64, 64, 64\n",
    "    \n",
    "    # CT Scan (Normalized)\n",
    "    ct_data = torch.randn(B, 1, D, H, W)\n",
    "    # Coarse Logits (Simulated output from previous net)\n",
    "    coarse_logits = torch.randn(B, 1, D, H, W)\n",
    "    # Ground Truth (Binary Mask 0 or 1)\n",
    "    gt_mask = torch.randint(0, 2, (B, 1, D, H, W)).float()\n",
    "\n",
    "    dataset = TensorDataset(ct_data, coarse_logits, gt_mask)\n",
    "    dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "    # B. Initialize Models & Optimizers\n",
    "    gen = Generator().to(device)\n",
    "    disc = PatchDiscriminator().to(device)\n",
    "    \n",
    "    opt_g = optim.Adam(gen.parameters(), lr=1e-3)\n",
    "    opt_d = optim.Adam(disc.parameters(), lr=1e-3)\n",
    "    \n",
    "    criterion_GAN = nn.MSELoss()\n",
    "    criterion_BCE = nn.BCEWithLogitsLoss()\n",
    "    criterion_Tversky = TverskyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    LAMBDA_SEG = 100.0\n",
    "    LAMBDA_ADV = 1.0\n",
    "\n",
    "    print(\"Setup complete. Starting training loop...\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. The Training Loop Logic\n",
    "    # ==========================================\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    \n",
    "    # Run 3 steps to verify gradients actually change\n",
    "    initial_loss = None\n",
    "    \n",
    "    for step in range(3):\n",
    "        for real_ct, coarse, real_gt in dataloader:\n",
    "            real_ct, coarse, real_gt = real_ct.to(device), coarse.to(device), real_gt.to(device)\n",
    "            \n",
    "            # --- 1. Discriminator Step ---\n",
    "            opt_d.zero_grad()\n",
    "            with autocast(device_type=device.type):\n",
    "                # Real\n",
    "                d_input_real = torch.cat([real_ct, real_gt], dim=1)\n",
    "                d_real = disc(d_input_real)\n",
    "                loss_d_real = criterion_GAN(d_real, torch.ones_like(d_real))\n",
    "                \n",
    "                # Fake\n",
    "                g_input = torch.cat([real_ct, coarse], dim=1)\n",
    "                refined_logits = gen(g_input)\n",
    "                refined_probs = torch.sigmoid(refined_logits)\n",
    "                \n",
    "                d_input_fake = torch.cat([real_ct, refined_probs.detach()], dim=1)\n",
    "                d_fake = disc(d_input_fake)\n",
    "                loss_d_fake = criterion_GAN(d_fake, torch.zeros_like(d_fake))\n",
    "                \n",
    "                loss_d = (loss_d_real + loss_d_fake) * 0.5\n",
    "\n",
    "            scaler.scale(loss_d).backward()\n",
    "            scaler.step(opt_d)\n",
    "\n",
    "            # --- 2. Generator Step ---\n",
    "            opt_g.zero_grad()\n",
    "            with autocast(device_type=device.type):\n",
    "                # Adversarial (Fool D)\n",
    "                # Note: We re-calculate d_fake WITH gradients flowing to G\n",
    "                d_input_g = torch.cat([real_ct, torch.sigmoid(refined_logits)], dim=1)\n",
    "                d_pred = disc(d_input_g)\n",
    "                loss_g_adv = criterion_GAN(d_pred, torch.ones_like(d_pred))\n",
    "                \n",
    "                # Segmentation (Structure)\n",
    "                loss_g_seg = criterion_BCE(refined_logits, real_gt) + criterion_Tversky(refined_logits, real_gt)\n",
    "                \n",
    "                loss_g = (LAMBDA_SEG * loss_g_seg) + (LAMBDA_ADV * loss_g_adv)\n",
    "\n",
    "            scaler.scale(loss_g).backward()\n",
    "            scaler.step(opt_g)\n",
    "            scaler.update()\n",
    "\n",
    "            print(f\"Step {step+1}: D Loss={loss_d.item():.4f}, G Loss={loss_g.item():.4f}\")\n",
    "            \n",
    "            if step == 0:\n",
    "                initial_loss = loss_g.item()\n",
    "            elif step == 2:\n",
    "                if loss_g.item() != initial_loss:\n",
    "                    print(\"\\nSUCCESS: Loss is changing. Gradients are flowing.\")\n",
    "                else:\n",
    "                    print(\"\\nWARNING: Loss is identical. Check for detached gradients.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69b6e0",
   "metadata": {},
   "source": [
    "### Building the training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "from os.path import join\n",
    "sys.path.append(\"../utils\")\n",
    "from main_train_class import main_train_STU_Net\n",
    "from GANs_networks import Generator, PatchDiscriminator\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import sigmoid, binary_cross_entropy_with_logits\n",
    "# Standard Library Imports\n",
    "from os.path import join\n",
    "import sys\n",
    "\n",
    "import json\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import sigmoid\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.nn import MSELoss\n",
    "# MONAI Specific Imports\n",
    "import monai\n",
    "from monai.data import CacheDataset\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    CopyItemsd,\n",
    "    LoadImaged, \n",
    "    ScaleIntensityRanged, \n",
    "    ResizeWithPadOrCropd,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd\n",
    ")\n",
    "from mask_utils import GetROIMaskdd, GetBinaryLabeld\n",
    "# Local Project Imports\n",
    "\n",
    "class postprocessConvNeXt(main_train_STU_Net):\n",
    "    def __init__(self, config):\n",
    "        # TODO predict and save logits from the segmentation network\n",
    "        self.config = config\n",
    "        self.labda_seg = self.config['labda_seg']\n",
    "        self.G_model = self._build_models()\n",
    "        self.train_loader = self._set_train_dataloader() \n",
    "        self.val_loader = self._set_val_dataloader() \n",
    "        self.opt_G = self._set_optimizers()\n",
    "        self.wandb_run = self._set_wandb_checkpoint() # Heritage\n",
    "        # Expects lists of predictions # TODO put predictions inside of a list\n",
    "        self.G_voxel_criterion = self._set_train_criterion() # Heritage\n",
    "        \n",
    "        self.val_metric = self._set_val_metric() # Heritage\n",
    "        self.G_cosAnnealLR = self._set_scheduler()\n",
    "\n",
    "        # set scaler for mix precision \n",
    "        self.G_scaler = GradScaler()\n",
    "        \n",
    "        # check resume\n",
    "        self._resume()\n",
    "\n",
    "    def _build_models(self):\n",
    "        # TODO change network\n",
    "        model = new_ConvNeXt(in_channels=2, first_channels=16, out_channels=1, use_checkpointing=True).to(self.config['device'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _resume(self):\n",
    "        if self.config.get('resume'):\n",
    "            G_checkpoint = torch.load(self.config['resume'], map_location=\"cpu\", weights_only=False) \n",
    "            G_model_weights = G_checkpoint['model_weights']  \n",
    "            self.G_model.load_state_dict(G_model_weights, strict=True)\n",
    "            self.G_model = self.G_model.to(self.config['device'])\n",
    "            # optimizer load\n",
    "            self.opt_G.load_state_dict(G_checkpoint['optimizer_state_dict'])\n",
    "            # parameters\n",
    "            self.start_epoch = G_checkpoint['epoch'] + 1 # To continue to the next epoch instead of repeating  \n",
    "            self.val_value = G_checkpoint['val_value']\n",
    "        else:\n",
    "            self.start_epoch = 0\n",
    "            self.val_value = 0\n",
    "\n",
    "    def _set_train_dataloader(self):\n",
    "        \"\"\" Getting the list of cases for training and loading using MONAI (all into memory)\"\"\"\n",
    "        data_list = []\n",
    "        # TODO: change back to this data list\n",
    "        #with open(self.config['data_split_json'], \"r\") as f:\n",
    "        #    split = json.load(f)\n",
    "        #train_cases = split[\"train\"]\n",
    "        #\n",
    "        train_cases = [\"2290837.nii.gz\"]\n",
    "        for train_case in train_cases:\n",
    "            complete_data_dict = {}\n",
    "            complete_data_dict[\"image\"] = join(self.config['vol_data_path'], train_case)\n",
    "            complete_data_dict[\"gt\"] = join(self.config['label_data_path'], train_case)\n",
    "            complete_data_dict[\"bridge_weight_map\"] = join(self.config['bridge_weight_map_path'], train_case)\n",
    "            # TODO in the json the pred_seg_logits needs to be changed!\n",
    "            complete_data_dict[\"pred_seg_logits\"] = join(self.config['pred_seg_logits'], train_case)\n",
    "            data_list.append(complete_data_dict)\n",
    "            \n",
    "            if self.config['debug']:\n",
    "                for i in range(30):\n",
    "                    data_list.append(complete_data_dict)\n",
    "                print(f\"training using case: {data_list[0]}\")\n",
    "                break  # repeat 30 cases for debug mode\n",
    "\n",
    "        print(f\"Train cases: {len(train_cases)}\")\n",
    "        print(f\"Some examples:\")\n",
    "        print(train_cases[:5])\n",
    "\n",
    "        transforms_list = [   \n",
    "                # Load image \n",
    "                LoadImaged(keys=[\"image\", 'gt', 'bridge_weight_map', 'pred_seg_logits']),\n",
    "                EnsureChannelFirstd(keys=[\"image\", 'gt', 'bridge_weight_map', 'pred_seg_logits']),\n",
    "\n",
    "                # Normalize uint8 input\n",
    "                ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0, b_max=1, clip=True),\n",
    "\n",
    "                # Create a ROI mask for cropping \n",
    "                GetROIMaskdd(keys=[\"gt\"], ignore_mask_value=2, new_key_names=[\"roi_mask\"]),\n",
    "\n",
    "                # Cropping or padding if bigger or smaller (expected to be all equall of smaller)\n",
    "                ResizeWithPadOrCropd(keys=[\"image\", 'gt', 'roi_mask', 'bridge_weight_map', 'pred_seg_logits'], spatial_size=self.config['patch_size'], mode=\"minimum\"),\n",
    "                GetBinaryLabeld(keys=[\"gt\"], ignore_mask_value=2),\n",
    "                EnsureTyped(keys=[\"image\", \"gt\", \"roi_mask\", \"bridge_weight_map\", 'pred_seg_logits'], track_meta=False)\n",
    "        ]\n",
    "\n",
    "        transforms = Compose(transforms_list)\n",
    "        \n",
    "        print(\"Initializing Dataset...\")\n",
    "        train_ds = CacheDataset(\n",
    "            data=data_list, \n",
    "            transform=transforms, \n",
    "            cache_rate=self.config['train_cache_rate'],  \n",
    "            num_workers=self.config['num_workers'], \n",
    "            progress=True\n",
    "        )\n",
    "\n",
    "        print(\"Initializing Train DataLoader...\")\n",
    "        train_loader = monai.data.DataLoader(\n",
    "            train_ds, \n",
    "            batch_size=self.config['batch_size'], \n",
    "            num_workers=self.config['num_workers'],\n",
    "            shuffle=True,      \n",
    "            pin_memory=True\n",
    "        )\n",
    "        return train_loader\n",
    "    \n",
    "    def _set_val_dataloader(self):\n",
    "        data_list = []\n",
    "        with open(self.config['data_split_json'], \"r\") as f:\n",
    "            split = json.load(f)\n",
    "\n",
    "        val_cases = split[\"val\"]\n",
    "\n",
    "        if self.config['debug']: \n",
    "            print(f\"Debug mode: Using training cases for validation dataloader\")\n",
    "            # train_cases = split[\"train\"] # TODO uncomment\n",
    "            train_cases = [\"2290837.nii.gz\"] # TODO remove\n",
    "            for train_case in train_cases:\n",
    "                complete_data_dict = {}\n",
    "                complete_data_dict[\"image\"] = join(self.config['vol_data_path'], train_case)\n",
    "                complete_data_dict[\"gt\"] = join(self.config['label_data_path'], train_case)\n",
    "                complete_data_dict[\"bridge_weight_map\"] = join(self.config['bridge_weight_map_path'], train_case)\n",
    "                complete_data_dict[\"pred_seg_logits\"] = join(self.config['pred_seg_logits'], train_case)\n",
    "                data_list.append(complete_data_dict)\n",
    "                print(f\"Validation using case: {train_case}\")\n",
    "                break  # The same training sample for validation in debug mode\n",
    "        else:\n",
    "            for val_case in val_cases:\n",
    "                complete_data_dict = {}\n",
    "                complete_data_dict[\"image\"] = join(self.config['vol_data_path'], val_case)\n",
    "                complete_data_dict[\"gt\"] = join(self.config['label_data_path'], val_case)\n",
    "                complete_data_dict[\"bridge_weight_map\"] = join(self.config['bridge_weight_map_path'], val_case)\n",
    "                complete_data_dict[\"pred_seg_logits\"] = join(self.config['pred_seg_logits'], val_case)\n",
    "                data_list.append(complete_data_dict)\n",
    "\n",
    "        print(f\"Val cases: {len(val_cases)}\")\n",
    "        print(f\"Some examples:\")\n",
    "        print(val_cases[:5])\n",
    "\n",
    "        transforms = Compose(\n",
    "            [   \n",
    "                # Load image \n",
    "                LoadImaged(keys=[\"image\", 'gt', 'bridge_weight_map', 'pred_seg_logits']),\n",
    "                EnsureChannelFirstd(keys=[\"image\", 'gt', 'bridge_weight_map', 'pred_seg_logits']),\n",
    "                # Normalize uint8 input\n",
    "                ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0, b_max=1, clip=True),\n",
    "                # Create a ROI mask for cropping \n",
    "                GetROIMaskdd(keys=[\"gt\"], ignore_mask_value=2, new_key_names=[\"roi_mask\"]),\n",
    "                # Get random patches\n",
    "                ResizeWithPadOrCropd(keys=[\"image\", \"gt\", \"roi_mask\", 'bridge_weight_map', 'pred_seg_logits'], spatial_size=self.config['patch_size'], mode=\"minimum\"),\n",
    "                GetBinaryLabeld(keys=[\"gt\"], ignore_mask_value=2),\n",
    "                EnsureTyped(keys=[\"image\", \"gt\", \"roi_mask\", 'bridge_weight_map', 'pred_seg_logits'], track_meta=False)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"Initializing Dataset...\")\n",
    "        val_ds = CacheDataset(\n",
    "            data=data_list, \n",
    "            transform=transforms, \n",
    "            cache_rate=self.config['val_cache_rate'],  \n",
    "            num_workers=self.config['num_workers'], \n",
    "            progress=True\n",
    "        )\n",
    "        \n",
    "        print(\"Initializing Val DataLoader...\")\n",
    "        val_loader = monai.data.DataLoader(val_ds, batch_size=1, num_workers=self.config['num_workers'])\n",
    "        return val_loader\n",
    "\n",
    "    def _set_optimizers(self):\n",
    "        \"\"\"Define the optimizer (e.g., Adam, SGD).\"\"\"\n",
    "        opt_g = optim.AdamW(self.G_model.parameters(), lr=self.config['learning_rate'])\n",
    "        return opt_g\n",
    "    \n",
    "    def _set_scheduler(self):\n",
    "        \"\"\"Define learning rate scheduler.\"\"\"\n",
    "        # If resuming, last_epoch should be start_epoch - 1\n",
    "        last_epoch = self.config.get('resume_epoch', 0) - 1 if self.config.get('resume') else -1\n",
    "        G_cosAnnealLR = CosineAnnealingLR(self.opt_G, self.config['num_epochs'], eta_min=self.config['learning_rate']/10, last_epoch=last_epoch)\n",
    "        return G_cosAnnealLR\n",
    "    \n",
    "    def saving_logic(self, best_val_value, val_avg_value, epoch):\n",
    "        \"\"\" Logic to save the best model and periodic checkpoints \"\"\"\n",
    "\n",
    "        if best_val_value < val_avg_value: \n",
    "            best_val_value = val_avg_value\n",
    "            G_save_path = join(self.model_save_path, f\"model_best.pth\")\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_weights': self.G_model.state_dict(),  \n",
    "                    'optimizer_state_dict': self.opt_G.state_dict(),\n",
    "                    'val_value': val_avg_value,\n",
    "                }, G_save_path)\n",
    "            print(f\"Saved checkpoint: {G_save_path}\")\n",
    "        \n",
    "        # Save Checkpoint\n",
    "        if epoch % 10 == 0: \n",
    "            G_save_path = join(self.model_save_path, f\"model_epoch_{epoch}.pth\")\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_weights': self.G_model.state_dict(),  \n",
    "                    'optimizer_state_dict': self.opt_G.state_dict(),\n",
    "                    'val_value': val_avg_value,\n",
    "                }, G_save_path)\n",
    "            print(f\"Saved checkpoint: {G_save_path}\")\n",
    "        return best_val_value\n",
    "\n",
    "    def train_epoch(self, **kwargs):\n",
    "        \"\"\"Logic for a single training epoch. Returns average loss.\"\"\"\n",
    "        epoch = kwargs.get('epoch')\n",
    "        \n",
    "        G_epoch_loss = 0\n",
    "\n",
    "        G_per_criterio_loss = {} # voxel wise metrics dict\n",
    "\n",
    "        self.G_model.train()\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch}/{self.config['num_epochs']}\")\n",
    "\n",
    "        for idx, batch_dict in enumerate(pbar):\n",
    "            # batch_dict contains:\n",
    "                # image (volume normalized)\n",
    "                # gt (the real ground truth binary)\n",
    "                # the roi_mask (with the region to ignore 0 and to consider 1)\n",
    "                # weighted map for the bridge weight loss\n",
    "                # segmentation logits (pre-computed to save time!)\n",
    "            input_image = batch_dict['image'].to(self.config['device'])\n",
    "            ground_truth = batch_dict['gt'].to(self.config['device'])\n",
    "            roi_mask = batch_dict['roi_mask'].to(self.config['device'])\n",
    "            bridge_weight_map = batch_dict['bridge_weight_map'].to(self.config['device'])\n",
    "            pred_seg_logits = batch_dict['pred_seg_logits'].to(self.config['device']) # TODO change to pred_seg_logits\n",
    "\n",
    "            self.opt_G.zero_grad()\n",
    "            \n",
    "            with autocast(device_type=self.config['device']):\n",
    "                input_G = torch.cat([input_image, pred_seg_logits], dim=1)\n",
    "                refined_logits = self.G_model(input_G)\n",
    "                refined_probs_for_g = torch.sigmoid(refined_logits) \n",
    "                \n",
    "                # Segmentation Loss (Ground Truth Accuracy)\n",
    "                # Compare refined_logits directly to real_gt_mask\n",
    "                voxel_wise_loss, G_losses_dict = self.G_voxel_criterion([refined_logits], [ground_truth], roi_mask=[roi_mask], bridge_weight_map=bridge_weight_map) \n",
    "                \n",
    "                # loss_seg dominates (weight 100), loss_adv refines\n",
    "                loss_g_total = voxel_wise_loss\n",
    "\n",
    "\n",
    "            # Backward G\n",
    "            self.G_scaler.scale(loss_g_total).backward()\n",
    "            self.G_scaler.step(self.opt_G)\n",
    "            \n",
    "            # Update Scaler once per batch\n",
    "            self.G_scaler.update()\n",
    "            \n",
    "            \n",
    "            ##### Handle loss graphs #####\n",
    "            # Overall loss\n",
    "            G_epoch_loss += loss_g_total.item()\n",
    "            \n",
    "            # adding all individual metrics to the G dict\n",
    "            for G_criterio_name in G_losses_dict.keys():\n",
    "                if G_criterio_name in G_per_criterio_loss:\n",
    "                    G_per_criterio_loss[G_criterio_name] += G_losses_dict[G_criterio_name]\n",
    "                else:\n",
    "                    G_per_criterio_loss[G_criterio_name] = G_losses_dict[G_criterio_name]\n",
    "            \n",
    "            # Update status bar\n",
    "            pbar.set_postfix({\n",
    "                \"G_Loss\": loss_g_total.item()\n",
    "            })\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            # Save a prediction\n",
    "            self.save_vol(refined_probs_for_g, join(self.preds_path, f\"epoch_{epoch}_pred_train.nii.gz\"))\n",
    "            self.save_vol(input_image, join(self.preds_path, f\"epoch_{epoch}_input_train.nii.gz\"))\n",
    "            self.save_vol(pred_seg_logits, join(self.preds_path, f\"epoch_{epoch}_input_pred_seg_logits_train.nii.gz\"))\n",
    "            self.save_vol(ground_truth, join(self.preds_path, f\"epoch_{epoch}_gt_train.nii.gz\"))\n",
    "\n",
    "        \n",
    "        G_train_avg_loss = G_epoch_loss / len(self.train_loader)\n",
    "        print(f\"Epoch {epoch} Finished. Avg Loss: {G_train_avg_loss:.6f}\")\n",
    "        \n",
    "        # This will replace each element in the dict with the mean\n",
    "        for criterio_name in G_losses_dict.keys():\n",
    "            G_per_criterio_loss[criterio_name] = G_per_criterio_loss[criterio_name] / len(self.train_loader)\n",
    "\n",
    "        return G_train_avg_loss, G_per_criterio_loss\n",
    "    \n",
    "    def val(self, **kwargs):\n",
    "        \"\"\"Logic for evaluation. Returns a dictionary of metrics.\"\"\"\n",
    "        epoch = kwargs.get('epoch')\n",
    "        self.G_model.eval()\n",
    "        \n",
    "        # General DSC validation value for quality controll\n",
    "        val_value_sum = 0\n",
    "        epoch_val_pixel_loss = 0\n",
    "        adv_fake = 0\n",
    "        adv_real = 0\n",
    "        # Add the per criterio val loss for checking overfitting\n",
    "        per_criterio_val_loss = {}\n",
    "        for val_criterio_name in self.config['criterion']:\n",
    "            per_criterio_val_loss[f\"val_{val_criterio_name}\"] = 0\n",
    "\n",
    "        pbar = tqdm(self.val_loader, desc=f\"Val epoch {epoch}/{self.config['num_epochs']}\")\n",
    "        for idx, batch_dict in enumerate(pbar):\n",
    "            input_image = batch_dict['image'].to(self.config['device'])\n",
    "            ground_truth = batch_dict['gt'].to(self.config['device']) \n",
    "            # Create the mask of the region to compute the loss\n",
    "            roi_mask = batch_dict['roi_mask'].to(self.config['device'])\n",
    "            bridge_weight_map = batch_dict['bridge_weight_map'].to(self.config['device'])\n",
    "            pred_seg_logits = batch_dict['pred_seg_logits'].to(self.config['device'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                input_G = torch.cat([input_image, pred_seg_logits], dim=1)\n",
    "                refined_logits = self.G_model(input_G)\n",
    "                # Calculate DSC (Compare Prediction vs. GT)\n",
    "                val_value = self.val_metric(pred=refined_logits, target=ground_truth, roi_mask=roi_mask)\n",
    "                # Also compute val losses for logging (no deep supervision here)\n",
    "                val_loss, val_losses_dict = self.G_voxel_criterion([refined_logits], [ground_truth], roi_mask=[roi_mask], bridge_weight_map=bridge_weight_map, deep_supervision_weights=[1.0]) \n",
    "                # commented to avoid overwhelming \n",
    "                #self.wandb_run.log({\"val_value\": val_value.item()})\n",
    "\n",
    "            val_value_sum += val_value # val metric (DSC)\n",
    "            epoch_val_pixel_loss += val_loss.item() # all losses function used for training (except Adv)\n",
    "            for val_criterio_name in val_losses_dict.keys():\n",
    "                per_criterio_val_loss[f\"val_{val_criterio_name}\"] += val_losses_dict[f\"{val_criterio_name}\"]\n",
    "            pbar.set_postfix({\"DSC\": val_value})\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            pred_save = sigmoid(refined_logits)\n",
    "            pred_save[pred_save>0.5] = 1.0\n",
    "            pred_save[pred_save<=0.5] = 0.0\n",
    "            self.save_vol(refined_logits, join(self.preds_path, f\"epoch_{epoch}_logits_val.nii.gz\"))\n",
    "            self.save_vol(pred_save, join(self.preds_path, f\"epoch_{epoch}_pred_val.nii.gz\"))\n",
    "            self.save_vol(input_image, join(self.preds_path, f\"epoch_{epoch}_input_val.nii.gz\"))\n",
    "            self.save_vol(pred_seg_logits, join(self.preds_path, f\"epoch_{epoch}_input_pred_seg_logits_val.nii.gz\"))\n",
    "            self.save_vol(ground_truth, join(self.preds_path, f\"epoch_{epoch}_gt_val.nii.gz\"))\n",
    "\n",
    "        # computing mean of metrics\n",
    "        val_avg_value = val_value_sum / len(self.val_loader)\n",
    "        val_avg_pixel_loss = epoch_val_pixel_loss / len(self.val_loader)\n",
    "\n",
    "        for val_criterio_name in val_losses_dict.keys():\n",
    "            per_criterio_val_loss[f\"val_{val_criterio_name}\"] = per_criterio_val_loss[f\"val_{val_criterio_name}\"] / len(self.val_loader)\n",
    "        print(f\"Epoch {epoch} with validation avg DSC: {val_avg_value:.6f} | avg Loss: {val_avg_pixel_loss:.6f}\")\n",
    "        return val_avg_value, val_avg_pixel_loss, per_criterio_val_loss \n",
    "    \n",
    "    def train_loop(self, **kwargs):\n",
    "        \"\"\"Standardized training loop.\"\"\"\n",
    "        best_val_value = self.val_value\n",
    "        \n",
    "        # Make sure all weights are trainable\n",
    "        for param in self.G_model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for self.epoch in range(self.start_epoch, self.config['num_epochs'] + 1):\n",
    "            # Train one epoch\n",
    "            G_train_avg_loss, G_per_criterio_loss = self.train_epoch(\n",
    "                epoch=self.epoch\n",
    "            )\n",
    "            # Perform evaluation \n",
    "            val_avg_value, val_avg_pixel_loss, per_criterio_val_loss  = self.val(\n",
    "                epoch=self.epoch\n",
    "            )\n",
    "\n",
    "            # Save in wandb\n",
    "            log_train_data = {\n",
    "                    \"epoch_train\": self.epoch,\n",
    "                    \"train_avg_loss\": G_train_avg_loss,\n",
    "                    \"val_Dice\": val_avg_value,\n",
    "                    \"val_avg_pixel_loss\": val_avg_pixel_loss,\n",
    "                    \"G_lr\": self.opt_G.param_groups[0]['lr'],\n",
    "                    \"D_lr\": self.opt_D.param_groups[0]['lr']  \n",
    "                }\n",
    "\n",
    "            for criterio_name in G_per_criterio_loss.keys():\n",
    "                log_train_data[criterio_name] = G_per_criterio_loss[criterio_name]\n",
    "                if criterio_name.endswith(\"_fullres\"):\n",
    "                    print(f\"_fullres is still in the loss function! It should not!\")\n",
    "\n",
    "\n",
    "            for val_criterio_name in per_criterio_val_loss.keys():\n",
    "                log_train_data[val_criterio_name] = per_criterio_val_loss[val_criterio_name]\n",
    "\n",
    "            self.wandb_run.log(\n",
    "                log_train_data\n",
    "            )\n",
    "\n",
    "            # Checking if saving \n",
    "            best_val_value = self.saving_logic(\n",
    "                best_val_value=best_val_value, \n",
    "                val_avg_value=val_avg_value, \n",
    "                epoch=self.epoch\n",
    "            )\n",
    "\n",
    "            # Applying learning rate Cosine Annealing\n",
    "            self.G_cosAnnealLR.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = '../configs/post_process_GANs.json'\n",
    "with open(CONFIG_FILE, \"r\") as f:\n",
    "    config_content = json.load(f)\n",
    "GANs_train_object = postprocessGANs(config_content)\n",
    "GANs_train_object.train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check if the D_loss is within the value expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
