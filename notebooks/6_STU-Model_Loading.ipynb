{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc98182",
   "metadata": {},
   "source": [
    "# Taking the pre-trained model from STU-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7777c4",
   "metadata": {},
   "source": [
    "### Load the model using the nnUNetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8135fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nnunet\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_pickle, join\n",
    "import pkgutil\n",
    "import importlib\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# --- Helper to find the class ---\n",
    "def recursive_find_python_class(folder, trainer_name, current_module):\n",
    "    tr = None\n",
    "    for importer, modname, ispkg in pkgutil.iter_modules(folder):\n",
    "        if not ispkg:\n",
    "            m = importlib.import_module(current_module + \".\" + modname)\n",
    "            if hasattr(m, trainer_name):\n",
    "                tr = getattr(m, trainer_name)\n",
    "                break\n",
    "    if tr is None:\n",
    "        for importer, modname, ispkg in pkgutil.iter_modules(folder):\n",
    "            if ispkg:\n",
    "                next_current_module = current_module + \".\" + modname\n",
    "                tr = recursive_find_python_class([join(folder[0], modname)], trainer_name, current_module=next_current_module)\n",
    "            if tr is not None:\n",
    "                break\n",
    "    return tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3cb7f",
   "metadata": {},
   "source": [
    "### Test with one inference -> Loading pre-trained STU-Net Large and doing inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924877c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model_reconstruction(pkl_file, checkpoint=None, train=False, fp16=None):\n",
    "    # Load Configuration\n",
    "    info = load_pickle(pkl_file)\n",
    "    init = info['init']\n",
    "    name = info['name']\n",
    "    print(info)\n",
    "    # Instantiate Trainer\n",
    "    search_in = join(nnunet.__path__[0], \"training\", \"network_training\")\n",
    "    tr = recursive_find_python_class([search_in], name, current_module=\"nnunet.training.network_training\")\n",
    "    \n",
    "    # Fallback for meddec\n",
    "    if tr is None:\n",
    "        try:\n",
    "            import meddec\n",
    "            search_in = join(meddec.__path__[0], \"model_training\")\n",
    "            tr = recursive_find_python_class([search_in], name, current_module=\"meddec.model_training\")\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "    if tr is None: raise RuntimeError(f\"Could not find trainer: {name}\")\n",
    "\n",
    "    trainer = tr(*init)\n",
    "    if fp16 is not None: trainer.fp16 = fp16\n",
    "\n",
    "    # Initialize Network (This creates the standard 5-head, 2-channel model)\n",
    "    trainer.process_plans(info['plans'])\n",
    "    trainer.initialize_network()\n",
    "    \n",
    "    # --- SURGERY STEP 1: MODIFY ARCHITECTURE ---\n",
    "    print(\"\\n--- Starting Architecture Surgery ---\")\n",
    "    \n",
    "    # The network is now built. We need to find the High-Res output head.\n",
    "    # In STUNet/nnU-Net, seg_outputs is a list. \n",
    "    # Index 0 = Deepest (Lowest Res). Index -1 (or 4) = Highest Res.\n",
    "    \n",
    "    # A. Disable Deep Supervision flag in the network module\n",
    "    # This prevents the forward pass from trying to return multiple outputs\n",
    "    if hasattr(trainer.network, 'deep_supervision'):\n",
    "        trainer.network.deep_supervision = False\n",
    "    if hasattr(trainer.network, 'do_ds'):\n",
    "        trainer.network.do_ds = False\n",
    "    \n",
    "    # B. Replace the Final Output Layer with 1-Channel Conv3d\n",
    "    # We grab the last layer (highest resolution)\n",
    "    old_final_layer = trainer.network.seg_outputs[-1] \n",
    "    \n",
    "    print(f\"Replacing final layer: {old_final_layer}\")\n",
    "    print(f\"Old config: In={old_final_layer.in_channels}, Out={old_final_layer.out_channels}\")\n",
    "    \n",
    "    # Create new 1-channel layer\n",
    "    new_final_layer = nn.Conv3d(\n",
    "        in_channels=old_final_layer.in_channels,\n",
    "        out_channels=105,\n",
    "        kernel_size=old_final_layer.kernel_size,\n",
    "        stride=old_final_layer.stride,\n",
    "        padding=old_final_layer.padding,\n",
    "        bias=(old_final_layer.bias is not None)\n",
    "    )\n",
    "    \n",
    "    # Replace it in the module list. \n",
    "    # We perform a hard replacement so only this layer remains or is valid.\n",
    "    # To be safe against list indexing errors in forward(), we replace ALL with Identity, \n",
    "    # and put the real one at the end.\n",
    "    \n",
    "    new_seg_outputs = nn.ModuleList()\n",
    "    \n",
    "    # Fill 0 to N-1 with Dummy Identity (to keep indices valid if code relies on them)\n",
    "    for i in range(len(trainer.network.seg_outputs) - 1):\n",
    "        new_seg_outputs.append(nn.Identity())\n",
    "        \n",
    "    # Append our new 1-channel real layer at the end\n",
    "    new_seg_outputs.append(new_final_layer)\n",
    "    \n",
    "    # Assign back to network\n",
    "    trainer.network.seg_outputs = new_seg_outputs\n",
    "    print(f\"Architecture Modified. Output hea5_Download_tif_files.ipynbds: {len(trainer.network.seg_outputs)} (Last one is active 1-channel).\")\n",
    "\n",
    "\n",
    "    # --- SURGERY STEP 2: LOAD & PATCH WEIGHTS ---\n",
    "    if checkpoint is not None:\n",
    "        print(f\"\\n--- Loading and Patching Weights from {checkpoint} ---\")\n",
    "        \n",
    "        # Load with weights_only=False to allow numpy scalars\n",
    "        saved_state_dict = torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict']\n",
    "        network_state_dict = trainer.network.state_dict()\n",
    "        \n",
    "        final_state_dict = {}\n",
    "        \n",
    "        # Find index of the last layer in the NEW network\n",
    "        last_idx = len(trainer.network.seg_outputs) - 1\n",
    "        new_layer_prefix = f\"seg_outputs.{last_idx}\"\n",
    "        \n",
    "        for key_new, param_new in network_state_dict.items():\n",
    "            \n",
    "            # 1. Handle the Output Head\n",
    "            if new_layer_prefix in key_new:\n",
    "                # We assume the old checkpoint had the high-res head at index '4'\n",
    "                # (You verified this in logs: seg_outputs.4 had 64 input features)\n",
    "                key_old = key_new.replace(f\"seg_outputs.{last_idx}\", \"seg_outputs.4\")\n",
    "                \n",
    "                if key_old in saved_state_dict:\n",
    "                    param_old = saved_state_dict[key_old]\n",
    "                    \n",
    "                    if \"weight\" in key_new:\n",
    "                        patched_param = param_old[:, ...] # Slice first dim\n",
    "                    else: # bias\n",
    "                        patched_param = param_old[:]\n",
    "                        \n",
    "                    final_state_dict[key_new] = patched_param\n",
    "                    print(f\"  PATCHED {key_new}: Sliced {key_old} {param_old.shape} -> {patched_param.shape}\")\n",
    "                else:\n",
    "                    print(f\"  WARNING: Could not find {key_old} in checkpoint!\")\n",
    "\n",
    "            # 2. Handle Dummy/Identity Layers (Skip loading)\n",
    "            elif \"seg_outputs\" in key_new:\n",
    "                # These are the Identity layers we added. They have no weights.\n",
    "                # If they appear in state_dict (rare for Identity), ignore or init default.\n",
    "                pass\n",
    "\n",
    "            # 3. Handle Standard Layers (Encoder/Decoder)\n",
    "            elif key_new in saved_state_dict:\n",
    "                # Direct Copy\n",
    "                if saved_state_dict[key_new].shape == param_new.shape:\n",
    "                    final_state_dict[key_new] = saved_state_dict[key_new]\n",
    "                else:\n",
    "                    print(f\"  Skipping {key_new}: Shape mismatch {saved_state_dict[key_new].shape} vs {param_new.shape}\")\n",
    "            else:\n",
    "                pass # Missing key\n",
    "\n",
    "        # Load weights (Strict=False is ESSENTIAL because we messed with the architecture)\n",
    "        load_result = trainer.network.load_state_dict(final_state_dict, strict=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"WEIGHT LOADING REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Missing Keys (Layers initialized randomly because no weights were found)\n",
    "    # We expect the \"Identity\" layers to be here (since they have no weights, this list might be empty or contain irrelevant names depending on implementation)\n",
    "    # But mostly we care if 'seg_outputs.4' is MISSING (bad) or present.\n",
    "    if len(load_result.missing_keys) > 0:\n",
    "        print(f\"âš ï¸  MISSING KEYS ({len(load_result.missing_keys)}):\")\n",
    "        for k in load_result.missing_keys:\n",
    "            print(f\"   - {k}\")\n",
    "    else:\n",
    "        print(\"âœ… No missing keys (All target layers received weights).\")\n",
    "\n",
    "    # 2. Unexpected Keys (Weights in the checkpoint that we threw away)\n",
    "    # We EXPECT to see seg_outputs.0, .1, .2, .3 here because we deleted those layers from the architecture.\n",
    "    # We also expect to see the unused channels of seg_outputs.4 here (though PyTorch won't list unused channels, just unused full keys).\n",
    "    \n",
    "    # To see what we skipped from the FILE, we compare the file's keys to the loaded dict\n",
    "    skipped_keys = [k for k in saved_state_dict.keys() if k not in final_state_dict]\n",
    "    \n",
    "    if len(skipped_keys) > 0:\n",
    "        print(f\"\\nðŸ—‘ï¸  SKIPPED LAYERS ({len(skipped_keys)}):\")\n",
    "        print(\"   (These were present in the checkpoint but removed/ignored in the new model)\")\n",
    "        # Print first 10 just to verify\n",
    "        for k in skipped_keys[:10]:\n",
    "            print(f\"   - {k}\")\n",
    "        if len(skipped_keys) > 10:\n",
    "            print(f\"   ... and {len(skipped_keys)-10} more.\")\n",
    "\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2896c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to load it latter\n",
    "PLANS_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model.pkl\"\n",
    "MODEL_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model\"\n",
    "\n",
    "trainer = restore_model_reconstruction(PLANS_PATH, MODEL_PATH, train=False)\n",
    "model = trainer.network\n",
    "\n",
    "# Verify\n",
    "print(\"\\nFinal Check:\")\n",
    "print(f\"Output Head: {model.seg_outputs[-1]}\")\n",
    "# Should print: Conv3d(64, 1, kernel_size=(1, 1, 1), ...)\n",
    "# Save the state dictionary of your modified model\n",
    "torch.save(model.state_dict(), \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/tmp/stunet_reconstruction_weights.pth\")\n",
    "print(\"âœ… Weights saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stunet_model import STUNetReconstruction\n",
    "import torch\n",
    "\n",
    "# Load the model with our Network\n",
    "# Initialize the independent model\n",
    "model = STUNetReconstruction()\n",
    "\n",
    "# Load the weights you saved\n",
    "#    'strict=True' should work perfectly now because the class matches the patched architecture exactly.\n",
    "state_dict = torch.load(\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/tmp/stunet_reconstruction_weights.pth\", map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Ready for training\n",
    "model.eval()\n",
    "model.cuda()\n",
    "print(\"Model loaded successfully without nnU-Net dependencies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def pad_and_center_crop_3d(tensor, crop_size=(128,128,128)):\n",
    "    _, _, D, H, W = tensor.shape\n",
    "    d_crop, h_crop, w_crop = crop_size\n",
    "    \n",
    "    # Compute padding\n",
    "    pad_d = max(d_crop - D, 0)\n",
    "    pad_h = max(h_crop - H, 0)\n",
    "    pad_w = max(w_crop - W, 0)\n",
    "    \n",
    "    # Pad (pad=(w_left, w_right, h_left, h_right, d_left, d_right))\n",
    "    tensor = F.pad(tensor, (\n",
    "        pad_w//2, pad_w - pad_w//2,\n",
    "        pad_h//2, pad_h - pad_h//2,\n",
    "        pad_d//2, pad_d - pad_d//2\n",
    "    ), mode='constant', value=-1000)\n",
    "    \n",
    "    # Now do center crop\n",
    "    _, _, D, H, W = tensor.shape\n",
    "    d_start = (D - d_crop) // 2\n",
    "    h_start = (H - h_crop) // 2\n",
    "    w_start = (W - w_crop) // 2\n",
    "    \n",
    "    cropped = tensor[:, :, d_start:d_start+d_crop,\n",
    "                           h_start:h_start+h_crop,\n",
    "                           w_start:w_start+w_crop]\n",
    "    return cropped\n",
    "\n",
    "def z_score_normalize(tensor, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization to a 3D tensor.\n",
    "    Args:\n",
    "        tensor: torch.Tensor, shape [1, 1, D, H, W]\n",
    "        eps: small constant to avoid division by zero\n",
    "    Returns:\n",
    "        normalized tensor\n",
    "    \"\"\"\n",
    "    mean = tensor.mean()\n",
    "    std = tensor.std()\n",
    "    normalized = (tensor - mean) / (std + eps)\n",
    "    return normalized\n",
    "\n",
    "def save_tensor_as_nii(tensor, output_path, reference_image=None):\n",
    "    \"\"\"\n",
    "    Save a 3D PyTorch tensor as a .nii.gz file.\n",
    "    \n",
    "    tensor: torch.Tensor, shape [1,1,D,H,W] or [D,H,W]\n",
    "    reference_image: sitk.Image to copy spacing, origin, direction\n",
    "    \"\"\"\n",
    "    # Handle tuple\n",
    "    if isinstance(tensor, tuple):\n",
    "        tensor = tensor[0]\n",
    "    print(f\"tensor: {tensor.shape}\")\n",
    "    # Move to CPU\n",
    "    if tensor.is_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    tensor = tensor.detach().numpy()\n",
    "    \n",
    "    # Remove batch & channel dimensions\n",
    "    while tensor.ndim > 3:\n",
    "        tensor = tensor[0]\n",
    "    \n",
    "    # Convert to SimpleITK image\n",
    "    sitk_image = sitk.GetImageFromArray(tensor)\n",
    "    \n",
    "    # Copy metadata if provided\n",
    "    if reference_image is not None:\n",
    "        # Only copy 3D metadata\n",
    "        sitk_image.SetSpacing(reference_image.GetSpacing())\n",
    "        sitk_image.SetOrigin(reference_image.GetOrigin())\n",
    "        sitk_image.SetDirection(reference_image.GetDirection())\n",
    "    \n",
    "    # Save\n",
    "    sitk.WriteImage(sitk_image, output_path)\n",
    "    print(f\"Saved output to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59711d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do one inferenc (check if the results are good, the scan should be a CT scan)\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "nii = nib.load(\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/ct.nii\")\n",
    "image_array = nii.get_fdata().astype(np.float32)\n",
    "image_array = np.transpose(image_array, (2, 1, 0))\n",
    "\n",
    "image_tensor = torch.from_numpy(image_array).unsqueeze(0).unsqueeze(0).cuda()\n",
    "\n",
    "print(f\"image_tensor: {image_tensor.shape}\")\n",
    "\n",
    "\n",
    "# cropped: shape [1, 1, 128, 128, 128]\n",
    "\n",
    "cropped = pad_and_center_crop_3d(image_tensor, crop_size=(128,128,128))\n",
    "cropped = z_score_normalize(cropped)\n",
    "print(cropped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "output = model(cropped)\n",
    "print(f\"output: {output.shape}\")\n",
    "save_tensor_as_nii(tensor=cropped[0][0], output_path=\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/cropped.nii.gz\", reference_image=None)\n",
    "print(torch.argmax(output, dim=1).shape)\n",
    "save_tensor_as_nii(torch.argmax(output, dim=1)[0].to(torch.uint8) , \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/output.nii.gz\", reference_image=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFYING IF THE MODEL LOADED BY THE NNUNET AND LOAD BY OUR NETWORK IS SIMILAR. MAX DIFF SHOULD BE 0.0\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP: LOAD BOTH MODELS\n",
    "# ==========================================\n",
    "\n",
    "# A. Load Reference Model (The one that works via nnunet logic)\n",
    "#    Use the restore function that uses the original nnunet code\n",
    "PLANS = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model.pkl\"\n",
    "CKPT = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model\"\n",
    "\n",
    "print(\"Loading Reference Model...\")\n",
    "# Ensure you have your 'restore_model_reconstruction' function available here\n",
    "ref_trainer = restore_model_reconstruction(PLANS, CKPT, train=False, fp16=True)\n",
    "model_ref = ref_trainer.network\n",
    "model_ref.eval().cuda()\n",
    "\n",
    "# B. Load Your Standalone Model\n",
    "print(\"Loading Standalone Model...\")\n",
    "from stunet_model import STUNetReconstruction\n",
    "model_new = STUNetReconstruction()\n",
    "model_new.load_state_dict(torch.load(\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/tmp/stunet_reconstruction_weights.pth\"), strict=True)\n",
    "model_new.eval().cuda()\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEBUGGING TOOL: HOOKS\n",
    "# ==========================================\n",
    "# We attach hooks to capture the output of every block\n",
    "\n",
    "activations_ref = {}\n",
    "activations_new = {}\n",
    "\n",
    "def get_hook(name, storage_dict):\n",
    "    def hook(model, input, output):\n",
    "        # Detach and move to CPU to save memory\n",
    "        storage_dict[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "# List of layers to check (Encoder blocks + Decoder blocks)\n",
    "layer_names = [\n",
    "    # Encoder\n",
    "    \"conv_blocks_context.0\", \n",
    "    \"conv_blocks_context.1\", \n",
    "    \"conv_blocks_context.2\", \n",
    "    \"conv_blocks_context.3\", \n",
    "    \"conv_blocks_context.4\", \n",
    "    \"conv_blocks_context.5\", # Bottleneck\n",
    "    \n",
    "    # Decoder (Upsampling)\n",
    "    \"upsample_layers.0\",\n",
    "    \"upsample_layers.1\",\n",
    "    \n",
    "    # Decoder (Localization)\n",
    "    \"conv_blocks_localization.0\",\n",
    "    \"conv_blocks_localization.1\",\n",
    "]\n",
    "\n",
    "# Attach hooks\n",
    "for name in layer_names:\n",
    "    # Use recursive getattr to find the layer\n",
    "    # Ref Model\n",
    "    layer_ref = dict(model_ref.named_modules())[name]\n",
    "    layer_ref.register_forward_hook(get_hook(name, activations_ref))\n",
    "    \n",
    "    # New Model\n",
    "    layer_new = dict(model_new.named_modules())[name]\n",
    "    layer_new.register_forward_hook(get_hook(name, activations_new))\n",
    "\n",
    "# ==========================================\n",
    "# 3. RUN COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n--- Running Comparison ---\")\n",
    "with torch.no_grad():\n",
    "    # Create a random input\n",
    "    dummy_input = torch.randn(1, 1, 128, 128, 128).cuda()\n",
    "    \n",
    "    # Forward passes\n",
    "    _ = model_ref(dummy_input)\n",
    "    _ = model_new(dummy_input)\n",
    "\n",
    "# Check errors\n",
    "for name in layer_names:\n",
    "    act_ref = activations_ref[name]\n",
    "    act_new = activations_new[name]\n",
    "    \n",
    "    # 1. Check Shape\n",
    "    if act_ref.shape != act_new.shape:\n",
    "        print(f\"âŒ SHAPE MISMATCH at {name}!\")\n",
    "        print(f\"   Ref: {act_ref.shape}\")\n",
    "        print(f\"   New: {act_new.shape}\")\n",
    "        print(\"   -> Check your strides or kernel sizes in this block.\")\n",
    "        break\n",
    "    \n",
    "    # 2. Check Values\n",
    "    diff = torch.abs(act_ref - act_new).max().item()\n",
    "    print(f\"Layer {name:<30} | Max Diff: {diff:.8f}\")\n",
    "    \n",
    "    if diff > 1e-4: # Tolerance threshold\n",
    "        print(f\"âŒ VALUE MISMATCH at {name}!\")\n",
    "        print(\"   -> The weights match, but the calculation is different.\")\n",
    "        print(\"   -> Possible causes: InstanceNorm settings (eps/momentum), LeakyReLU slope, or interpolation method.\")\n",
    "        break\n",
    "\n",
    "print(\"--- Done ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c6310",
   "metadata": {},
   "source": [
    "### All seems good. Save the model independently to load alone with PyTorch only -> Ignore nnUNet v1\n",
    "* For this, we:\n",
    "    * Save the model with replaced output layer (outputs 1 channel)\n",
    "    * Defined the model network without the nnunet framework, in the stunet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model_reconstruction(pkl_file, checkpoint=None, train=False, fp16=None):\n",
    "    # 1. Load Configuration\n",
    "    info = load_pickle(pkl_file)\n",
    "    init = info['init']\n",
    "    name = info['name']\n",
    "    \n",
    "    # 2. Force Plans to 1 Class (This gets us close, usually 2 channels)\n",
    "    info['plans']['num_classes'] = 1\n",
    "    info['plans']['all_classes'] = [1]\n",
    "\n",
    "    # 3. Instantiate Trainer\n",
    "    search_in = join(nnunet.__path__[0], \"training\", \"network_training\")\n",
    "    tr = recursive_find_python_class([search_in], name, current_module=\"nnunet.training.network_training\")\n",
    "    \n",
    "    # Fallback for meddec\n",
    "    if tr is None:\n",
    "        try:\n",
    "            import meddec\n",
    "            search_in = join(meddec.__path__[0], \"model_training\")\n",
    "            tr = recursive_find_python_class([search_in], name, current_module=\"meddec.model_training\")\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "    if tr is None: raise RuntimeError(f\"Could not find trainer: {name}\")\n",
    "\n",
    "    trainer = tr(*init)\n",
    "    if fp16 is not None: trainer.fp16 = fp16\n",
    "\n",
    "    # 4. Initialize Network (This creates the standard 5-head, 2-channel model)\n",
    "    trainer.process_plans(info['plans'])\n",
    "    trainer.initialize_network()\n",
    "    \n",
    "    # --- SURGERY STEP 1: MODIFY ARCHITECTURE ---\n",
    "    print(\"\\n--- Starting Architecture Surgery ---\")\n",
    "    \n",
    "    # The network is now built. We need to find the High-Res output head.\n",
    "    # In STUNet/nnU-Net, seg_outputs is a list. \n",
    "    # Index 0 = Deepest (Lowest Res). Index -1 (or 4) = Highest Res.\n",
    "    \n",
    "    # A. Disable Deep Supervision flag in the network module\n",
    "    # This prevents the forward pass from trying to return multiple outputs\n",
    "    if hasattr(trainer.network, 'deep_supervision'):\n",
    "        trainer.network.deep_supervision = False\n",
    "    if hasattr(trainer.network, 'do_ds'):\n",
    "        trainer.network.do_ds = False\n",
    "    \n",
    "    # B. Replace the Final Output Layer with 1-Channel Conv3d\n",
    "    # We grab the last layer (highest resolution)\n",
    "    old_final_layer = trainer.network.seg_outputs[-1] \n",
    "    \n",
    "    print(f\"Replacing final layer: {old_final_layer}\")\n",
    "    print(f\"Old config: In={old_final_layer.in_channels}, Out={old_final_layer.out_channels}\")\n",
    "    \n",
    "    # Create new 1-channel layer\n",
    "    new_final_layer = nn.Conv3d(\n",
    "        in_channels=old_final_layer.in_channels,\n",
    "        out_channels=1, # <--- FORCING 1 CHANNEL HERE\n",
    "        kernel_size=old_final_layer.kernel_size,\n",
    "        stride=old_final_layer.stride,\n",
    "        padding=old_final_layer.padding,\n",
    "        bias=(old_final_layer.bias is not None)\n",
    "    )\n",
    "    \n",
    "    # Replace it in the module list. \n",
    "    # We perform a hard replacement so only this layer remains or is valid.\n",
    "    # To be safe against list indexing errors in forward(), we replace ALL with Identity, \n",
    "    # and put the real one at the end.\n",
    "    new_seg_outputs = nn.ModuleList()\n",
    "    \n",
    "    # Fill 0 to N-1 with Dummy Identity (to keep indices valid if code relies on them)\n",
    "    for i in range(len(trainer.network.seg_outputs) - 1):\n",
    "        new_seg_outputs.append(nn.Identity())\n",
    "        \n",
    "    # Append our new 1-channel real layer at the end\n",
    "    new_seg_outputs.append(new_final_layer)\n",
    "    \n",
    "    # Assign back to network\n",
    "    trainer.network.seg_outputs = new_seg_outputs\n",
    "    print(f\"Architecture Modified. Output heads: {len(trainer.network.seg_outputs)} (Last one is active 1-channel).\")\n",
    "\n",
    "\n",
    "    # --- SURGERY STEP 2: LOAD & PATCH WEIGHTS ---\n",
    "    if checkpoint is not None:\n",
    "        print(f\"\\n--- Loading and Patching Weights from {checkpoint} ---\")\n",
    "        \n",
    "        # Load with weights_only=False to allow numpy scalars\n",
    "        saved_state_dict = torch.load(checkpoint, map_location=torch.device('cpu'), weights_only=False)['state_dict']\n",
    "        network_state_dict = trainer.network.state_dict()\n",
    "        \n",
    "        final_state_dict = {}\n",
    "        \n",
    "        # We need to map the Old High-Res Head (index 4) to our New High-Res Head (index 4)\n",
    "        # And slice channels from 104 -> 1\n",
    "        \n",
    "        # Find index of the last layer in the NEW network\n",
    "        last_idx = len(trainer.network.seg_outputs) - 1\n",
    "        new_layer_prefix = f\"seg_outputs.{last_idx}\"\n",
    "        \n",
    "        for key_new, param_new in network_state_dict.items():\n",
    "            \n",
    "            # 1. Handle the Output Head\n",
    "            if new_layer_prefix in key_new:\n",
    "                # We assume the old checkpoint had the high-res head at index '4'\n",
    "                # (You verified this in logs: seg_outputs.4 had 64 input features)\n",
    "                key_old = key_new.replace(f\"seg_outputs.{last_idx}\", \"seg_outputs.4\")\n",
    "                \n",
    "                if key_old in saved_state_dict:\n",
    "                    param_old = saved_state_dict[key_old]\n",
    "                    \n",
    "                    if \"weight\" in key_new:\n",
    "                        patched_param = param_old[:1, ...] # Slice first dim\n",
    "                    else: # bias\n",
    "                        patched_param = param_old[:1]\n",
    "                        \n",
    "                    final_state_dict[key_new] = patched_param\n",
    "                    print(f\"  PATCHED {key_new}: Sliced {key_old} {param_old.shape} -> {patched_param.shape}\")\n",
    "                else:\n",
    "                    print(f\"  WARNING: Could not find {key_old} in checkpoint!\")\n",
    "\n",
    "            # 2. Handle Dummy/Identity Layers (Skip loading)\n",
    "            elif \"seg_outputs\" in key_new:\n",
    "                # These are the Identity layers we added. They have no weights.\n",
    "                # If they appear in state_dict (rare for Identity), ignore or init default.\n",
    "                pass\n",
    "\n",
    "            # 3. Handle Standard Layers (Encoder/Decoder)\n",
    "            elif key_new in saved_state_dict:\n",
    "                # Direct Copy\n",
    "                if saved_state_dict[key_new].shape == param_new.shape:\n",
    "                    final_state_dict[key_new] = saved_state_dict[key_new]\n",
    "                else:\n",
    "                    print(f\"  Skipping {key_new}: Shape mismatch {saved_state_dict[key_new].shape} vs {param_new.shape}\")\n",
    "            else:\n",
    "                pass # Missing key\n",
    "\n",
    "        # Load weights (Strict=False is ESSENTIAL because we messed with the architecture)\n",
    "        load_result = trainer.network.load_state_dict(final_state_dict, strict=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"WEIGHT LOADING REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Missing Keys (Layers initialized randomly because no weights were found)\n",
    "    # We expect the \"Identity\" layers to be here (since they have no weights, this list might be empty or contain irrelevant names depending on implementation)\n",
    "    # But mostly we care if 'seg_outputs.4' is MISSING (bad) or present.\n",
    "    if len(load_result.missing_keys) > 0:\n",
    "        print(f\"âš ï¸  MISSING KEYS ({len(load_result.missing_keys)}):\")\n",
    "        for k in load_result.missing_keys:\n",
    "            print(f\"   - {k}\")\n",
    "    else:\n",
    "        print(\"âœ… No missing keys (All target layers received weights).\")\n",
    "\n",
    "    # 2. Unexpected Keys (Weights in the checkpoint that we threw away)\n",
    "    # We EXPECT to see seg_outputs.0, .1, .2, .3 here because we deleted those layers from the architecture.\n",
    "    # We also expect to see the unused channels of seg_outputs.4 here (though PyTorch won't list unused channels, just unused full keys).\n",
    "    \n",
    "    # To see what we skipped from the FILE, we compare the file's keys to the loaded dict\n",
    "    skipped_keys = [k for k in saved_state_dict.keys() if k not in final_state_dict]\n",
    "    \n",
    "    if len(skipped_keys) > 0:\n",
    "        print(f\"\\nðŸ—‘ï¸  SKIPPED LAYERS ({len(skipped_keys)}):\")\n",
    "        print(\"   (These were present in the checkpoint but removed/ignored in the new model)\")\n",
    "        # Print first 10 just to verify\n",
    "        for k in skipped_keys[:10]:\n",
    "            print(f\"   - {k}\")\n",
    "        if len(skipped_keys) > 10:\n",
    "            print(f\"   ... and {len(skipped_keys)-10} more.\")\n",
    "\n",
    "    return trainer\n",
    "\n",
    "# --- EXECUTE ---\n",
    "PLANS_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model.pkl\"\n",
    "MODEL_PATH = \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/large_ep4k.model\"\n",
    "\n",
    "trainer = restore_model_reconstruction(PLANS_PATH, MODEL_PATH, train=False)\n",
    "model = trainer.network\n",
    "\n",
    "# save model and network\n",
    "from stunet_model import STUNetReconstruction\n",
    "import torch\n",
    "\n",
    "# Verify\n",
    "print(\"\\nFinal Check:\")\n",
    "print(f\"Output Head: {model.seg_outputs[-1]}\")\n",
    "# Should print: Conv3d(64, 1, kernel_size=(1, 1, 1), ...)\n",
    "# Save the state dictionary of your modified model\n",
    "torch.save(model.state_dict(), \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/binary_large_ep4k.pth\")\n",
    "print(\"âœ… Weights saved.\")\n",
    "\n",
    "# Initialize the independent model\n",
    "model = STUNetReconstruction()\n",
    "\n",
    "# Load the weights you saved\n",
    "#    'strict=True' should work perfectly now because the class matches the patched architecture exactly.\n",
    "state_dict = torch.load(\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/checkpoints/pre-trained/Independent/binary_large_ep4k.pth\", map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Ready for training\n",
    "model.train()\n",
    "model.cuda()\n",
    "print(\"Model loaded successfully without nnU-Net dependencies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce7d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
