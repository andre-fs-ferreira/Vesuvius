{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_results_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences\"\n",
    "# Define the directory to search\n",
    "directory = Path(root_results_path)\n",
    "\n",
    "# Use rglob to search recursively ('**/*.csv') \n",
    "# or glob for just the current folder ('*.csv')\n",
    "csv_files = []\n",
    "for path in list(directory.rglob('*.csv')):\n",
    "    if \"tests\" in str(path) or len(str(path).split('/')[-1])<20:\n",
    "        continue\n",
    "    csv_files.append(path)\n",
    "\n",
    "root_results_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences_postprocess\"\n",
    "# Define the directory to search\n",
    "directory = Path(root_results_path)\n",
    "\n",
    "# Use rglob to search recursively ('**/*.csv') \n",
    "# or glob for just the current folder ('*.csv')\n",
    "for path in list(directory.rglob('*.csv')):\n",
    "    if \"tests\" in str(path) or len(str(path).split('/')[-1])<20:\n",
    "        continue\n",
    "    csv_files.append(path)\n",
    "\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Set options to show all rows and columns\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_colwidth', None) # Prevents text inside cells from being cut off\n",
    "\n",
    "\n",
    "rows_list = []\n",
    "cols_to_remove = ['tif_paths', 'id', 'pred_paths']\n",
    "\n",
    "for file in csv_files:\n",
    "    filename = os.path.basename(file)\n",
    "    c_time = os.path.getctime(file)\n",
    "    dt_c_time = datetime.fromtimestamp(c_time)\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    if len(df) >= 80:\n",
    "        mean_row = df.iloc[[79]].copy()\n",
    "        clean_row = mean_row.drop(columns=cols_to_remove, errors='ignore')\n",
    "        \n",
    "        # --- PARSING FILENAME ---\n",
    "        clean_row['Losses'] = filename.split('_DA')[0] if '_DA' in filename else  filename.split('_epoch')[0]\n",
    "        clean_row['epoch'] = filename.split('epoch_')[-1].split('_')[0] \n",
    "        clean_row['Train DA'] = filename.split('_DA')[-1].split('_')[0] if '_DA' in filename else  filename.split('_epoch')[0][-4:]\n",
    "        clean_row['tta_status'] = 'no_TTA' if 'no_TTA' in filename else 'TTA'\n",
    "        \n",
    "        if 'overlap_' in filename:\n",
    "            overlap_val = filename.split('overlap_')[1].split('_')[0]\n",
    "            clean_row['overlap'] = float(overlap_val)\n",
    "            \n",
    "        if 'th_' in filename:\n",
    "            th_val = filename.split('th_')[1].replace('.csv', '')\n",
    "            clean_row['threshold'] = float(th_val)\n",
    "        clean_row['dt_c_time'] = dt_c_time\n",
    "\n",
    "        if 'post_process_' in str(file).split('/')[-2]:\n",
    "            clean_row['postprocess'] = str(file).split('/')[-2].split('post_process_')[-1]\n",
    "        else:\n",
    "            clean_row['postprocess'] = 'no_postprocess'\n",
    "        rows_list.append(clean_row)\n",
    "\n",
    "# 2. Create the new combined DataFrame\n",
    "combined_df = pd.concat(rows_list, ignore_index=True)\n",
    "\n",
    "# 3. REORDER COLUMNS: Define the leading order\n",
    "# We list exactly what we want first, then add the rest of the columns\n",
    "fixed_cols = ['Losses', 'epoch', 'Train DA', 'tta_status', 'overlap', 'threshold', 'postprocess']\n",
    "other_cols = [c for c in combined_df.columns if c not in fixed_cols]\n",
    "\n",
    "combined_df = combined_df[fixed_cols + other_cols]\n",
    "\n",
    "# 4. View the result\n",
    "combined_df.sort_values(['image_score'], ascending=False)\n",
    "#combined_df.sort_values(['Losses', 'epoch', 'tta_status', 'image_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c438fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Basic save\n",
    "combined_df.to_csv('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/resume_results_old.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70277c19",
   "metadata": {},
   "source": [
    "# check individual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_Tversky_DAsafe_epoch_model_best/TTA/overlap_0.5/th_0.5/BCE_Tversky_DAsafe_epoch_model_best_TTA_overlap_0.5_th_0.5.csv\")\n",
    "df_1.sort_values(\"topo_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(\n",
    "    \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/trash/post_dilated/results_post.csv\")\n",
    "df_2[df['id'] == \"2961547523\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ab123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on the 'id' column\n",
    "combined_df = df_1.merge(df_2[['id', 'voi_score']], on='id', suffixes=('_1', '_2'))\n",
    "\n",
    "combined_df['diff'] = combined_df['voi_score_1'] - combined_df['voi_score_2']\n",
    "combined_df = combined_df.sort_values('diff', ascending=False)\n",
    "combined_df = combined_df[['id', 'voi_score_1', 'voi_score_2', 'diff']]\n",
    "print(f\"mean: {combined_df['diff'].mean()}\")\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(combined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5b4dd",
   "metadata": {},
   "source": [
    "# Copy all csv to an independent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Define directories\n",
    "base_path = Path(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences\")\n",
    "dest_root = Path(\"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/csv_results\")\n",
    "\n",
    "# Find all .csv files\n",
    "csv_files = list(base_path.rglob(\"*.csv\"))\n",
    "\n",
    "for file in csv_files:\n",
    "    file_str = str(file)\n",
    "    \n",
    "    # Filtering logic\n",
    "    if '/tests/' in file_str or file.name.startswith('th_'):\n",
    "        continue\n",
    "    \n",
    "    # Create the new path using pathlib (cleaner than .replace)\n",
    "    relative_path = file.relative_to(base_path)\n",
    "    dest_path = dest_root / relative_path\n",
    "\n",
    "    # Create the folder structure in the destination root\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy the file\n",
    "    shutil.copy2(file, dest_path)\n",
    "    print(f\"Copied: {dest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33c315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
