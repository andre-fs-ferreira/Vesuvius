{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b429c26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_DSC_DAsafe_epoch_80/no_TTA/overlap_0.5/th_0.5/BCE_DSC_DAsafe_epoch_80_no_TTA_overlap_0.5_th_0.5.csv'),\n",
       " PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/BCE_DSC_DAall_epoch_200/no_TTA/overlap_0.5/th_0.5/BCE_DSC_DAall_epoch_200_no_TTA_overlap_0.5_th_0.5.csv'),\n",
       " PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/Focal_Tversky_DAsafe_epoch_40/no_TTA/overlap_0.5/th_0.5/Focal_Tversky_DAsafe_epoch_40_no_TTA_overlap_0.5_th_0.5.csv'),\n",
       " PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/Focal_Tversky_DAsafe_epoch_150/TTA/overlap_0.5/th_0.4/Focal_Tversky_DAsafe_epoch_150_TTA_overlap_0.5_th_0.4.csv'),\n",
       " PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/Focal_Tversky_DAsafe_epoch_150/TTA/overlap_0.5/th_0.5/Focal_Tversky_DAsafe_epoch_150_TTA_overlap_0.5_th_0.5.csv'),\n",
       " PosixPath('/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences/Focal_Tversky_DAsafe_epoch_150/TTA/overlap_0.5/th_0.6/Focal_Tversky_DAsafe_epoch_150_TTA_overlap_0.5_th_0.6.csv')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_results_path = \"/home/shadowtwin/Desktop/AI_work/Vesuvius_Challenge/Vesuvius/inferences\"\n",
    "# Define the directory to search\n",
    "directory = Path(root_results_path)\n",
    "\n",
    "# Use rglob to search recursively ('**/*.csv') \n",
    "# or glob for just the current folder ('*.csv')\n",
    "csv_files = []\n",
    "for path in list(directory.rglob('*.csv')):\n",
    "    if \"tests\" in str(path) or len(str(path).split('/')[-1])<20:\n",
    "        continue\n",
    "    csv_files.append(path)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7b3d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Losses</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Train DA</th>\n",
       "      <th>tta_status</th>\n",
       "      <th>overlap</th>\n",
       "      <th>threshold</th>\n",
       "      <th>image_score</th>\n",
       "      <th>topo_score</th>\n",
       "      <th>surface_dice</th>\n",
       "      <th>voi_score</th>\n",
       "      <th>voi_split</th>\n",
       "      <th>voi_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCE_DSC</td>\n",
       "      <td>80</td>\n",
       "      <td>safe</td>\n",
       "      <td>no_TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.516074</td>\n",
       "      <td>0.130427</td>\n",
       "      <td>0.819026</td>\n",
       "      <td>0.543678</td>\n",
       "      <td>1.335766</td>\n",
       "      <td>1.513423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCE_DSC</td>\n",
       "      <td>200</td>\n",
       "      <td>all</td>\n",
       "      <td>no_TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.485808</td>\n",
       "      <td>0.109025</td>\n",
       "      <td>0.770171</td>\n",
       "      <td>0.524402</td>\n",
       "      <td>1.475593</td>\n",
       "      <td>1.594309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Focal_Tversky</td>\n",
       "      <td>40</td>\n",
       "      <td>safe</td>\n",
       "      <td>no_TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.519876</td>\n",
       "      <td>0.130271</td>\n",
       "      <td>0.823788</td>\n",
       "      <td>0.549909</td>\n",
       "      <td>1.304752</td>\n",
       "      <td>1.463048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Focal_Tversky</td>\n",
       "      <td>150</td>\n",
       "      <td>safe</td>\n",
       "      <td>TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.537427</td>\n",
       "      <td>0.186253</td>\n",
       "      <td>0.812687</td>\n",
       "      <td>0.563173</td>\n",
       "      <td>1.178807</td>\n",
       "      <td>1.439129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Focal_Tversky</td>\n",
       "      <td>150</td>\n",
       "      <td>safe</td>\n",
       "      <td>TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.531597</td>\n",
       "      <td>0.176505</td>\n",
       "      <td>0.817828</td>\n",
       "      <td>0.549730</td>\n",
       "      <td>1.333118</td>\n",
       "      <td>1.444002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Focal_Tversky</td>\n",
       "      <td>150</td>\n",
       "      <td>safe</td>\n",
       "      <td>TTA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.508585</td>\n",
       "      <td>0.144277</td>\n",
       "      <td>0.785108</td>\n",
       "      <td>0.544325</td>\n",
       "      <td>1.291426</td>\n",
       "      <td>1.544986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Losses epoch Train DA tta_status  overlap  threshold  image_score  \\\n",
       "0        BCE_DSC    80     safe     no_TTA      0.5        0.5     0.516074   \n",
       "1        BCE_DSC   200      all     no_TTA      0.5        0.5     0.485808   \n",
       "2  Focal_Tversky    40     safe     no_TTA      0.5        0.5     0.519876   \n",
       "3  Focal_Tversky   150     safe        TTA      0.5        0.4     0.537427   \n",
       "4  Focal_Tversky   150     safe        TTA      0.5        0.5     0.531597   \n",
       "5  Focal_Tversky   150     safe        TTA      0.5        0.6     0.508585   \n",
       "\n",
       "   topo_score  surface_dice  voi_score  voi_split  voi_merge  \n",
       "0    0.130427      0.819026   0.543678   1.335766   1.513423  \n",
       "1    0.109025      0.770171   0.524402   1.475593   1.594309  \n",
       "2    0.130271      0.823788   0.549909   1.304752   1.463048  \n",
       "3    0.186253      0.812687   0.563173   1.178807   1.439129  \n",
       "4    0.176505      0.817828   0.549730   1.333118   1.444002  \n",
       "5    0.144277      0.785108   0.544325   1.291426   1.544986  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "rows_list = []\n",
    "cols_to_remove = ['tif_paths', 'id', 'pred_paths']\n",
    "\n",
    "for file in csv_files:\n",
    "    filename = os.path.basename(file)\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    if len(df) >= 80:\n",
    "        mean_row = df.iloc[[79]].copy()\n",
    "        clean_row = mean_row.drop(columns=cols_to_remove, errors='ignore')\n",
    "        \n",
    "        # --- PARSING FILENAME ---\n",
    "        clean_row['Losses'] = filename.split('_DA')[0] \n",
    "        clean_row['epoch'] = filename.split('epoch_')[-1].split('_')[0] \n",
    "        clean_row['Train DA'] = filename.split('_DA')[-1].split('_')[0] \n",
    "        clean_row['tta_status'] = 'no_TTA' if 'no_TTA' in filename else 'TTA'\n",
    "        \n",
    "        if 'overlap_' in filename:\n",
    "            overlap_val = filename.split('overlap_')[1].split('_')[0]\n",
    "            clean_row['overlap'] = float(overlap_val)\n",
    "            \n",
    "        if 'th_' in filename:\n",
    "            th_val = filename.split('th_')[1].replace('.csv', '')\n",
    "            clean_row['threshold'] = float(th_val)\n",
    "        \n",
    "        rows_list.append(clean_row)\n",
    "\n",
    "# 2. Create the new combined DataFrame\n",
    "combined_df = pd.concat(rows_list, ignore_index=True)\n",
    "\n",
    "# 3. REORDER COLUMNS: Define the leading order\n",
    "# We list exactly what we want first, then add the rest of the columns\n",
    "fixed_cols = ['Losses', 'epoch', 'Train DA', 'tta_status', 'overlap', 'threshold']\n",
    "other_cols = [c for c in combined_df.columns if c not in fixed_cols]\n",
    "\n",
    "combined_df = combined_df[fixed_cols + other_cols]\n",
    "\n",
    "# 4. View the result\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4f559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
