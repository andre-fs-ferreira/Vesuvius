{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2800fd0",
   "metadata": {},
   "source": [
    "# Creation of a new loss function taking in consideration edges for not merging between sheets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396e344",
   "metadata": {},
   "source": [
    "* we want that each sheet (line) doesn't touch the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "def load_nii(file_path, integer):\n",
    "    \"\"\"\n",
    "    Loads a NIfTI file and returns the data array and the affine matrix.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .nii or .nii.gz file.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (data_array (np.ndarray), affine_matrix (np.ndarray))\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\" The file at {file_path} was not found.\")\n",
    "    \n",
    "    # Load the NIfTI object\n",
    "    nii_img = nib.load(file_path)\n",
    "    \n",
    "    # Get the data as a numpy array\n",
    "    # usage of get_fdata() is preferred as it automatically handles data typing\n",
    "    data = nii_img.get_fdata()\n",
    "    print(np.unique(data))\n",
    "    if integer:\n",
    "        data = np.rint(data).astype(np.int16)\n",
    "        print(np.unique(data))\n",
    "    # Get the affine (position/orientation in space)\n",
    "    affine = nii_img.affine\n",
    "    \n",
    "    print(f\"Loaded: {os.path.basename(file_path)}\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    \n",
    "    return data, affine\n",
    "\n",
    "def save_nii_with_metadata(data_to_save, original_nii_file_path, output_filepath):\n",
    "    \"\"\"\n",
    "    Saves a NumPy array as a NIfTI file, inheriting the affine matrix and \n",
    "    header information from an original NIfTI file.\n",
    "    \n",
    "    Args:\n",
    "        data_to_save (np.ndarray): The 3D NumPy array containing the segmented mask.\n",
    "        original_nii_file_path (str): The file path to the original NIfTI file.\n",
    "        output_filepath (str): The desired path and filename for the new NIfTI file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The path to the newly saved file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(original_nii_file_path):\n",
    "        raise FileNotFoundError(f\"Original file not found: {original_nii_file_path}\")\n",
    "\n",
    "    # 1. Load the original image object\n",
    "    # We only need its header and affine, not the data itself\n",
    "    original_img = nib.load(original_nii_file_path)\n",
    "    \n",
    "    # Check if the shapes match (important validation)\n",
    "    # 2. Extract Affine and Header\n",
    "    affine_matrix = original_img.affine\n",
    "    header_data = original_img.header\n",
    "\n",
    "    # 3. Create the new NIfTI image object\n",
    "    # Use the segmented data array and the affine matrix from the original file\n",
    "    try:\n",
    "        new_img = nib.Nifti1Image(data_to_save, affine_matrix, header_data)\n",
    "    except: \n",
    "         new_img = nib.Nifti1Image(data_to_save, affine_matrix)\n",
    "    \n",
    "    # 4. Update Header Datatype (Optional but recommended for masks)\n",
    "    # Masks are usually integers (e.g., int8 or int16)\n",
    "    # This prevents the mask from being saved unnecessarily as a float64.\n",
    "    new_img.set_data_dtype(np.int16) \n",
    "    \n",
    "    # 5. Save the file\n",
    "    nib.save(new_img, output_filepath)\n",
    "    \n",
    "    print(f\"Successfully saved mask to: {output_filepath}\")\n",
    "    return output_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d19abb",
   "metadata": {},
   "source": [
    "* making sure the lines are being separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09829ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.00001526 2.        ]\n",
      "[0 1 2]\n",
      "Loaded: 2290837.nii.gz\n",
      "Shape: (314, 314, 320)\n",
      "[0 1 2]\n",
      "data dtype: int16, shape: (314, 314, 320)\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/original_labels.nii.gz\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/binary_labels.nii.gz\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/several_labels.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/several_labels.nii.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to consider each \"line\" as individual labels\n",
    "from skimage.measure import label\n",
    "data, affine = load_nii(\n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\",\n",
    "    integer=True) \n",
    "\n",
    "\n",
    "print(np.unique(data))\n",
    "\n",
    "print(f\"data dtype: {data.dtype}, shape: {data.shape}\")\n",
    "save_nii_with_metadata(\n",
    "    data, \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/original_labels.nii.gz\",\n",
    "    )\n",
    "\n",
    "# ignore labels 2 \n",
    "\n",
    "data[data==2] = 0\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    data, \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/binary_labels.nii.gz\")\n",
    "\n",
    "labeled_mask = label(data)\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    labeled_mask, \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/several_labels.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47370e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.00001526 2.        ]\n",
      "[0 1 2]\n",
      "Loaded: 2290837.nii.gz\n",
      "Shape: (314, 314, 320)\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/weight_map.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/weight_map.nii.gz'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn.functional import sigmoid, binary_cross_entropy\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation, generate_binary_structure\n",
    "from skimage.measure import label\n",
    "\n",
    "\n",
    "sigma=1.0\n",
    "w0=10.0\n",
    "# getting an example\n",
    "gt, affine = load_nii(\n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\",\n",
    "    integer=True) \n",
    "\n",
    "gt = np.array(gt)\n",
    "gt[gt == 2] = 0 \n",
    "\n",
    "# Label 3D Instances\n",
    "# This correctly identifies connected blobs in 3D space\n",
    "instance_mask = label(gt)\n",
    "\n",
    "weight_map = np.zeros_like(instance_mask, dtype=np.float32)\n",
    "\n",
    "# Define 3D Structure for Dilation\n",
    "# A 3x3x3 cube connectivity (1 means consider diagonals, 0 means cross only)\n",
    "# This replaces the 2D cv2 kernel\n",
    "struct = generate_binary_structure(3, 2) \n",
    "\n",
    "# 4. Iterate Instances\n",
    "obj_ids = np.unique(instance_mask)\n",
    "obj_ids = obj_ids[obj_ids != 0]\n",
    "\n",
    "for obj_id in obj_ids:\n",
    "    obj_mask = (instance_mask == obj_id)\n",
    "\n",
    "    # 3D Dilation\n",
    "    # Expands the object in X, Y, AND Z directions\n",
    "    dilated = binary_dilation(obj_mask, structure=struct, iterations=2)\n",
    "    \n",
    "    # Create Halo\n",
    "    halo = dilated ^ obj_mask # XOR operation (same as dilated - original)\n",
    "    \n",
    "    # 3D Gaussian Blur\n",
    "    # Scipy handles 3D arrays automatically here\n",
    "    blurred_halo = gaussian_filter(halo.astype(float), sigma=sigma)\n",
    "    \n",
    "    # Normalize and Add\n",
    "    if blurred_halo.max() > 0:\n",
    "        blurred_halo = blurred_halo / blurred_halo.max() * w0\n",
    "        \n",
    "    weight_map += blurred_halo\n",
    "\n",
    "# Final Base Weight\n",
    "weight_map += 1.0\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    weight_map, \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/weight_map.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1e4ac",
   "metadata": {},
   "source": [
    "### Create the function to create the weight map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, binary_dilation, generate_binary_structure\n",
    "from skimage.measure import label\n",
    "\n",
    "class AntiBridgeLoss(nn.Module):\n",
    "    def __init__(self, sigma=1.0, w0=10.0):\n",
    "        super().__init__()\n",
    "        self.smooth = 1e-5\n",
    "        self.sigma = sigma\n",
    "        self.w0 = w0\n",
    "\n",
    "    def _get_edge_weight_map(self, gt_vol):\n",
    "        \"\"\"\n",
    "        Generates a 3D weight map for one volume.\n",
    "        gt_vol input: Numpy array (D, H, W)\n",
    "        Returns: Numpy array (1, 1, D, H, W)\n",
    "        \"\"\"\n",
    "        # Ensure clean copy to avoid side-effects on the original dataset\n",
    "        gt_vol = np.array(gt_vol)\n",
    "        gt_vol[gt_vol == 2] = 0 \n",
    "        \n",
    "        # Label 3D Instances\n",
    "        instance_mask = label(gt_vol)\n",
    "        \n",
    "        weight_map = np.zeros_like(instance_mask, dtype=np.float32)\n",
    "\n",
    "        # 3D Structure for Dilation (Connect across Z axis too)\n",
    "        struct = generate_binary_structure(3, 2) \n",
    "\n",
    "        obj_ids = np.unique(instance_mask)\n",
    "        obj_ids = obj_ids[obj_ids != 0]\n",
    "\n",
    "        for obj_id in obj_ids:\n",
    "            obj_mask = (instance_mask == obj_id)\n",
    "\n",
    "            # 3D Dilation\n",
    "            dilated = binary_dilation(obj_mask, structure=struct, iterations=2)\n",
    "            \n",
    "            # Create Halo (XOR)\n",
    "            halo = dilated ^ obj_mask \n",
    "            \n",
    "            # 3D Gaussian Blur\n",
    "            blurred_halo = gaussian_filter(halo.astype(float), sigma=self.sigma)\n",
    "            \n",
    "            # Normalize and Add\n",
    "            if blurred_halo.max() > 0:\n",
    "                blurred_halo = (blurred_halo / blurred_halo.max()) * self.w0\n",
    "                \n",
    "            weight_map += blurred_halo\n",
    "\n",
    "        # Final Base Weight\n",
    "        weight_map += 1.0\n",
    "        \n",
    "        # Add Batch and Channel dimensions: (D,H,W) -> (1, 1, D, H, W)\n",
    "        return weight_map[None, None, ...]\n",
    "\n",
    "    def forward(self, pred, gt, roi_mask, bridge_weight_map):\n",
    "        \"\"\"\n",
    "        pred: (B, 1, D, H, W) Logits\n",
    "        gt:   (B, 1, D, H, W) Binary Target\n",
    "        roi_mask: (B, 1, D, H, W) \n",
    "        bridge_weight_map: (Optional) Pre-calculated map. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Activation (Logits -> Probabilities)\n",
    "        pred_prob = torch.sigmoid(pred)\n",
    "\n",
    "        # Handle Weight Map Generation (CPU <-> GPU Bridge)\n",
    "        if bridge_weight_map is None:\n",
    "            # WARNING: Generating this on the fly is SLOW. \n",
    "            # It moves tensors to CPU, runs Scipy, and moves back.\n",
    "            \n",
    "            generated_maps = []\n",
    "            # Loop over batch (B)\n",
    "            for i in range(gt.shape[0]):\n",
    "                # Detach, move to CPU, convert to Numpy, remove Channel dim\n",
    "                gt_np = gt[i, 0].detach().cpu().numpy()\n",
    "                \n",
    "                # Generate Map\n",
    "                w_map_np = self._get_edge_weight_map(gt_np)\n",
    "                \n",
    "                # Convert back to Tensor and move to correct device\n",
    "                w_map_tensor = torch.from_numpy(w_map_np).to(pred.device)\n",
    "                generated_maps.append(w_map_tensor)\n",
    "            \n",
    "            # Stack batch back together\n",
    "            bridge_weight_map = torch.cat(generated_maps, dim=0)\n",
    "\n",
    "        # Compute Weighted Loss\n",
    "        # reduction='none' is crucial to keep the shape for masking\n",
    "        pixel_loss = F.binary_cross_entropy(pred_prob, gt, reduction='none')\n",
    "        \n",
    "        # Apply Anti-Bridge Weights\n",
    "        weighted_loss = pixel_loss * bridge_weight_map\n",
    "\n",
    "        # Apply ROI Mask\n",
    "        # Zero out loss in ignored regions\n",
    "        masked_loss = weighted_loss * roi_mask\n",
    "\n",
    "        # Average over VALID pixels only\n",
    "        loss_scalar = masked_loss.sum() / (roi_mask.sum() + self.smooth)\n",
    "\n",
    "        return loss_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.00001526 2.        ]\n",
      "[0 1 2]\n",
      "Loaded: 2290837.nii.gz\n",
      "Shape: (314, 314, 320)\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "anti_bridge_criterio = AntiBridgeLoss(sigma=1.0, w0=10.0)\n",
    "\n",
    "gt, affine = load_nii(\n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\",\n",
    "    integer=True) \n",
    "\n",
    "weight_map = anti_bridge_criterio._get_edge_weight_map(gt)\n",
    "save_nii_with_metadata(\n",
    "    weight_map[0][0], \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/weight_map.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4992f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING ANTI-BRIDGE LOSS TEST ---\n",
      "\n",
      "Test 1: checking weight map generation...\n",
      "  - Weight inside object: 2.8780 (Expected ~1.0)\n",
      "  - Weight in the gap:    14.1506 (Expected > 1.0, close to 21.0 due to overlap)\n",
      "  ✅ PASS: Gap has higher weight than object center.\n",
      "\n",
      "Test 2: Checking bridging penalty...\n",
      "  - Loss (Perfect): 0.000484\n",
      "  - Loss (Bridged): 10.741927\n",
      "  ✅ PASS: Bridging is heavily penalized.\n",
      "\n",
      "Test 3: Checking ROI masking...\n",
      "  - Loss (Fully Masked): 0.000000\n",
      "  ✅ PASS: ROI Mask successfully ignored the terrible prediction.\n",
      "\n",
      "--- TEST COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "def test_antibridge_loss():\n",
    "    print(\"--- STARTING ANTI-BRIDGE LOSS TEST ---\\n\")\n",
    "    \n",
    "    # 1. Setup Mock Data (Small 3D Volume: 1x1x10x10x10)\n",
    "    # We will place two objects close to each other\n",
    "    D, H, W = 10, 10, 10\n",
    "    gt_vol = np.zeros((D, H, W), dtype=np.float32)\n",
    "    \n",
    "    # Object 1: Cube at left\n",
    "    gt_vol[2:8, 2:8, 1:4] = 1 \n",
    "    # Object 2: Cube at right (Gap of 2 pixels in W dimension)\n",
    "    gt_vol[2:8, 2:8, 6:9] = 1 \n",
    "    \n",
    "    # Convert to Tensors (Batch=1, Channel=1)\n",
    "    gt_tensor = torch.from_numpy(gt_vol).unsqueeze(0).unsqueeze(0).float()\n",
    "    \n",
    "    # ROI Mask: Fully valid for now\n",
    "    roi_mask = torch.ones_like(gt_tensor)\n",
    "\n",
    "    # Initialize Loss\n",
    "    w0 = 10.0\n",
    "    loss_fn = AntiBridgeLoss(sigma=1.0, w0=w0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # TEST 1: Weight Map Generation\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Test 1: checking weight map generation...\")\n",
    "    # Generate map manually to inspect values\n",
    "    weight_map_np = loss_fn._get_edge_weight_map(gt_vol)\n",
    "    weight_map = torch.from_numpy(weight_map_np)\n",
    "    \n",
    "    # Inspect the GAP pixel (Slice 5, Row 5, Col 5)\n",
    "    # Obj1 ends at Col 3, Obj2 starts at Col 6. Gap is Col 4, 5.\n",
    "    gap_val = weight_map[0, 0, 5, 5, 5].item()\n",
    "    center_val = weight_map[0, 0, 5, 5, 2].item() # Inside Obj 1\n",
    "    \n",
    "    print(f\"  - Weight inside object: {center_val:.4f} (Expected ~1.0)\")\n",
    "    print(f\"  - Weight in the gap:    {gap_val:.4f} (Expected > 1.0, close to {1.0 + w0*2:.1f} due to overlap)\")\n",
    "    \n",
    "    if gap_val > center_val:\n",
    "        print(\"  ✅ PASS: Gap has higher weight than object center.\")\n",
    "    else:\n",
    "        print(\"  ❌ FAIL: Gap weight is not higher.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # TEST 2: Anti-Bridge Logic (The Penalty)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\nTest 2: Checking bridging penalty...\")\n",
    "    \n",
    "    # Scenario A: Perfect Prediction\n",
    "    # Logits: High positive for FG, High negative for BG\n",
    "    pred_perfect = torch.zeros_like(gt_tensor) + (-10.0) # Background everywhere\n",
    "    pred_perfect[gt_tensor==1] = 10.0 # Foreground where GT is\n",
    "    \n",
    "    # Scenario B: Bridging Prediction (Bad!)\n",
    "    # We predict the GAP pixels (4 and 5) as Foreground\n",
    "    pred_bridge = pred_perfect.clone()\n",
    "    pred_bridge[:, :, 2:8, 2:8, 4:6] = 10.0 # Fill the gap\n",
    "    \n",
    "    # Calculate Losses\n",
    "    # Note: We pass None for map so it generates it internally\n",
    "    loss_perfect = loss_fn(pred_perfect, gt_tensor, roi_mask).item()\n",
    "    loss_bridge = loss_fn(pred_bridge, gt_tensor, roi_mask).item()\n",
    "    \n",
    "    print(f\"  - Loss (Perfect): {loss_perfect:.6f}\")\n",
    "    print(f\"  - Loss (Bridged): {loss_bridge:.6f}\")\n",
    "    \n",
    "    if loss_bridge > loss_perfect * 10: # Should be significantly higher\n",
    "        print(\"  ✅ PASS: Bridging is heavily penalized.\")\n",
    "    else:\n",
    "        print(\"  ❌ FAIL: Bridging penalty is too low.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # TEST 3: ROI Masking Logic\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\nTest 3: Checking ROI masking...\")\n",
    "    \n",
    "    # We create a prediction that is TERRIBLE (All ones), \n",
    "    # but we mask the entire volume so loss should be 0.\n",
    "    pred_terrible = torch.ones_like(gt_tensor) * 10.0 \n",
    "    roi_mask_zero = torch.zeros_like(gt_tensor) # Ignore everything\n",
    "    \n",
    "    loss_masked = loss_fn(pred_terrible, gt_tensor, roi_mask_zero).item()\n",
    "    \n",
    "    print(f\"  - Loss (Fully Masked): {loss_masked:.6f}\")\n",
    "    \n",
    "    if loss_masked < 1e-4:\n",
    "        print(\"  ✅ PASS: ROI Mask successfully ignored the terrible prediction.\")\n",
    "    else:\n",
    "        print(\"  ❌ FAIL: ROI Mask did not ignore the errors.\")\n",
    "\n",
    "    print(\"\\n--- TEST COMPLETE ---\")\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_antibridge_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e7a3f",
   "metadata": {},
   "source": [
    "## Create a function to avoid descontuinity (*clDice*) -> from these tests, this doesn't work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ddacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/utils\"))\n",
    "\n",
    "from cldice.cldice import soft_cldice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef5c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_empty_prediction (__main__.TestVesuviusLoss.test_empty_prediction)\n",
      "Does empty prediction yield high loss? ... ok\n",
      "test_forward_pass_3d (__main__.TestVesuviusLoss.test_forward_pass_3d)\n",
      "Does it run without crashing on 3D volumes? ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Empty Prediction...\n",
      "Empty Prediction Loss: 0.9999998211860657\n",
      "\n",
      "Testing 3D Forward Pass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "test_gradient_flow (__main__.TestVesuviusLoss.test_gradient_flow)\n",
      "Is the loss differentiable? ... ok\n",
      "test_iter_parameter_bug (__main__.TestVesuviusLoss.test_iter_parameter_bug)\n",
      "Check if the 'iter_' parameter is actually being used. ... ok\n",
      "test_perfect_match (__main__.TestVesuviusLoss.test_perfect_match)\n",
      "Does perfect prediction yield near-zero loss? ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Loss Value: 0.49892014265060425\n",
      "\n",
      "Testing Gradient Flow...\n",
      "Gradients computed successfully.\n",
      "\n",
      "Checking 'iter_' parameter usage...\n",
      "Good: 'iter_' parameter is being passed correctly.\n",
      "\n",
      "Testing Perfect Match...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.495s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect Match Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import unittest\n",
    "\n",
    "# --- Paste your provided classes here (SoftSkeletonize, soft_cldice, etc.) ---\n",
    "# (Assuming the code you provided is available in the scope or imported)\n",
    "\n",
    "class TestVesuviusLoss(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Vesuvius-like dimensions: Batch=2, Channels=1, Depth=16, H=64, W=64\n",
    "        self.b, self.c, self.d, self.h, self.w = 2, 1, 16, 64, 64\n",
    "        self.shape_3d = (self.b, self.c, self.d, self.h, self.w)\n",
    "        self.shape_2d = (self.b, self.c, self.h, self.w)\n",
    "        \n",
    "        # Instantiate the loss\n",
    "        self.loss_fn = soft_cldice(iter_=3, smooth=1e-5, exclude_background=False)\n",
    "\n",
    "    def test_forward_pass_3d(self):\n",
    "        \"\"\"Does it run without crashing on 3D volumes?\"\"\"\n",
    "        print(\"\\nTesting 3D Forward Pass...\")\n",
    "        pred = torch.rand(self.shape_3d, requires_grad=True)\n",
    "        target = torch.randint(0, 2, self.shape_3d).float()\n",
    "        \n",
    "        loss, skeleton_pred, skel_true = self.loss_fn(target, pred)\n",
    "        print(f\"3D Loss Value: {loss.item()}\")\n",
    "        self.assertFalse(torch.isnan(loss), \"Loss should not be NaN\")\n",
    "\n",
    "    def test_gradient_flow(self):\n",
    "        \"\"\"Is the loss differentiable?\"\"\"\n",
    "        print(\"\\nTesting Gradient Flow...\")\n",
    "        pred = torch.rand(self.shape_3d, requires_grad=True)\n",
    "        target = torch.randint(0, 2, self.shape_3d).float()\n",
    "        \n",
    "        loss, skeleton_pred, skel_true = self.loss_fn(target, pred)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Check if gradients exist and are not zero\n",
    "        self.assertIsNotNone(pred.grad, \"Gradients should be calculated\")\n",
    "        # We expect some gradients to be non-zero\n",
    "        self.assertTrue(torch.sum(torch.abs(pred.grad)) > 0, \"Gradients should be non-zero\")\n",
    "        print(\"Gradients computed successfully.\")\n",
    "\n",
    "    def test_perfect_match(self):\n",
    "        \"\"\"Does perfect prediction yield near-zero loss?\"\"\"\n",
    "        print(\"\\nTesting Perfect Match...\")\n",
    "        # Create a synthetic 'line' target to guarantee a skeleton exists\n",
    "        target = torch.zeros(self.shape_3d)\n",
    "        target[:, :, :, 30:34, 30:34] = 1.0 # A central 'tube'\n",
    "        \n",
    "        # Prediction equals target\n",
    "        pred = target.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        loss, skeleton_pred, skel_true = self.loss_fn(target, pred)\n",
    "        print(f\"Perfect Match Loss: {loss.item()}\")\n",
    "        # clDice isn't always exactly 0.0 due to soft operations, but should be very low\n",
    "        self.assertLess(loss.item(), 0.1, \"Perfect match should have low loss\")\n",
    "\n",
    "    def test_empty_prediction(self):\n",
    "        \"\"\"Does empty prediction yield high loss?\"\"\"\n",
    "        print(\"\\nTesting Empty Prediction...\")\n",
    "        target = torch.zeros(self.shape_3d)\n",
    "        target[:, :, :, 30:34, 30:34] = 1.0 # A central 'tube'\n",
    "        \n",
    "        # Prediction is all zeros (empty)\n",
    "        pred = torch.zeros_like(target, requires_grad=True)\n",
    "        \n",
    "        loss, skeleton_pred, skel_true = self.loss_fn(target, pred)\n",
    "        print(f\"Empty Prediction Loss: {loss.item()}\")\n",
    "        self.assertGreater(loss.item(), 0.5, \"Empty prediction should have high loss\")\n",
    "\n",
    "    def test_iter_parameter_bug(self):\n",
    "        \"\"\"\n",
    "        Check if the 'iter_' parameter is actually being used.\n",
    "        Based on your code snippet, it looked like it was ignored.\n",
    "        \"\"\"\n",
    "        print(\"\\nChecking 'iter_' parameter usage...\")\n",
    "        \n",
    "        # Create a loss with 1 iteration\n",
    "        loss_short = soft_cldice(iter_=1)\n",
    "        # Create a loss with 20 iterations\n",
    "        loss_long = soft_cldice(iter_=20)\n",
    "        \n",
    "        # IN YOUR PROVIDED CODE:\n",
    "        # self.soft_skeletonize = SoftSkeletonize(num_iter=10) \n",
    "        # This is hardcoded! Both losses will behave IDENTICALLY.\n",
    "        \n",
    "        if loss_short.soft_skeletonize.num_iter == loss_long.soft_skeletonize.num_iter:\n",
    "            print(\"WARNING: Your code is ignoring the 'iter_' parameter!\")\n",
    "            print(f\"Both are fixed to: {loss_short.soft_skeletonize.num_iter}\")\n",
    "            # This is not a 'test failure' per se, but a warning for you.\n",
    "        else:\n",
    "            print(\"Good: 'iter_' parameter is being passed correctly.\")\n",
    "    \n",
    "# --- Run the tests ---\n",
    "if __name__ == '__main__':\n",
    "    # Standard unittest runner\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(TestVesuviusLoss)\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a290fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dice(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Standard Soft Dice Loss.\n",
    "    Returns: 1 - DiceScore\n",
    "    \"\"\"\n",
    "    smooth = 1e-5\n",
    "    intersection = torch.sum((y_true * y_pred))\n",
    "    coeff = (2. * intersection + smooth) / (torch.sum(y_true) + torch.sum(y_pred) + smooth)\n",
    "    return (1. - coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f80984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing The 'Dumbbell' Scenario ===\n",
      "Scenario: Two huge blocks connected by a tiny wire.\n",
      "Defect:   The wire is snapped.\n",
      "----------------------------------------\n",
      "Dice Loss:    0.0002\n",
      "clDice Loss:  0.1000\n",
      "----------------------------------------\n",
      "PASS: clDice is significantly more sensitive to the break!\n"
     ]
    }
   ],
   "source": [
    "# 4. Modified Test Function\n",
    "def test_dumbbell_bridge():\n",
    "    print(\"\\n=== Testing The 'Dumbbell' Scenario ===\")\n",
    "    \n",
    "    # Setup Canvas\n",
    "    shape = (1, 1, 64, 64, 64)\n",
    "    ground_truth = torch.zeros(shape)\n",
    "    \n",
    "    # Create Ground Truth: Two Massive Blocks connected by a Thin Wire\n",
    "    ground_truth[:, :, 20:44, 20:44, 10:20] = 1.0 # Left Block\n",
    "    ground_truth[:, :, 20:44, 20:44, 44:54] = 1.0 # Right Block\n",
    "    ground_truth[:, :, 32, 32, 20:44] = 1.0       # Bridge\n",
    "    \n",
    "    # Create Prediction: Same Blocks, but BROKEN Bridge\n",
    "    prediction = ground_truth.clone()\n",
    "    prediction[:, :, 32, 32, 30:34] = 0.0         # Cut the bridge\n",
    "    \n",
    "    prediction.requires_grad = True\n",
    "    \n",
    "    # Initialize Loss\n",
    "    criterion_cldice = soft_cldice(iter_=3, smooth=1e-5)\n",
    "    \n",
    "    # Calculate Scores\n",
    "    loss_dice = soft_dice(ground_truth, prediction)\n",
    "    \n",
    "    # Unpack the 3 return values\n",
    "    loss_cldice, skeleton_pred, skel_true = criterion_cldice(ground_truth, prediction)\n",
    "    \n",
    "    # Report\n",
    "    print(f\"Scenario: Two huge blocks connected by a tiny wire.\")\n",
    "    print(f\"Defect:   The wire is snapped.\")\n",
    "    print(f\"-\"*40)\n",
    "    print(f\"Dice Loss:    {loss_dice.item():.4f}\")\n",
    "    print(f\"clDice Loss:  {loss_cldice.item():.4f}\")\n",
    "    print(f\"-\"*40)\n",
    "    \n",
    "    if loss_cldice > loss_dice * 2.0:\n",
    "        print(\"PASS: clDice is significantly more sensitive to the break!\")\n",
    "    else:\n",
    "        print(\"FAIL: Scores are still too similar.\")\n",
    "\n",
    "    # Return the 4 tensors you need for saving\n",
    "    return ground_truth, prediction, skeleton_pred, skel_true\n",
    "\n",
    "# --- Execute and unpack ---\n",
    "ground_truth, prediction, skeleton_pred, skel_true = test_dumbbell_bridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f7cde5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Complex Structure: The Broken Helix ===\n",
      "Structure: 3D Spiral (Radius=18, Turns=1.5)\n",
      "Defect:    Gap of 4 slices in the middle\n",
      "----------------------------------------\n",
      "Dice Loss:    0.0449\n",
      "clDice Loss:  0.0621\n",
      "----------------------------------------\n",
      "FAIL: Scores are too similar.\n"
     ]
    }
   ],
   "source": [
    "def generate_thick_helix(shape, radius=15, turns=1.5, thickness=2):\n",
    "    \"\"\"\n",
    "    Generates a 3D spiral tube.\n",
    "    Returns: Tensor of shape (1, 1, D, H, W)\n",
    "    \"\"\"\n",
    "    volume = torch.zeros(shape)\n",
    "    D, H, W = shape[2], shape[3], shape[4]\n",
    "    \n",
    "    steps = 600 # Resolution of the spiral\n",
    "    t = np.linspace(0, turns * 2 * np.pi, steps)\n",
    "    \n",
    "    # Helix Math: Z moves linearly, X/Y move in a circle\n",
    "    z_coords = np.linspace(10, D-10, steps)\n",
    "    y_coords = (H // 2) + radius * np.sin(t)\n",
    "    x_coords = (W // 2) + radius * np.cos(t)\n",
    "    \n",
    "    # Draw the spiral\n",
    "    for i in range(steps):\n",
    "        z, y, x = int(z_coords[i]), int(y_coords[i]), int(x_coords[i])\n",
    "        \n",
    "        # Define the cube bounds for \"thickness\"\n",
    "        z0, z1 = max(0, z-thickness), min(D, z+thickness+1)\n",
    "        y0, y1 = max(0, y-thickness), min(H, y+thickness+1)\n",
    "        x0, x1 = max(0, x-thickness), min(W, x+thickness+1)\n",
    "        \n",
    "        volume[0, 0, z0:z1, y0:y1, x0:x1] = 1.0\n",
    "        \n",
    "    return volume\n",
    "\n",
    "# ==========================================\n",
    "# 3. Test Function\n",
    "# ==========================================\n",
    "\n",
    "def test_broken_helix():\n",
    "    print(\"\\n=== Testing Complex Structure: The Broken Helix ===\")\n",
    "    \n",
    "    # 1. Setup Canvas (64^3 cube)\n",
    "    shape = (1, 1, 64, 64, 64)\n",
    "    \n",
    "    # 2. Generate Ground Truth (Complete Spiral)\n",
    "    # Thickness=2 means the tube is about 5x5 pixels wide\n",
    "    ground_truth = generate_thick_helix(shape, radius=18, turns=1.5, thickness=2)\n",
    "    \n",
    "    # 3. Generate Prediction (Spiral with a Break)\n",
    "    prediction = ground_truth.clone()\n",
    "    \n",
    "    # Create a break in the middle of the Z-stack\n",
    "    # Cutting slices 30 to 34 creates a distinct gap\n",
    "    prediction[:, :, 30:34, :, :] = 0.0\n",
    "    \n",
    "    # Ensure gradients and range [0,1]\n",
    "    prediction.requires_grad = True\n",
    "    ground_truth = torch.clamp(ground_truth, 0.0, 1.0)\n",
    "    prediction = torch.clamp(prediction, 0.0, 1.0)\n",
    "    \n",
    "    # 4. Initialize Losses\n",
    "    # iter_=3 is ideal for thickness=2 (diameter ~5)\n",
    "    criterion_cldice = soft_cldice(iter_=30, smooth=1e-5)\n",
    "    \n",
    "    # 5. Calculate Scores\n",
    "    loss_dice = soft_dice(ground_truth, prediction)\n",
    "    loss_cldice, skeleton_pred, skel_true = criterion_cldice(ground_truth, prediction)\n",
    "    \n",
    "    # 6. Report\n",
    "    print(f\"Structure: 3D Spiral (Radius=18, Turns=1.5)\")\n",
    "    print(f\"Defect:    Gap of 4 slices in the middle\")\n",
    "    print(f\"-\"*40)\n",
    "    print(f\"Dice Loss:    {loss_dice.item():.4f}\")\n",
    "    print(f\"clDice Loss:  {loss_cldice.item():.4f}\")\n",
    "    print(f\"-\"*40)\n",
    "    \n",
    "    if loss_cldice > loss_dice * 1.5:\n",
    "        print(\"PASS: clDice detects the break in the complex spiral!\")\n",
    "    else:\n",
    "        print(\"FAIL: Scores are too similar.\")\n",
    "        \n",
    "    return ground_truth, prediction, skeleton_pred, skel_true\n",
    "\n",
    "# --- Run it ---\n",
    "ground_truth, prediction, skeleton_pred, skel_true = test_broken_helix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9af65d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Complex Structure: The Broken Helix ===\n",
      "[0.         1.00001526 2.        ]\n",
      "[0 1 2]\n",
      "Loaded: 2290837.nii.gz\n",
      "Shape: (314, 314, 320)\n",
      "Dice Loss:    0.129822\n",
      "clDice Loss:  0.071428\n"
     ]
    }
   ],
   "source": [
    "def test_broken_helix():\n",
    "    print(\"\\n=== Testing Complex Structure: The Broken Helix ===\")\n",
    "    \n",
    "    \n",
    "    # 2. Generate Ground Truth (Complete Spiral)\n",
    "    # Thickness=2 means the tube is about 5x5 pixels wide\n",
    "    ground_truth, affine = load_nii(\n",
    "        \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\",\n",
    "        integer=True) \n",
    "    ground_truth[ground_truth==2] = 0 \n",
    "    ground_truth = torch.from_numpy(ground_truth)\n",
    "    ground_truth = ground_truth.unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "    prediction = ground_truth.clone()\n",
    "\n",
    "    # SEVER TEST: Cut a 5-slice gap across the ENTIRE Z-axis\n",
    "    # This guarantees the connectivity is broken regardless of X/Y shape\n",
    "    mid_z = ground_truth.shape[2] // 2\n",
    "    prediction[:, :, mid_z : mid_z + 5, :, :] = 1\n",
    "    \n",
    "    # Use iter_=1 first to ensure we don't over-erode thin papyrus\n",
    "    criterion_cldice = soft_cldice(iter_=10, smooth=1e-5)\n",
    "    \n",
    "    loss_dice = soft_dice(ground_truth, prediction)\n",
    "    loss_cldice, skeleton_pred, skel_true = criterion_cldice(ground_truth, prediction)\n",
    "    \n",
    "    print(f\"Dice Loss:    {loss_dice.item():.6f}\")\n",
    "    print(f\"clDice Loss:  {loss_cldice.item():.6f}\")\n",
    "    \n",
    "    return ground_truth, prediction, skeleton_pred, skel_true\n",
    "\n",
    "# --- Run it ---\n",
    "ground_truth, prediction, skeleton_pred, skel_true = test_broken_helix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "810b220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/ground_truth.nii.gz\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/prediction.nii.gz\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/skeleton_pred.nii.gz\n",
      "Successfully saved mask to: /mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/skel_true.nii.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/skel_true.nii.gz'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_nii_with_metadata(\n",
    "    ground_truth[0][0].detach(), \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/ground_truth.nii.gz\")\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    data_to_save=prediction[0][0].detach(), \n",
    "    original_nii_file_path=\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    output_filepath=\"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/prediction.nii.gz\")\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    skeleton_pred[0][0].detach(), \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/skeleton_pred.nii.gz\")\n",
    "\n",
    "save_nii_with_metadata(\n",
    "    skel_true[0][0].detach(), \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/DataSet/Challenge_dataset_updated/train_labels_nii_crop/2290837.nii.gz\", \n",
    "    \"/mounts/disk4_tiago_e_andre/vesuvius/Vesuvius/trash/skel_true.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b0cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vesuvius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
